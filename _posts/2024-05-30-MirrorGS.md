---
layout: distill
title: MirrorGS
description: Incorporating Mirror Reflections into 3D Gaussian Splatting
tags: 
    -  Guassin-Splatting
    -  Reflection
categories: guassin-splatting
giscus_comments: true
date: 2024-05-30
featured: true

authors:
  - name: Tingting Liao
    url: "https://tingtingliao.github.io"
    affiliations:
      name: MBZUAI
  
bibliography: 2024-05-30-distill.bib

toc:
  - name: Mirror Plane Estimation
  - name: Mirror Camera Transformation 
  - name: Fuse Image

_styles: >
  .fake-img {
    background: #bbb;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
    margin-bottom: 12px;
  }
  .fake-img p {
    font-family: monospace;
    color: white;
    text-align: left;
    margin: 12px 0;
    text-align: center;
    font-size: 16px;
  }
---

I reimplement Mirror3DGS <d-cite key="mirror3dgs"></d-cite> and the code can be found [here](https://github.com/TingtingLiao/MirrorGS). This blog helps better understanding the paper and the code. 
 
<!-- - [ArXiv](https://arxiv.org/pdf/2404.01168) 
- [Code](https://github.com/TingtingLiao/MirrorGS) -->


> **Key Idea**
>
> For non-mirron area, rendering image from the origin camera viewpoint.
> 
> For mirror area, transforming the camera to the other side of the mirror. 
{: .block-warning }

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/MirrorGS/mirror_camera.png" title="example image" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
 Blue Camera: origin viewpoint. Yellow Camera: virtual viewpoint after mirror transform.
</div>
 
To render the mirror area, we have to solve two problem:

- **How to get the mirror plane from the scene?** 
- **How to transform the camera?**

## 1. Mirror Plane Estimation 
### Mirror Label Learning  
To get the mirror points, we can learn a [mirror label](https://github.com/TingtingLiao/MirrorGS/blob/82f6e3bb3e5b22e8dfc21546b7a0cca804c3c759/scene/gaussian_model.py#L168) 
$$k \in [0, 1]$$ for each guassian point. To learn the mirror labels, mirror masks are required for supervision. 

$$\mathcal{L}_{mirr\_mask}=\mathcal{L}_1(\mathbf{M} , \mathbf{M} _{gt})$$

The [mirror mask rendering](https://github.com/TingtingLiao/MirrorGS/blob/82f6e3bb3e5b22e8dfc21546b7a0cca804c3c759/gaussian_renderer/__init__.py#L131) is similar to rgb image rendering, replacing color with $k$. During training, the mirror points can be extracted through a threshold. Then estimate the plane equation from the mirror points. 

### Plane Fitting

$$ax + by + cz + d = 0$$

Where $$n=(a, b, c)^⊤$$ is the normal of the plane, $$d$$ is the distance to the origin. **Assuming for any point $$p = (x, y, z)^⊤$$ on the plane satisfies**:

$$
n^{T}p+d=0
$$

The objective is to minimizing the least squares error:

$$
\sum_{i=1}^{m} (n^T(p_i - \mathbf{c}))^2
$$

where $$\mathbf{c} = \frac{1}{m} \sum_{i=1}^{m} \mathbf{p}_i$$, $$d=-n^T\mathbf{c}$$ and normal $$n$$ equals the eigenvector of the smallest eigenvalue of the covariance matrix:

$$
\sum_{i=1}^{m} (\mathbf{p}_i - \mathbf{c})(\mathbf{p}_i - \mathbf{c})^T
$$

The method is simple yet effective for clean points. **However, the extracted points are noisy.** Thus we use the RANSAC algorithm<d-cite key="fischler1981random"></d-cite>. The basic idea involves sampling three points in each iteration, computing the plane equation, and then removing points that are far from the plane. You can find the [ransac code here.](https://github.com/TingtingLiao/MirrorGS/blob/82f6e3bb3e5b22e8dfc21546b7a0cca804c3c759/utils/ransac.py)


## 2. Mirror Camera Transformation 

The camera transformation is 

## 3. Fuse Image 