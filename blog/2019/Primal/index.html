<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Primal Dual Problem | Tingting Liao </title> <meta name="author" content="Tingting Liao"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tingtingliao.github.io/blog/2019/Primal/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Tingting</span> Liao </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Primal Dual Problem</h1> <p class="post-meta"> April 20, 2019 • Tintin </p> <p class="post-tags"> <a href="/blog/2019"> <i class="fa-solid fa-calendar fa-sm"></i> 2019 </a>   ·   <a href="/blog/tag/optimization"> <i class="fa-solid fa-hashtag fa-sm"></i> optimization</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <h3 id="1-fenchel-legendre-duality">1. Fenchel-Legendre Duality</h3> <p>Fenchel Duality和Legendre变换本质上是一样的，只是从不同的角度去解释，它刻画的是函数斜率与截距之间的关系。</p> <table> <td> <img src="https://pic1.zhimg.com/80/v2-20901fce41b710cdba10d49045227b14_hd.jpg" width="700"> </td> <td> <img src="http://mmbiz.qpic.cn/mmbiz_gif/REGqUlN1rzLia767DGoeTAGu2hU8hc1kD6o5Eh6pZgpEGMIVTLJMEBPBZjeBKRibksopf0REwR0Hq673cn5Cc0FA/0?wx_fmt=gif&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1"> </td> </table> <p>过原点作一条斜线\(y=kx\)，将其向下平移与\(f(x)\)相切，该切线与\(y\)轴的截距与斜线向下平移的距离相等，\(f^*(k)是截距\):</p> \[f^*(k) = kx-f(x)\] \[f'(x)=k\] <p>这就是Legendre变换，Fenchel则将其换成一个更general的表达式：</p> \[f^*(y) = \max_x\{yx-f(x)\}\] <p>\(f^*(y)\)称为\(f(x)\)的共轭,这样的好处是，当\(f(x)\)是非凸函数时，\(f(x)=k\)不唯一，而Fenchel可以很好解决这个问题得到唯一解。</p> <h6 id="例求gx--log1ex的共轭gy">例：求\(g(x) = \log(1+e^x)\)的共轭\(g^*(y)\)</h6> <ul> <li>切线斜率\(y = \frac{e^x}{1+e^x} \in (0,1)\),\(e^x = \frac{y}{1-y},x = \log \frac{y}{1-y}\)</li> <li> \[g(x)=\log(1+e^x)=\log \frac{1}{1-y}\] </li> </ul> \[\begin{split} g^*(y) &amp;= yx-g(x) \\ &amp;= y\log \frac{y}{1-y}-\log \frac{1}{1-y} \\ &amp;= y\log y +(1-y) \log(1-y) \end{split}\] \[\therefore g^*(y)=\left\{\begin{matrix} y\log y +(1-y) \log(1-y) &amp;\quad y\in (0,1)\\ 0 &amp;\quad otherwise \end{matrix}\right.\] <p>Fenchel共轭的性质：</p> <ol> <li>共轭的共轭等于原函数\(g^{**}(x) = g(x)\)</li> <li>\(g(x)\)是凸函数，那么共轭\(g^*(x)\)也为凸函数</li> <li>\(g(x)\)是\(L-smooth\),那么\(g^*(x)\)是\(\frac{1}{L}-SC(Strongly Convex)\)</li> </ol> <h3 id="2-primal-dual">2. Primal Dual</h3> <p><strong>Primal</strong></p> \[\min_{x \in R^d}{\Phi(x)+\frac{1}{n}\sum_{i=1}^{n}f_i(a_i x)} \quad (1)\] <p><strong>Primal Dual</strong><br> 前一项不变（Primal），将后一项\(ERM\)换成对偶（Dual）形式：</p> \[\min_{x \in R^d}\max_{y \in R^d}{\Phi(x)-\frac{1}{n}\sum_{i=1}^{n}f^*_i(y) +\frac{1}{n}y^TAx } \quad (2)\] <p><strong>Dual</strong></p> <p>将(2)式第一项与第三项替换合并为其对偶形式，那么整个目标函数就变成对偶问题：</p> \[\begin{split} &amp;-\min_{x \in R^d}\max_{y \in R^d}{-\Phi(x)+\frac{1}{n}\sum_{i=1}^{n}f^*_i(y) -\frac{1}{n}yx } \\ =&amp; -\min_{y \in R^d}{\Phi^*(-\frac{1}{n}A^Ty)+\frac{1}{n}\sum_{i=1}^{n}f^*_i(y) }\quad (3) \end{split}\] <h6 id="例求fracsigma2-x2frac12nsum_i1na_itx-b_i2的对偶问题">例：求\(\frac{\sigma}{2} ||x||^2+\frac{1}{2n}\sum_{i=1}^n(a_i^Tx-b_i)^2\)的对偶问题。</h6> <p>该式对应Primal（1）式：</p> \[f(a_i^Tx) = \frac{1}{2}(a_i^Tx-b_i)^2\] \[f(z) = \frac{1}{2}(z-b_i)^2\] <p>下面求共轭\(f^*(y)\):</p> \[y =z-b_i,\therefore z = y+b_i,f(z)=\frac{1}{2}y^2\] \[\begin{split} f^*(y)&amp;=yz-f(z) \\ &amp; =y(y+b_i)- \frac{1}{2}y^2 \\ &amp; = \frac{1}{2}y^2 + b_iy \end{split}\] <p>对应(2)式：</p> \[\frac{\sigma}{2} ||x||^2-\frac{1}{n}\sum_{i=1}^n(\frac{1}{2}y_i^2 + b_iy_i ) +\frac{1}{n}y^TAx \quad (Primal Dual)\] <p>下面计算Dual问题：</p> \[\Phi(x)= \frac{\sigma}{2} ||x||^2\] \[y=\sigma ||x||,\therefore ||x|| = \frac{y}{\sigma},\Phi(x)=\frac{y^2}{2\sigma}\] \[\begin{split} \Phi^*(y) &amp;= y^Tx-\Phi(x) \\ &amp; = \frac{y^2}{\sigma} - \frac{y^2}{2\sigma} = \frac{y^2}{2\sigma} \end{split}\] \[\Phi^*(-\frac{1}{n}A^Ty) =\frac{1}{2\sigma} ||\frac{A^Ty}{n}||^2\] <p>对应（3）式：</p> \[-\min_{y \in R^d}{\frac{1}{2\sigma} ||\frac{A^Ty}{n}||^2+\frac{1}{2n}||y||^2 +\frac{1}{n}y^Tb } \quad (Dual)\] <h3 id="3-stochastic-solvers">3. Stochastic Solvers</h3> <p>泽园大神总结了针对Primal,Primal-Dual,Dual问题的随机方法并将其分为三类：SGD,方差下降/随机下降和加速算法。</p> <p><img src="/img/PrimalDual/StoSovlver.jpg" alt="avatar"></p> <p>并针对四种情况，讨论各类方法的收敛性，这里只给出总结性结果不讨论方法具体实现过程。</p> <p>Case1: 强突光滑。\(\sigma&gt;0,L &lt; +\infty.\) <br> Case2: 强突非光滑。\(\sigma&gt;0,L = +\infty.\) <br> Case3: 非强突光滑。\(\sigma=0,L &lt; +\infty.\) <br> Case4: 非强突非光滑。\(\sigma=0,L = +\infty.\) <br></p> <h5 id="31-sgd-vs-svrg">3.1 SGD VS SVRG</h5> <table> <thead> <tr> <th style="text-align: center"> </th> <th style="text-align: center">Case1</th> <th style="text-align: center">Case2</th> <th style="text-align: center">Case3</th> <th>Case4</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(SGD\)</td> <td style="text-align: center">\(O(\frac{L^2}{\sigma \epsilon})\)</td> <td style="text-align: center">\(O(\frac{G}{\sigma \epsilon})\)</td> <td style="text-align: center">\(O(\frac{L^2}{ \epsilon^2})\)</td> <td>\(O(\frac{G}{ \epsilon^2})\)</td> </tr> <tr> <td style="text-align: center">\(SVRG\)</td> <td style="text-align: center">\(O((n+\frac{L}{\sigma})\log\frac{1}{\epsilon})\)</td> <td style="text-align: center"> </td> <td style="text-align: center">\(O(n\log\frac{1}{\epsilon}+\frac{L}{\epsilon})\)</td> <td> </td> </tr> </tbody> </table> <p>\(SVRG\)在函数光滑的情况下比\(SGD\)快，而在非光滑的情况下比\(SGD\)多了\(O(n)\).</p> <h5 id="32-stochastic-dual-coordinate-ascentsdca">3.2 Stochastic Dual Coordinate ascent(SDCA)</h5> <p>coordinate descent坐标下降的两条定理：</p> <ol> <li>如果目标函数为\(L-smooth\),收敛速率为\(O(\frac{nL}{\epsilon})\)</li> <li>如果目标函数为\(\sigma-StronglyConvex\),收敛速率为\(O(\frac{nL}{\sigma}\log\frac{1}{\epsilon})\)</li> </ol> <p>值得注意的是，对于一个Primal问题使用\(SVRG\)，将其转换成Dual问题使用坐标下降，两者的收敛速度是一样的吗？答案是一样的。<br> 假设原始问题中\(\Phi(x)\)是\(\sigma-SC\),\(f(x)\)是\(L-smooth\)：</p> \[\min_{x \in R^d}{\Phi(x)+\frac{1}{n}\sum_{i=1}{n}f_i(a_i x)} \quad (1)\] <p>那么\(\Phi^*(x)\)是\(\frac{1}{\sigma}-smooth\),\(f^*(x)\)是\(\frac{1}{L}-SC\),其对偶：</p> \[g(y) = {\Phi^*(-\frac{1}{n}A^Ty)+\frac{1}{n}\sum_{i=1}^{n}f^*_i(y) }\] <p>\(g(y)\)是\((\frac{1}{n^2\sigma}+ \frac{1}{nL})-smooth\),\(\frac{1}{nL}-SC\),代入到第二条定理中:</p> \[\begin{split} &amp;O(\frac{dL}{\sigma}\log\frac{1}{\epsilon}) \\ =&amp; O( \frac{n (\frac{1}{n^2\sigma}+ \frac{1}{nL})}{\frac{1}{nL}}\log\frac{1}{\epsilon}) \\ =&amp; O((n+\frac{L}{\sigma} )\log\frac{1}{\epsilon}) \end{split}\] <p>可以看到在凸且光滑的情况下，\(SDCA\)与\(SVRG\)的收敛速度相等，而在另外三种情况下它们也等价。</p> <h5 id="33-accelerated-proximal-coordinate-gradient-apgc">3.3 Accelerated Proximal Coordinate Gradient (APGC)</h5> <p>\(APGC\)在\(SDCA\)的基础上用了Neterov Momentum加速算法.SDCA收敛速度为\(O(\frac{nL}{\sigma}\log\frac{1}{\epsilon})\),\(APCG\)收敛速度为\(O(\frac{n\sqrt{L}}{\sqrt{\sigma}}\log\frac{1}{\epsilon})\)</p> <p><img src="/img/PrimalDual/Nesterov.jpg" alt=""></p> <table> <thead> <tr> <th style="text-align: center"> </th> <th style="text-align: center">Case1</th> <th style="text-align: center">Case2</th> <th style="text-align: center">Case3</th> <th>Case4</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(SDCA\)</td> <td style="text-align: center">\(O(n+\frac{L}{\sigma})\)</td> <td style="text-align: center">\(O(n+\frac{G}{\sigma\epsilon})\)</td> <td style="text-align: center">\(O(n+\frac{L}{\epsilon})\)</td> <td>\(O(n+\frac{G}{\epsilon^2})\)</td> </tr> <tr> <td style="text-align: center">\(APCG\)</td> <td style="text-align: center">\(O(n+\frac{\sqrt{nL}}{\sqrt{\sigma}})\)</td> <td style="text-align: center">\(O(n+\frac{\sqrt{nG}}{\sqrt{\sigma\epsilon}})\)</td> <td style="text-align: center">\(O(n+\frac{\sqrt{nL}}{\sqrt{\epsilon}})\)</td> <td>\(O(n+\frac{\sqrt{nG}}{\epsilon})\)</td> </tr> </tbody> </table> <p>可以看到\(APCG\)比\(SDCA\)收敛更快，加速算法总是比非加速算法快的。</p> <h5 id="34-stochastic-primal-dual-coordinate-spdc">3.4 Stochastic Primal Dual Coordinate (SPDC)</h5> <p>\(SPDC\)主要针对Primal-Dual，也就是说它需要更新两方面的参数，一方面用坐标下降更新Dual问题一方面用SVRG更新Primal问题：</p> <ol> <li> <p>coordinate descent： \(y_{k+1} = y_k-\eta_y \triangledown g_i(y)\)</p> </li> <li> <p>full gradient descent: \(x_{k+1} = x_k-\eta_x \triangledown g(x)\)</p> </li> </ol> <p>并且需要保存两个学习率\(\eta_y,\eta_x\).\(SPDC\)的主要贡献在于它使用了momentum，它的收敛速率和\(APCG\)相等。</p> <h5 id="35-katyusha">3.5 Katyusha</h5> <p>Katyusha是针对原始问题随机梯度方法的加速方法，有一个问题是Momentum不能直接用在SGD中，这是因为SGD的gradient方向本身就不够准确，而用momentum过后之前不够准确的梯度方向会进一步导致后面的梯度方向往错的方向走。</p> <p><img src="/img/PrimalDual/Katyusha.jpg" alt=""></p> <p><img src="/img/PrimalDual/Katyusha2.jpg" alt=""></p> <p>泽园大神的Katyusha就很巧妙，负梯度（黑线）–&gt; momentum（绿线）–&gt; retracted（黄线）–&gt; 负梯度方向 –&gt; momentum–&gt; retracted…</p> <p>它在momentum的基础上增加了一步retracted过程，即momentum点与起始点\(x_0\)相连取中点为最后更新的位置，在一次epoch过后将最终点设为新的起始点\(x_o\)去retracted后面更新的点。</p> <p>Katyucha的收敛速度与SPDC和APCG的收敛速度相等。</p> <h4 id="4-总结">4. 总结</h4> <font color="blue">1.如何选择Primal、Primal-Dual和Dual问题？</font> <ul> <li> <p>Case1: \(\Phi(x)\)强凸\(f(x)\)光滑，可以选择Primal或Dual，不推荐Primal-Dual，因为它需要调整两个学习率.</p> </li> <li> <p>Case2: \(\Phi(x)\)强凸\(f(x)\)不光滑，对偶目标函数是光滑非强凸，推荐Dual问题不推荐原始问题。</p> </li> <li> <p>Case3：原始问题中\(\Phi(x)\)非强凸\(f(x)\)光滑，推荐Primal不推荐Dual，因为对应的Dual的目标函数是不光滑强凸的，而coordinate descent要求函数光滑，如果要用需要先</p> </li> <li> <p>Case4：Primal和Dual的目标函数都是非强凸非光滑的，推荐Primal-Dual。</p> </li> <li> <p>其它更复杂的情况，如\(f(x)\)是非凸，或者不是\(f(a_i^Tx)\)的形式，推荐使用Primal而不用Dual，因为Dual问题可能会变得十分高维。</p> </li> </ul> <font color="blue"> 2. 什么时候用加速算法？</font> <ul> <li> <p>当\(\epsilon\)特别小的时候。即对结果精度要求特别高的时候可以用加速算法。</p> </li> <li> <p>当\(\sigma\)特别小的时候。因为当\(\sigma\)特别小的时候，加速算法的收敛速度会比非加速算法快特别多。</p> </li> </ul> <font color="blue">3.并行计算Mini-Batch</font> <p><img src="/img/PrimalDual/Mini-Batch.png" alt=""> </p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/BreGAN/">Incorporate Bregman Divergence to generalize fGAN</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/Proximal-Descent/">近端梯度下降</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/Katyusha/">Katyusha</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/FasterRCNN/">Faster RCNN</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/Convergence/">梯度下降收敛速度</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Tingting Liao. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>