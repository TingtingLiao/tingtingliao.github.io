<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 差分隐私-三种机制 | Tingting Liao </title> <meta name="author" content="Tingting Liao"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tingtingliao.github.io/blog/2019/DP/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Tingting</span> Liao </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">差分隐私-三种机制</h1> <p class="post-meta"> April 01, 2019 • Tintin </p> <p class="post-tags"> <a href="/blog/2019"> <i class="fa-solid fa-calendar fa-sm"></i> 2019 </a>   ·   <a href="/blog/tag/privacy"> <i class="fa-solid fa-hashtag fa-sm"></i> privacy</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <h2 id="1-基础知识介绍">1. 基础知识介绍</h2> <blockquote> <p>差分隐私主要目的是最大化utility的查询结果同时保证个人隐私的泄露不超过\(\epsilon\).</p> </blockquote> <h4 id="11-概括">1.1 概括</h4> <ul> <li>差分隐私主要包含以下两类： <ol> <li>中心化差分隐私(\(\epsilon-DP\))</li> <li>本地化差分隐私(\(\epsilon-LDP\))</li> </ol> </li> </ul> <p>其区别在于中心化差分隐私的随机函数运行于服务器上，而本地化差分隐私的运行于本地。服务器上数据有全局敏感性，而本地查询中任意用户之间并不知晓其它人的数据记录。因此中心化差分隐私一般采用拉普拉斯、指数噪声机制等方法，而本地化差分隐私主要采用随机响应技术保护隐私。</p> <ul> <li>加噪方法主要分为以下两类： <ol> <li> <strong>扰动（perturbation）</strong> <ul> <li>对输入数据扰动：随机响应（Randomized Response）</li> <li>对输出数据扰动：拉普拉斯算法（Laplace）</li> <li>中间数据：随机响应或拉普拉斯算法</li> </ul> </li> <li> <strong>采样（sampling）</strong><br> 该算法中心思想为：将数据集分为\(k\)份，对每份数据应用拉普拉斯或随机相应算法。它的好处是对小数据集进行处理从而提高运行效率，有点类似于随机梯度下降计算每个Batch的梯度。</li> </ol> </li> </ul> <h4 id="12-差分隐私">1.2 差分隐私</h4> <p>核心思想：对于差别只有一条记录的两个相邻数据集，查询它们获得相同值的概率非常接近。</p> \[P[M(D)\in S] \leq e^\epsilon P[M(D')\in S] \\ \frac{P[M(D)=S]}{P[M(D')=S]} \leq e^{\epsilon}\] <p>对于两个只相差一个记录的相邻数据集\(D\)和数据集\(D'\),查询算法\(M\)的输出结果\(S\)的概率应该非常接近。对于任意参数\(\epsilon &gt;0\),函数\(M\)满足\(\epsilon-differential \quad privacy\) \(\epsilon\)接近于0，两个概率接近相等，保密程度高，噪声越大 \(\epsilon\)越大，数据越准确，保密程度低，噪声越小。</p> <h4 id="13-组合定理composition-theorem">1.3 组合定理Composition Theorem</h4> <ul> <li> <strong>串行组合 (Sequential Composition)</strong><br> 假设有\(k\)个算法\(M_1, M_2, …, M_k\)在同一数据库\(D\)上进行差分隐私算法, \(M_i\) 满足\(\epsilon_i\) 差分隐私,这样在顺序执行这些算法之后,那么组合后的算法满足\(\sum_i \epsilon_i-DP\):</li> </ul> \[\epsilon = \epsilon_1 +\epsilon_2+...+\epsilon_k\] <ul> <li> <strong>并行组合 (Parallel Composition)</strong><br> 假设有\(k\)个算法\(M_1, M_2, …, M_k\)分别作用于数据集\(D_1, D_2, …, D_k\)上,\(M_i\) 满足\(\epsilon_i\)差分隐私,那么组合后算法满足\(\max\epsilon_i\)-差分隐私:</li> </ul> \[\epsilon_i = \max\{ \epsilon_1 ,\epsilon_2,...,\epsilon_k \}\] <h2 id="2-三种分布">2. 三种分布</h2> <table> <td> <img src="http://5b0988e595225.cdn.sohucs.com/images/20170724/1038a80c62694dbdba65f3c80577a781.gif" width="200"> </td> <td> <img src="https://github.com/Echo-Gaoguichun/DP-Learning/raw/master/Reading-Notes/Pictures/20190224_DP/2.png" width="200"> </td> <td> <img src="https://gss3.bdstatic.com/7Po3dSag_xI4khGkpoWK1HF6hhy/baike/c0%3Dbaike80%2C5%2C5%2C80%2C26/sign=b02ffa7a8182b90129a0cb6112e4c212/96dda144ad345982cd6434cf07f431adcaef8485.jpg" width="200"> </td> </table> <p>\(\quad\quad\quad f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{\sigma^2}} \quad\quad\quad\quad f(x)=\frac{1}{2\lambda}e^{-\frac{|x-\mu|}{\lambda}}\quad\quad\quad f(x)=\left\{\begin{matrix} \lambda e^{-\lambda x} &amp;x&gt;0 \\ 0 &amp;x\leq 0 \end{matrix}\right.\)</p> <table> <thead> <tr> <th style="text-align: center"> </th> <th style="text-align: center">Gaussian</th> <th style="text-align: center">Laplace</th> <th style="text-align: center">Exponential</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(X \sim\)</td> <td style="text-align: center">\(N(\mu,\sigma)\)</td> <td style="text-align: center">\(L(\mu,\lambda)\)</td> <td style="text-align: center">\(E(\lambda)\)</td> </tr> <tr> <td style="text-align: center">\(E(X)\)</td> <td style="text-align: center">\(\mu\)</td> <td style="text-align: center">\(\mu\)</td> <td style="text-align: center">\(\frac{1}{\lambda}\)</td> </tr> <tr> <td style="text-align: center">\(D(X)\)</td> <td style="text-align: center">\(\sigma\)</td> <td style="text-align: center">\(2\lambda^2\)</td> <td style="text-align: center">\(\frac{1}{\lambda^2}\)</td> </tr> <tr> <td style="text-align: center">\(sensitivity\)</td> <td style="text-align: center">\(l_2\)</td> <td style="text-align: center">\(l_1\)</td> <td style="text-align: center">\(l_1\)</td> </tr> <tr> <td style="text-align: center">加噪对象</td> <td style="text-align: center">数值型</td> <td style="text-align: center">数值型</td> <td style="text-align: center">非数值型</td> </tr> </tbody> </table> <p>以高斯分布为例，可以把概率看作是点到均值的距离，距离中心点越远概率越小，距离越近概率越大。</p> \[D_{Gau} = ||x-\mu||_2\] \[D_{Lap} = ||x-\mu||_1\] \[D_{Exp} = \lambda x\] <p>其中拉普拉斯用一范式距离，高斯是二范式即欧式距离，分别对应了differential privacy中的\(l_1,l_2-sensitivity\).而\(\frac{x-\mu}{\sigma}\)是为了归一化，可以看作是统一量纲消去变量之间的，例如在二元高斯中特征\(X=[x_1,x_2]\)表示身高和体重,而身高和体重之间的量纲是不一样的,直接计算距离会产生很大的误差，那么就需要对其归一化再计算其总距离：</p> \[Distance = \frac{(x_1-\mu_1)^2}{\sigma_1^2}+\frac{(x_2-\mu_2)^2}{\sigma_2^2}\] <p>再用指数函数放大距离，即放大距离对概率的影响。而前面的系数则是为了积分等于1.例如：</p> \[\int e^{-\frac{(x-\mu)^2}{\sigma^2}} = {\sqrt{2\pi}\sigma}\] <p>拉普拉斯分布和指数分布同理。</p> <h2 id="3-laplace机制">3. Laplace机制</h2> <p><strong>Definition 1 \((l_1-sensitivity\))：</strong>查询函数\(f\)的\(l_1\)敏感度表示相邻数据集输出的最大\(l_1\)距离。</p> \[\Delta f = \max_{D,D'}||f(D)-f(D')||_1\] <p><strong>Theorem 1</strong> \((Laplace Mechanism)\)：</p> \[M(D) = f(D)+Y\] <p><strong>Definition 3：</strong>噪声\(Y \sim L(0,\frac{\Delta f}{\epsilon})\)满足\((\epsilon,0)-differential　privacy.\)</p> <p>证明：</p> \[\begin{split} &amp; \ln \frac{P[M(D)=S]}{P[M(D')=S]} \\ = &amp;\ln\frac{\frac{\epsilon}{2\Delta f}e^{ \frac{\epsilon}{\Delta f}|f(D)|}}{ \frac{\epsilon}{2\Delta f}e^{ \frac{\epsilon}{\Delta f}|f(D')|}}\\ =&amp;{\frac{\epsilon}{\Delta f}(|f(D)|-|f(D')|)} \leq {\epsilon} \\ \therefore需满足&amp;\quad |f(D)|-|f(D')| \leq \Delta f \\ &amp;\quad |f(D)|-|f(D')| \leq \max_{D,D'}|f(D)-f(D')| \end{split}\] <p>该式满足绝对值不等式，因此\(Laplace(0, \frac{\Delta f}{\epsilon})\)满足\(\epsilon-\)差分隐私。</p> <h2 id="4-gaussian机制">4. Gaussian机制</h2> <p><strong>Definition 1 \((l_2-sensitivity\))：</strong>查询函数\(f\)的\(l_1\)敏感度表示相邻数据集输出的最大\(l_2\)距离。</p> \[\Delta f = \max_{D,D'}||f(D)-f(D')||_2\] <p><strong>Theorem 1</strong> \((Laplace Mechanism)：\)对于任意的\(\delta\in(0,1),\sigma&gt;\frac{\sqrt{2ln(1.25/ \delta)}\Delta f}{\epsilon}\),有噪声\(Y \sim N(0,\sigma^2)\)满足\((\epsilon,\delta)-differential　privacy.\)</p> \[P[M(D)\in S] \leq e^\epsilon P[M(D')\in S]+\delta\] <font size="4">证明：</font> \[\begin{split} &amp;|ln \frac{e^{-\frac{1}{2\sigma^2}x^2}}{e^{-\frac{1}{2\sigma^2}(x+\Delta f)^2}}|\\ =&amp;| {\frac{1}{2\sigma^2}(2x\Delta f+(\Delta f)^2)}| \leq \epsilon \\ \therefore \quad |x| \leq \frac{\sigma^2\epsilon}{\Delta f}-\frac{\Delta f}{2} \end{split}\] <p>令\(t=\frac{\sigma^2\epsilon}{\Delta f}-\frac{\Delta f}{2}\),当且仅当\(\|x\|\leq t\)时，该分布是满足DP的，而当\(\|x\|&gt;t\)时为隐私泄露，我们希望隐私泄露的概率小于\(\delta\),即：</p> \[P(|x|&gt;t)&lt;\delta\] \[P(x&gt;t)&lt;\frac{\delta}{2}\] <p>正太分布的上下界证明可参照<a href="https://www.johndcook.com/blog/norm-dist-bounds/" rel="external nofollow noopener" target="_blank">这里</a>. 以下证明其上界：</p> \[\begin{split} P(x&gt;t) &amp;= \frac{1}{\sqrt{2\pi}\sigma}\int_t^\infty e^{-\frac{x^2}{2\sigma^2}}dx \\ &amp;&lt; \frac{1}{\sqrt{2\pi}\sigma}\int_t^\infty \frac{x}{t} e^{-\frac{x^2}{2\sigma^2}}dx \quad 【因为x&gt;t】\\ &amp;=\frac{\sigma}{\sqrt{2\pi}t}e^{-\frac{t^2}{2\sigma^2}} \end{split}\] <p>那么问题转变为：</p> \[\begin{split} \frac{\sigma}{\sqrt{2\pi}t}e^{-\frac{t^2}{2\sigma^2}} &amp;&lt; \frac{\delta}{2} \\ \frac{t}{\sigma}e^{\frac{t^2}{2\sigma^2}} &amp;&gt; \frac{2}{\sqrt{2\pi}\delta} \\ \ln \frac{t}{\sigma} + \frac{t^2}{2\sigma^2} &amp;&gt; \ln\frac{2}{\sqrt{2\pi}\delta} \end{split}\] \[\begin{split} 将该式转换为\left\{\begin{matrix} \ln \frac{t}{\sigma} &amp; \geq 0\\ \frac{t^2}{2\sigma^2} &amp; &gt; \ln\frac{2}{\sqrt{2\pi}\delta} \end{matrix}\right. \end{split}\] <p>下面分别分析左边两项，由于\(t=\frac{\sigma^2\epsilon}{\Delta f}-\frac{\Delta f}{2}\)，若令\(\sigma=c\frac{\Delta f}{\epsilon}\),那么\(t=c\sigma-\frac{\Delta f}{2}\),因此：</p> \[\frac{t}{\sigma} = c-\frac{\Delta f}{2\sigma} = c-\frac{\epsilon}{2c}\] <p>这里\(\epsilon&lt;1,c\geq 1,\)</p> \[\ln(c-\frac{\epsilon}{2c}) &gt; \ln(c-\frac{1}{2})\geq 0\] \[\therefore c\geq\frac{3}{2}\] <p>第二项：</p> \[\begin{split} \frac{t^2}{2\sigma^2} &amp;=\frac{1}{2}(c-\frac{\epsilon}{2c})^2 \\ &amp;= \frac{1}{2}(c^2-\epsilon + \frac{\epsilon^2}{4c^2}) \end{split}\] <p>因为\(\epsilon&lt;1,c\geq\frac{3}{2}\),</p> \[\begin{split} c^2-\epsilon + \frac{\epsilon^2}{4c^2} &gt; c^2 - \frac{8}{9} &gt; 2\ln\frac{2}{\sqrt{2\pi}\delta} \end{split}\] \[c^2 &gt; \ln\frac{2}{\pi}e^{\frac{8}{9}}+2\ln\frac{1}{\delta}\] \[\because \ln\frac{2}{\pi}e^{\frac{8}{9}}&gt;1.25^2\] \[\therefore c^2&gt;2\ln\frac{1.25}{\delta}\] <p>上文中我们令\(\sigma=c\frac{\Delta f}{\epsilon}\),因此\(\sigma&gt;\frac{\sqrt{2\ln(1.25/ \delta)}\Delta f}{\epsilon}\).随机梯度下降中\(\sigma \geq c\frac{q \sqrt{T \ln(1/\delta)}}{\epsilon}\)【下次再证】。</p> <h2 id="5-指数机制">5. 指数机制</h2> <p><strong>Definition 1</strong> 选择一个查询\(r\),给定分值函数（score function）,指数机制以\(M(x,q,r)\)的概率输出结果\(x\)</p> \[M(x,q,r) = e^{\frac{\epsilon q(x,r)}{2\Delta q}}\] \[\Delta q = \max_{x,x'}||q(x,r)-q(x',r)||\] <p><strong>Theorem 1</strong> 指数分布\(E( \frac{\epsilon}{2\Delta q})\)满足\(\epsilon-DP\).</p> <p>证明：</p> <p>\(\quad\)这里是以一个概率输出结果，不是直接对数值数据进行加噪，因此需要归一化以概率表示：</p> \[\begin{split} \frac{P[M(x,q,R)=r]}{P[M(x',q,R)=r]} &amp;= \frac{\frac{ e^\frac{\epsilon q(x,r)}{2\Delta q}}{\sum_R e^\frac{ \epsilon q(x,R)}{2\Delta q}}}{\frac{ e^\frac{\epsilon q(x',r)}{2\Delta q}}{\sum_R e^\frac{ \epsilon q(x',R)}{2\Delta q}} } \\ &amp; = \frac{e^\frac{\epsilon q(x,r)}{2\Delta q}}{e^\frac{\epsilon q(x',r)}{2\Delta q}} \frac{\sum_R e^\frac{\epsilon q(x',R)}{2\Delta q}}{\sum_R e^\frac{\epsilon q(x,R)}{2\Delta q}} \end{split}\] <p>第一项</p> \[e^{\frac{\epsilon}{2\Delta q}(q(x,r)-q(x',r))} &lt; e^{\frac{\epsilon}{2}}\] <p>第二项</p> \[\frac{\sum_i e^\frac{\epsilon q(x',R_i)}{2\Delta q}}{\sum_i e^\frac{\epsilon q(x,R_i)}{2\Delta q}} = \frac{\sum_i e^\frac{\epsilon q(x,R_i)}{2\Delta q} e^\frac{\epsilon (q(x',R_i)-q(x,R_i))}{2\Delta q}} {\sum_i e^\frac{\epsilon q(x,R_i)}{2\Delta q}}\] \[\because e^\frac{\epsilon (q(x',R_i)-q(x,R_i))}{2\Delta q}\leq e^{\frac{\epsilon}{2}}\] \[\therefore \frac{\sum_i e^\frac{\epsilon q(x',R_i)}{2\Delta q}}{\sum_i e^\frac{\epsilon q(x,R_i)}{2\Delta q}} \leq e^{\frac{\epsilon}{2}}\] \[\therefore \frac{P[M(x,q,R)=r]}{P[M(x',q,R)=r]} \leq e^{\epsilon}\] <p>因此\(E( \frac{\epsilon}{2\Delta q})\)满足\(\epsilon-differential　privacy\).</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/Proximal-Descent/">近端梯度下降</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/Linear_Coupling/">梯度下降与镜像下降线性耦合</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/VarienceReduction/">Variance Reduction</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/Convergence/">梯度下降收敛速度</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/Primal/">Primal Dual Problem</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Tingting Liao. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>