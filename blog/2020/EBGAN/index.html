<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Energy-based GAN | Tingting Liao </title> <meta name="author" content="Tingting Liao"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tingtingliao.github.io/blog/2020/EBGAN/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Tingting</span> Liao </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Energy-based GAN</h1> <p class="post-meta"> August 07, 2020 • Tintin </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/tag/vae"> <i class="fa-solid fa-hashtag fa-sm"></i> VAE</a>   <a href="/blog/tag/gan"> <i class="fa-solid fa-hashtag fa-sm"></i> GAN</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <h2 id="0-evidence-lower-bound-elbo">0. Evidence Lower Bound ELBO</h2> <p>最大似然可以推导出最大ELBO</p> \[\begin{align} \log p(x) &amp;= \int_z q(z) \log p(x) dz \\ &amp;= \int_z q(z) \log \frac{p(x,z)}{p(z|x)} dz \\ &amp;= \int_z q(z) \log \frac{p(x,z)}{q(z)} \frac{q(z)}{p(z|x)}dz \\ &amp;= \int_z q(z) \log (\frac{p(x,z)}{q(z)}) dz+KL(q(z)||p(z|x)) \\ &amp;= L_b +KL(q(z)||p(z|x)) \\ \end{align}\] <p>记\(L_b = \int_z q(z) \log (\frac{p(x,z)}{q(z)}) dz\) 就是evidence lower bound, 当\(KL(q(z),p(z\| x))=0\)时，最大似然就等价于ELBO，最大似然就是最小化模型生成分布 \(p(z\|x)\) 和真实分布 \(q(z)\) 之间的KL距离。</p> <h2 id="1-vae">1. VAE</h2> <p>AE将输入encode成中间编码 \(z\) 再将其还原decode成 \(\hat{x}\), 它的局限性在于编码需要根据输入得到，随意输入一个中间编码生成图片可能会很奇怪。那么我们能否得到输入数据 \(X\)的分布\(p(x)\)，然后在 \(p(x)\)中采样生成图片即可。<strong>任何一个分布都可以看作是多个高斯分布的叠加</strong>。</p> \[p(x)=\int_z p(x|z)p(z)dz\\\] <p>和混合高斯不一样的是， \(z\) 服从连续分布。如果我们知道\(z\) 的分布那么就可以得到与输入近似的 \(\hat{x}\),这相当于是一个decode的过程， \(z\) 的分布则可以通过encode输入得到。有两个encoder，一个encoder输出均值 \(\mu\) ,另一个输出方差 \(\sigma\), 这样就能得到 \(p(z\|x)\)的分布 \(N(\mu, \sigma^2)\) ,从 \(p(z\|x)\)中采样得到 \(z\) . 这里有两个问题：</p> <ol> <li>\(z\) 为什么是从\(p(z\|x)\)中采样的而不是从 \(q(z)\)中采样的？</li> <li>采样得到的 \(z\)与真实数据的编码会有一定的误差如何解决？</li> </ol> <p><img src="https://pic3.zhimg.com/50/v2-975c73b5748459a9840341b5a7be3ab3_b.jpg" alt="img"></p> <p><strong>第一个问题：p(z|x)和 q(z)是同分布的.</strong></p> \[p(z) = \int p(z|x)p(x) dx=N(\mu, \sigma^2)\int p(x)dx = N(\mu, \sigma^2)\] <p><strong>第二个问题：假设\(q(z)\)理想情况下服从正态分布</strong> N(0,1) <strong>，让</strong> p(z|x) <strong>逼近正态分布，这样就能让采样的</strong> <strong>z</strong> <strong>接近理想编码分布。</strong></p> \[\min KL(p(z|x)||q(z))\] <p>VAE的优化目标是最小化 \(KL(p(x,z) \| q(x,z))\)，<strong>它等价于最大化ELBO</strong>.</p> \[\begin{align} KL(p(x,z) || q(x,z)) &amp; = \int \int p(x,z) \log \frac{p(x,z)}{q(x,z)}dzdx\\ &amp; = \int \int p(z|x)p(x) \log \frac{p(z|x)p(x)}{q(x|z)q(z)}dzdx\\ &amp; = E_{x\sim p(x)} [ \int_z p(z|x)\log \frac{p(z|x)p(x)}{q(x|z)q(z)}dz]\\ &amp; = E_{x\sim p(x)} [\int_z p(z|x)\log \frac{p(z|x)}{ q(z)}dz + \int_z p(z|x)\log \frac{p(x)}{ q(x|z)}dz ]\\ &amp; = E_{x\sim p(x)} [KL( p(z|x)||q(z))-\int_z p(z|x) \log q(x|z)dz + p(x) ]\\ &amp; \rightarrow KL( p(z|x)||q(z))-\int_z p(z|x) \log q(x|z)dz + C \\ &amp; \rightarrow KL( p(z|x)||N(0,1))-E_{z \sim p(z|x) }[\log q(x|z)] \end{align}\] <p>第一项为KL正则项，第二项为重构损失(给定编码器 \(p(z\|x)\)的情况下解码器\(p(x\|z)\)的值尽可能高）。所以VAE可以看作是加了KL正则的Auto-Encoder。</p> <p><strong>VAE在重构损失的基础上，最大化ELBO，它的目的是最大化似然，等价于最小化生成分布 \(p(z\|x)\) 和编码真实分布 \(q(z)\) 之间的KL距离，并假设 \(q(z)\) 服从标准正态分布。</strong></p> <h2 id="2-energy-based-gan">2. Energy-Based GAN</h2> <p><img src="https://picb.zhimg.com/80/v2-60151c07ecffaeb33743679371d2cbcc_720w.jpg" alt="img"><em>**</em></p> <p>生成器 \(G\) 将 \(z\) 作为输入， 输出 \(\hat{x}= G(z)\)</p> <p>判别器 \(D\) 是一个Auto-encoder, 输出重构误差 \(D(x)=\|Dec(Enc(x))-x\|\)。那么 \(D\) 目标函数应该让 \(D(x)\) 尽可能大，让 \(D(G(z))\) 尽可能小。\(G\) 的目标是最大化 \(D(G(z))\)</p> \[\begin{align} L_D(x,z)&amp;=D(x)-D(G(z))\\ L_G(z)&amp;=D(G(z)) \end{align}\] <p><strong>那么这和能量有什么关系？</strong> 生成器就是一个能量函数，输出的能量值 \(D(x)\) 低就将它分类为real, 能量值高就分类为fake, 对应了上面的重构损失。</p> <h3 id="21-能量判别器">2.1 能量判别器</h3> <p>定义能量函数 \(U_{\theta}(x), \theta\)是能量函数的参数，系统总能量 \(Z_\theta = \int e^{-U_{\theta}(x)}dx\), 样本概率和能量之间关系表示为：\(p_{\theta}(x) = \frac{e^{-U_{\theta}(x)}}{Z_{\theta}} \propto e^{-U_{\theta}(x)}\),最大似然目标函数</p> \[\max_\theta \prod_{x\in X} p_\theta(x) \\\] <p>上式取对数除以 \(N\) （输入样本个数），目标函数变成 \(\max_\theta E_{x\sim p_D} [\log p_\theta(x) ],p_D\)表示 \(X\) 的真实分布。</p> \[-\log p_\theta(x) = U_\theta(x) + \log Z_\theta \\\] \[\begin{aligned} -\frac{\partial \log p_\theta(x) }{\partial\theta }&amp;= \frac{\partial U_\theta(x)}{\partial\theta } + \frac{1}{Z_\theta }\frac{\partial Z_\theta }{\partial \theta}\\ &amp;= \frac{\partial U_\theta(x)}{\partial\theta } + \frac{1}{Z_\theta } \int -e^{-U_\theta(x)} \frac{\partial U_\theta(x)}{\partial \theta }dx\\ &amp;= \frac{\partial U_\theta(x)}{\partial\theta } - E_{x\sim p(x)}[\frac{\partial U_\theta(x)}{\partial \theta}] \end{aligned}\\\] <p>最大然就变成了最小化下式：</p> \[\begin{aligned} &amp; \frac{\partial E_{x\sim p_D} [-\log p_\theta(x) ] }{\partial \theta} \\ \rightarrow &amp; E_{x\sim p_D} [\frac{\partial U_\theta(x)}{\partial\theta }] - E_{x\sim p_{\theta}(x)}[\frac{\partial U_\theta(x)}{\partial \theta}] \end{aligned}\] <p>\(p_D\)是真实分布, \(p_\theta\)是模型近似出来的假分布.最大似然就变成找到一组最优的参数使得真实分布和假分布之间的能量\(U_\theta(x)\)越近越好。目标函数为：</p> \[\begin{aligned} &amp;\min_\theta E_{x\sim p_D} [U_\theta(x)] - E_{x\sim p_{\theta}(x)}[U_\theta(x)] \\ \rightarrow &amp;\min_\theta E_{x\sim p_D} [D(x)] - E_{x\sim p_{\theta}(x)}[D(x)] \\ \end{aligned}\] <p>可以看到可以用生成器 \(D\) 来替代能量函数 \(U_\theta\) 。<strong>但是这个公式和EBGAN的目标函数不完全一样，因为用判别其作为能量函数之后， \(\theta\) 应该与 \(D\) 的参数 \(W\) 是一致的, 所以 \(x\sim p_\theta (x)\) 不能直接替换成生成器 \(p_G\) 的采样。那么如何从 \(p_\theta\) 中采样 \(x\) ,即如何得到假样本？</strong></p> <h3 id="22--最大熵生成器">2.2 最大熵生成器</h3> <p>用生成器 \(G\) 的生成分布 \(p_G\) 近似替代 \(p_\theta\)，并使两分布距离尽可能的小以减小近似误差</p> \[\begin{align} \min_G KL(p_G||p_\theta) &amp;= p_G \log \frac{p_G}{p_\theta}\\ &amp;= p_G \log p_G - p_G \log p_\theta\\ &amp;= -H[p_G] - E_{p_G}[\log p_\theta]\\ &amp;= -H[p_G] + E_{p_G}[U_\theta(x)] +\log Z_\theta \end{align}\] <p>上式中\(\log Z_\theta\)和\(G\)无关，那么生成器的目标函数就变成了,从\(p_G\)中采样\(x\)相当于是从先验分布\(p(z)\)采样\(z\)经过生成器得到的\(G(z)\):</p> \[\begin{align} &amp;\min_G -H[p_G] + E_{x\sim p_G}[U_\theta(x)]\\ \rightarrow &amp;\min_G -H[p_G] + E_{z\sim p(z)}[U_\theta(G(z))] \end{align}\] <p>EBGAN的生成器目标函数是最小化生成样本的能量，<font color="blue">这里在EBGAN的基础上多了一项，最大化生成分布的熵 </font>\(H[p_G]\) 。</p> <p>接下来问题是<strong>如何计算 \(H[p_G]\) ? 这部分证明需要互信息(mutual information)的信息。</strong></p> <h3 id="23-互信息mutual-information">2.3 互信息(mutual information)</h3> <p><strong>互信息是两个变量之间共有的信息</strong>。定义为：</p> \[\begin{align} I(X,Y)&amp;=\int_X \int_Y p(X,Y)\log \frac{p(X,Y)}{p(X)p(Y)}\quad(*)\\ &amp;=KL(p(X,Y)||p(X)p(Y)) \end{align}\] <p>它有以下4条性质：</p> <p>1）当\(X,Y\)相互独立时，\(p(X,Y) =p(X)p(Y),I(X,Y)=0\)互信息为零</p> <p>2）当\(X,Y\)不独立时，\((*)\)式可以推导简化为：</p> \[I(X,Y)= H(X) - H(X|Y)\] <p>\(H(X)\)为\(X\)的熵，即\(X\)的不确定度，</p> <p>\(H(X\|Y)\)为已知 \(Y\) 的情况下\(X\) 的不确定度，</p> <p>\(I(X,Y)\)为已知 \(Y\) 的情况下\(X\) 不确定度减少的部分，减少的这部分就是 \(X\)和\(Y\) 的共同信息产生的。或者从 $KL$ 的角度也可以理解为，\(I(X,Y)\) 计算了\((X,Y)\)的联合分布与两者边缘分布乘积之间的\(KL\) 距离，也就是\(X,Y\) 的共有部分。</p> <p>3）\(I(X,Y)\geq 0\)</p> <p>4) 当\(X,Y\)知道一个就能推出另一个时，\(I(X,Y)=H(X)=H(Y)\)</p> <p>生成器中，我们希望输入和输出之间的互信息 \(I(G(Z),Z)\) 尽可能的大，根据性质4）可以得到</p> \[\begin{aligned} I(G(Z),Z) &amp;= H(G(Z)) - H(G(Z)|Z)\\ &amp;= H(G(Z)) \end{aligned}\] <p>最大化互信息 \(I(G(Z),Z)\) 等价于最大熵 \(H(p_G)\)，我们用 \(KL(p(\hat{x}\|z)p(z)\|p(\hat{x})p(z))\) 来优化。但是\(KL\) 散度是没有上限的，更好的做法是用\(Jensen-Shanno\) 散度，\(JSD\)是对称的\(KL\)散度，它有上界而且可以达到同样的效果。而在GAN Theory理论推导中，判别器的目标函数等价于最大化\(JS\)</p> \[\begin{align} &amp;\max_D E_{x\sim p_D}[\log D(x)] + E_{x\sim p_G}[\log (1-D(x))]\\ \rightarrow &amp; \max JSD(p_D,p_G) \end{align}\] <p>因此将 \(p_D,p_G\) 换成 \(p(\hat{x}\|z)p(z),p(\hat{x})p(z)\) 目标函数就变成：</p> \[\begin{align} I_{JSD}=\max_D E_{(x,z)\sim p(\hat{x}|z)p(z)}[\log D(x,z)] + E_{(x,z)\sim p(\hat{x})p(z)}[\log (1-D(x,z))]\\ \end{align}\] <p>综上GAN的能量模型损失函数为：</p> \[\begin{align} L_G &amp;= -I_{JSD}(G(Z),Z) + E_{z\sim p(z)}[D(G(z))]\\ L_D&amp;= E_{x\sim p_D}[D(x)]-E_{z\sim p(z)}D(G(z)) \end{align}\] </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/BreGAN/">Incorporate Bregman Divergence to generalize fGAN</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/GAN/">GAN Review</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/MeanFieldTheory/">Mean Field Theory Solution of the Ising Model</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/Proximal-Descent/">近端梯度下降</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/FasterRCNN/">Faster RCNN</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Tingting Liao. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>