<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> GAN Review | Tingting Liao </title> <meta name="author" content="Tingting Liao"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tingtingliao.github.io/blog/2020/GAN/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Tingting</span> Liao </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">GAN Review</h1> <p class="post-meta"> June 24, 2020 • Tintin </p> <p class="post-tags"> <a href="/blog/2020"> <i class="fa-solid fa-calendar fa-sm"></i> 2020 </a>   ·   <a href="/blog/tag/gan"> <i class="fa-solid fa-hashtag fa-sm"></i> GAN</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <h2 id="一introduction">一、Introduction</h2> <table> <thead> <tr> <th style="text-align: center">Time</th> <th style="text-align: center">Method</th> <th style="text-align: center">Describe</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(14年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1406.2661.pdf" rel="external nofollow noopener" target="_blank">\(GANs\)</a></td> <td style="text-align: center">生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(14年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1411.1784.pdf" rel="external nofollow noopener" target="_blank">\(CGAN\)</a></td> <td style="text-align: center">条件生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(15年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1506.05751.pdf" rel="external nofollow noopener" target="_blank">\(LAPGAN\)</a></td> <td style="text-align: center">拉普拉斯金字塔GAN</td> </tr> <tr> <td style="text-align: center">\(15年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1511.06434.pdf" rel="external nofollow noopener" target="_blank">\(DCGAN\)</a></td> <td style="text-align: center">深度卷积生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(15年12月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1512.09300.pdf" rel="external nofollow noopener" target="_blank">\(VAEGAN\)</a></td> <td style="text-align: center">变分自编码GAN</td> </tr> <tr> <td style="text-align: center">\(16年05月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1605.09782.pdf" rel="external nofollow noopener" target="_blank">\(BiGAN\)</a></td> <td style="text-align: center">双向生成生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1606.07536.pdf" rel="external nofollow noopener" target="_blank">\(CoGAN\)</a></td> <td style="text-align: center">耦合生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1606.00709.pdf" rel="external nofollow noopener" target="_blank">\(fGAN\)</a></td> <td style="text-align: center">f-散度生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1606.03498.pdf" rel="external nofollow noopener" target="_blank">\(ImprovedDCGAN\)</a></td> <td style="text-align: center">提升DCGAN</td> </tr> <tr> <td style="text-align: center">\(16年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1606.03657.pdf" rel="external nofollow noopener" target="_blank">\(InfoGAN\)</a></td> <td style="text-align: center">互信息生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年09月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1609.03126.pdf" rel="external nofollow noopener" target="_blank">\(EBGAN\)</a></td> <td style="text-align: center">基于能量的生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年09月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1609.04802.pdf" rel="external nofollow noopener" target="_blank">\(SRGAN\)</a></td> <td style="text-align: center">超分辨率生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1611.04076.pdf" rel="external nofollow noopener" target="_blank">\(LSGAN\)</a></td> <td style="text-align: center">最小二乘生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年12月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1612.03242.pdf" rel="external nofollow noopener" target="_blank">\(StackGAN\)</a></td> <td style="text-align: center">堆栈式生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(17年01月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1701.07875.pdf" rel="external nofollow noopener" target="_blank">\(WGAN\)</a></td> <td style="text-align: center">Wasserstein距离GAN</td> </tr> <tr> <td style="text-align: center">\(17年03月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1703.10717.pdf" rel="external nofollow noopener" target="_blank">\(BEGAN\)</a></td> <td style="text-align: center">边界均衡生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(17年03月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1703.10593.pdf" rel="external nofollow noopener" target="_blank">\(CycleGAN\)</a></td> <td style="text-align: center">循环生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(17年03月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1703.02291.pdf" rel="external nofollow noopener" target="_blank">\(TripleGAN\)</a></td> <td style="text-align: center">三部分生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(17年04月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1704.00028.pdf" rel="external nofollow noopener" target="_blank">\(WGAN-GP\)</a></td> <td style="text-align: center">加强版WGAN</td> </tr> <tr> <td style="text-align: center">\(17年05月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1705.07215.pdf" rel="external nofollow noopener" target="_blank">\(DRAGAN\)</a></td> <td style="text-align: center">深度回归分析GAN</td> </tr> <tr> <td style="text-align: center">\(17年05月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1705.07215.pdf" rel="external nofollow noopener" target="_blank">\(DRAGAN\)</a></td> <td style="text-align: center">深度回归分析GAN</td> </tr> <tr> <td style="text-align: center">\(17年10月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1710.10196.pdf" rel="external nofollow noopener" target="_blank">\(PGGAN\)</a></td> <td style="text-align: center">渐进生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(17年10月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1710.10916.pdf" rel="external nofollow noopener" target="_blank">\(StackGAN++\)</a></td> <td style="text-align: center">提升的堆栈式GAN</td> </tr> <tr> <td style="text-align: center">\(17年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1711.09020.pdf" rel="external nofollow noopener" target="_blank">\(StarGAN\)</a></td> <td style="text-align: center">星型结构GAN</td> </tr> <tr> <td style="text-align: center">\(17年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1711.05139.pdf" rel="external nofollow noopener" target="_blank">\(XGAN\)</a></td> <td style="text-align: center">X型结构GAN</td> </tr> <tr> <td style="text-align: center">\(17年12月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1712.06909.pdf" rel="external nofollow noopener" target="_blank">\(ComboGAN\)</a></td> <td style="text-align: center">合一式生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(18年02月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1802.05957.pdf" rel="external nofollow noopener" target="_blank">\(SNGAN\)</a></td> <td style="text-align: center">频谱归一化生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(18年05月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1805.08318.pdf" rel="external nofollow noopener" target="_blank">\(SAGAN\)</a></td> <td style="text-align: center">自注意力生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(18年07月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1807.00734.pdf" rel="external nofollow noopener" target="_blank">\(RGAN\)</a></td> <td style="text-align: center">相对生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(18年09月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1809.11096.pdf" rel="external nofollow noopener" target="_blank">\(BigGAN\)</a></td> <td style="text-align: center">大规模的生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(18年12月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1812.04948.pdf" rel="external nofollow noopener" target="_blank">\(StyleGAN\)</a></td> <td style="text-align: center">基于样式的生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(19年03月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1903.02271.pdf" rel="external nofollow noopener" target="_blank">\(S3GAN\)</a></td> <td style="text-align: center">更少标签的生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(19年03月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1903.07291.pdf" rel="external nofollow noopener" target="_blank">\(GuaGAN\)</a></td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: center">\(19年05月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1905.01164.pdf" rel="external nofollow noopener" target="_blank">\(SinGAN\)</a></td> <td style="text-align: center">单幅自然图像学习的非条件生成模型</td> </tr> <tr> <td style="text-align: center">\(19年07月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1907.02544.pdf" rel="external nofollow noopener" target="_blank">\(BigBiGAN\)</a></td> <td style="text-align: center">超大规模生成对抗模型</td> </tr> <tr> <td style="text-align: center">\(19年08月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1908.03835.pdf" rel="external nofollow noopener" target="_blank">\(AutoGAN\)</a></td> <td style="text-align: center">自动搜索生成对抗网络的结构</td> </tr> <tr> <td style="text-align: center">\(CVPR2020\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1903.06048.pdf" rel="external nofollow noopener" target="_blank">\(MSG-GAN\)</a></td> <td style="text-align: center">用于稳定图像合成的多尺度梯度GAN</td> </tr> <tr> <td style="text-align: center">\(2019年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1911.12287.pdf" rel="external nofollow noopener" target="_blank">\(YLG\)</a></td> <td style="text-align: center">用于稳定图像合成的多尺度梯度GAN</td> </tr> </tbody> </table> <p><img src="/img/GAN/GANs.jpg" alt=""></p> <h2 id="二基于loss的改进">二、基于Loss的改进</h2> <h3 id="0-基础知识">0. 基础知识</h3> \[KL(p_1||p_2)=E_{X\sim p_1}\log\frac{p_1}{p_2}\\ JS(p_1||p_2)=\frac{1}{2}KL(p_1||\frac{p_1+p_2}{2})+\frac{1}{2}KL(p_2||\frac{p_1+p_2}{2})\] <h3 id="1最大似然推导出kl散度">1.最大似然推导出KL散度</h3> <p>从真实分布 \(P_{data}(x)\) 抽样部分数据 \(\{x^1,x^2,...,x^m\}\),最大似然就是找到一组 \(\theta\) 使得抽样的样本概率最大,\(\theta\) 是模拟真实分布的参数。</p> \[\max_\theta L=\prod_{i=1}^mP_G(x^i,\theta)\] <p>根据取对数推导可以得出最大似然等价于最小化真实分布与生成器分布的\(KL\)距离。</p> \[\min_{\theta} KL(P_{data}||P_{G})\] <p><strong>\(KL\)散度问题：不是对称的衡量</strong></p> <ul> <li>当\(P_g(x)\rightarrow 0\)而\(P_r(x)\rightarrow 1\)时，\(KL(P_g \|\| P_r)\rightarrow 0\)</li> <li>当\(P_g(x)\rightarrow 1\)而\(P_r(x)\rightarrow 0\)时，\(KL(P_g \|\| P_r) \rightarrow +\infty\)</li> </ul> <p>这就好比将 \(A\) 和 \(B\) 互换位置， \(D_{KL}(A,B)\) 和 \(D_{KL}(B,A)\) 距离不相等。而<strong>JSDiv</strong>能够很好解决这个问题。</p> <h3 id="2gan">2.GAN</h3> \[\min_G \max_D V(G,D) = E_{x\sim P_{data}}[logD(x)] + E_{x\sim P_{G}}[log(1-D(x))]\] <p>判别器 \(D\) 的目标函数可以推导出\(JS Div\)(推导略)</p> \[\max_D V(G,D) = E_{x\sim P_{data}}[logD(x)] + E_{x\sim P_{G}}[log(1-D(x))] \\ =-2log2 + 2JSD(P_{data}||P_G)\] <p>其中\(D^*(x)=\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}\),优化生成器\(G\)则变为最小化真实分布与生成器分布的\(JS\)距离.</p> <p>在固定判别器为 \(D^*(x)\) 训练 \(G\) 时候，\(JSDiv\)存在两个问题：</p> <p>①训练前期，真实分布和生成分布 <strong>重叠度很低时，JSDiv无法衡量两个分布之间的距离</strong>。举个例子：两个不重叠的圆\(A\)和\(B\)，无论圆心的距离是无穷远还是\(AB\)刚好相切，\(JS(A,B)\)都不变。如下图当两分布overlap很小Distance很大时，JSDiv很大，梯度更新几乎为0，这导致前期训练很慢效率不高。</p> <p><img src="/img/GAN/GAN%20gradient.jpg" alt=""></p> <p>② <strong>优化 \(G\) 时不再是 JS Div而主要是Reverse KL Div，导致mode dropping问题，生成的图片缺乏多样性。</strong> 训练过程\(G\)过程中，损失函数 \(-E_{x\sim P_{G}}log[D(x)]\),根据推导这一项等价于Reverse KL Div。</p> \[\begin{align} &amp;-E_{X\sim P_{G}}log[D^*(x)]\\ =&amp; KL(P_G||P_{data})-2JS(P_{data}||P_{G})+2\log2+E_{x\sim P_x}log[D^*(x)] \end{align}\] <p>后两项为常数，只看前两项，由于 \(JS(P_{data} \|\| P_{G})\) 范围为 \([0,\log2]\)对结果几乎无影响，\(KL(P_G \|\| P_{data})\) 占主导，它为逆 \(KL(P_{data} \|\| P_G)\)。</p> <p><img src="/img/GAN/Reverse%20KL.jpg" alt=""></p> <p>逆\(KL\)会造成模式丢失和模式坍塌问题。真实数据分布一般都存在多种特征模式如肤色、发型、性别等，如上图蓝色线为双模式分布， \(q\) 为生成分布，\(KL\)会让\(q\) 包含两个模式，而reverse KL的\(q\)分布丢失了一部分的mode, 实际生成图片就会缺乏多样性。</p> <h3 id="3wgan">3.WGAN</h3> <p>WGAN就很好解决了上述两个问题，它采用Earth Move（EM）距离（也叫Wasserstein距离）作为损失度量：</p> \[W(P_{data}, P_G)=\inf_{ \gamma\in \prod(P_{data}, P_G)} E_{(x,y)\sim \gamma}||x-y||\] <p>上述式子表示， \(P_{data}\) 为真实分布，穷举生成器所有可能的分布\(P_G , \prod(P_{data}, P_G)\)为所有联合分布集合, 取一组最优的联合分布 \(\gamma\),使真实分布和生成分布产生的 \(x,y\) 平均距离最小。优点：即使两个分布不重叠依然能够反映它们之间的距离，Was距离平滑可导，即使真假分布不重叠更新的梯度也是有意义的。</p> <p>但是上式求解很麻烦，需要穷举所有的 \(P_G\) 再取最优，作者将其转化为下式：</p> \[V(G,D)=\max_{D\in 1-Lipschitz} \{E_{x\sim P_{data}}[D(x)]-E_{x\sim P_{G}}[D(x)]\}\qquad (*)\\ ||f(x_1)-f(x_2)||\leq K||x_1-x_2||\] <p>\(D\)网络将从真假分布抽样的\(x\)映射到一个空间中，在这个空间他们的\(L_1\)距离最大。并且\(D\)满足1-Lipschitz连续，即一阶导上界为 \(1\). WGAN相比于GAN做了以下改动：</p> <ul> <li>把\(D\)参数的绝对值截断到不超过常数c（满足1-Lipschitz条件）</li> <li>生成器和判别器的loss不取log(Was距离)</li> <li>判别器最后一层去掉sigmoid（\(D\)不再是判别器而是距离的回归网络）</li> <li>不要用基于动量的优化算法包括momentum和Adam，推荐RMSProp/SGD（实验trick）</li> </ul> <p>● <strong>思考</strong></p> <p><strong>第一点，</strong>式 \((*)\)字面上理解是真实分布和生成分布生成图片经过判别器均值的L1距离， \(D(x)\) 可以看作一个映射函数mapping function。先举个例子，看一下马氏距离：</p> <p>马氏距离解释：将输入映射到另外一个空间，在这个空间中它们的欧式距离最小。</p> \[\begin{align} &amp;(X-Y)^TM(X-Y)\\ =&amp; (X-Y)^TW^TW(X-Y)\qquad M=W^TW\\ =&amp;(WX-WY)^T(WX-WY) \end{align}\] <p>\(X,Y\) 为 \(d\) 维向量， \(M\) 为对角正定矩阵，表示每一维的权重系数，因为 \(M\) 正定可以开根号分解为矩阵 \(W\) ，再将\(W\)放入阔号里马氏距离又变成特殊的欧式距离，而 W 矩阵可以看作是对 \(X,Y\) 的线性变换，通过一层的FC网络即可实现。将矩阵 \(W\) 扩展为非线性就是多层神经网络， \(W\) 更加general的意义就是一个mapping function \(f(·)\)，原始的输入通过 \(f\) 能够更加可分。而判别器 D 实际上也是一个函数映射。</p> <p><strong>第二点，能否将 D(x) 看作距离的度量函数</strong>，也就是将 \(D(x)\) 看作为一种divergence，\(D(x)\)可以为任意的divergence，我们只需定义一个通用的divergence损失就能训练出\(D(x)\)。我们知道Bregman divergence包含了对一切距离的定义，它的几何思想为：两点距离为一阶泰勒展开的差。</p> \[d_{\varphi}(x,y) = \varphi(x)-(\varphi(y)+\triangledown \varphi(y)(y-x))\] <p>如欧式距离\(\varphi(x)=x^2,d_\varphi(x,y) = x^2-y^2-2y (y-x))=(x-y)^2,\varphi\)选取不同表达式表示不同度量方式。具体如下图。</p> <p><img src="/img/GAN/BregmanDiv.png" alt=""></p> <p>可以结合Bregman divergence，令 \(D(x)\equiv\varphi(x)\) ,判别器的目标函数为:</p> \[\max_D E_{(x,y)\sim (P_{data}, P_G)}[D(x)-D(y)-\triangledown D(y)(x-y)]\] <p>这样就能通过 \(d_\varphi(x,y)\)训练出 \(\varphi(x)\) . 上式距离等价于WGAN判别器目标函数额外加上 \(\triangledown D(y)(x-y)\)，这也解释了为什么WGAN需要满足Lipchitz连续限制一阶导的大小，我觉得也正是这一点导致了用加速算法（momentum Adam）loss会崩掉。从Bregman的角度就无需再对一阶导进行限制。</p> <p>相关论文：b-GAN BreGMN</p> <h3 id="4-wgan-gp">4. WGAN-GP</h3> <p><strong>解决问题</strong>: WGAN未能将D真的限制在1-Lipschitz内。</p> \[\max_D E_{x\sim P_{data}}[D(x)] - E_{x\sim P_{G}}[D(x)] -\lambda\int_{x}max(0,||\triangledown_xD(x)-1||)dx\] <p><strong>核心思想</strong>：WGAN-GP为判别器目标函数增加对D约束： \(\max_D E_{x\sim P_{data}}[D(x)] - E_{x\sim P_{G}}[D(x)] -\lambda\int_{x}max(0,||\triangledown_xD(x)-1||)dx\)<br> 这个表达式的问题在于，前两项都是均值期望，添加的第三项是积分，直接导致第三项惩罚过高。于是作者将其改为下式，惩罚项改为在真假分布之间抽样计算梯度是否小于1. （为什么不直接给上式第三项加 \(1/N\) ？)</p> <p><img src="/img/GAN/WGAN-GP.png" alt=""></p> <p>作者发现 \(\| \| \triangledown_xD(x)\|\|\) 越接近 1 ，训练得越快，效果也越好，于是不表达式直接改成：</p> \[\max_D E_{x\sim P_{data}}[D(x)] - E_{x\sim P_{G}}[D(x)] -\lambda E_{x\sim P_{penalty}} [(||\triangledown_xD(x)||-1)^2]dx\] <p><strong>WGAN-PG问题：① 没有从根本上解决1-Lipschitz问题</strong>。让 \(\|\|\triangledown_x D(x)\|\|\) 尽量接近 1，并没有真的将\(\|\| \triangledown_xD(x)\|\|\)限制在小于等于1内。</p> <p><strong>②\(P_{penalty}\)可能改变了原始 \(P_G\)向\(P_{data}\)移动的方向。</strong></p> <h3 id="5-f-gan">5. f-GAN</h3> <p>生成器的目标其实是最小化真实分布与生成器分布之间的距离：</p> \[\min_G Div(P_G, P_{data})\] <p><strong>fGAN提出的问题是：能否用一种通用的框架表示所有可能的距离形式？</strong>fGAN提出了f-Divergence用 \(D_f\) 表示</p> \[D_f (P||Q)=\int_{x}q(x)f(\frac{p(x)}{q(x)})dx\\\] <p>其中函数\(f\)为凸函数且\(f(1)=0\) . \(f\) 选取不同的函数, \(D_f\)表示不同的Divergence</p> \[\begin{array}[b] {|c|c|} \hline f(x) &amp; D_f (p||q)&amp; Divergence\\ \hline x\log(x) &amp; \int_{x}p(x)log(\frac{p(x)}{q(x)}) &amp; KL \\ \hline -\log(x) &amp; \int_{x}q(x)log(\frac{q(x)}{p(x)}) &amp; 逆KL \\ \hline (x-1)^2 &amp; \int_{x}\frac{(p(x)-q(x))^2}{q(x)} &amp; Chi \:Square \\ \hline \end{array}\] <p>以上是生成器G的目标函数,对于判别器D，再根据Fenchel共轭可以推导出（1）对应的形式：</p> \[\max_D E_{x\sim P_{data}}[D(x)] - E_{x\sim P_{G}}[f^*(D(x))] \\\] <p>综上，fGAN的目标函数为：</p> \[\begin{align} &amp;\min_G\max_D E_{x\sim P_{data}}[D(x)] - E_{x\sim P_{G}}[f^*(D(x))] \\ =&amp;\min_G\max_D D_f(P_{data}||P_G) \end{align}\] <h3 id="6-geometric-gan">6. Geometric GAN</h3> <p>核心思想：将SVM的分割超平面思想运用在GAN上。</p> \[\begin{align} L_D&amp;=E_{x\sim P_r}[1-D(x)]_+ + E_{z\sim P_z}[1+D(G(z))]_+ \\ L_G&amp;= -E_{z\sim P_z}D(G(z)) \end{align}\] <p><img src="/img/GAN/Geometric%20GAN.png" alt=""></p> <h3 id="7-sphere-gan">7. Sphere GAN</h3> <p><a href="http://cau.ac.kr/~jskwon/paper/SphereGAN_CVPR2019.pdf" rel="external nofollow noopener" target="_blank">CVPR2019 Oral Sphere Generative Adversarial Network Based on Geometric Moment Matching </a></p> \[\min_G \max_D \sum_r E_x[d_s^r(N,D(x))]-\sum_r E_z[d_s^r(N,D(G(z)))]\] <p>WGAN中 \(D(x)\) 将输入映射为一个数值 \(D: x\in \boldsymbol{\chi}\rightarrow \mathbb{R}\) , 判别器求一维的欧式距离。</p> \[\max_D E_x[D(x)]-E_z[D(G(z))]\] <p>Sphere GAN将 其扩展为求高维的欧式距离， \(D: x\in \boldsymbol{\chi}\rightarrow \mathbb{S}^n\),D将输入映射为一个向量。下面以二维为例：</p> <p>①将点映射到球面上。</p> <p>球心为原点，球半径为1，根据相似三角形可得点在球面上的坐标。</p> \[\prod (p)=(x,y)=(\frac{2p}{||p||^2+1}, \frac{||p||^2-1}{||p||^2+1})\] <p><img src="/img/GAN/SphereGAN.jpg" alt=""></p> <p>②计算球面上点的距离。</p> <p>如图，绿点真分布 \(D(x)\) ，紫点假分布 \(D(G(z))\) ， \(N\)为球的北极坐标。 \(d_s\)计算真假分布到 \(N\)的距离 \(d_s^r(N,D(x)) , d_s^r(N,D(G(z)))\) 。</p> \[d_s(\prod(p),\prod(q))=\arccos(\frac{||p||^2||q||^2-||p||^2-||q||^2+4p·q+1}{(||p||^2+1)(||q||^2+1)})\] <p><img src="/img/GAN/SphereGAN%202.jpg" alt=""></p> <h3 id="8-realness-gan">8. Realness GAN</h3> <p><a href="https://openreview.net/pdf?id=B1lPaCNtPB" rel="external nofollow noopener" target="_blank">ICLR2020 REAL OR NOT REAL, THAT IS THE QUESTION </a></p> <p><a href="https://zhuanlan.zhihu.com/p/105171680" rel="external nofollow noopener" target="_blank">原作者知乎回答</a></p> <p>Original GAN目标表达式</p> \[\min_G\max_D E_{x\sim P_{data}}[\log (D(x)-0)]+E_{x\sim P_G}[\log(1-D(x))]\] <p>D的目标是让 \(D(x_{real})\) 靠近0，\(D(x_{fake})\)靠近1; G目标是\(D(x_{fake})\)靠近0。这样可以将“0”和“1”看作是真假分布的锚，设真锚为 \(A_1\) , 伪锚为 \(A_0\)，RealnessGAN目标函数为：</p> \[\max_G\min_D E_{x\sim P_{data}}[D_{KL}(A_1||D(x))]+E_{x\sim P_G}[D_{KL}(A_0||D(x))]\] <p>D: 最小化真图片与真锚、伪图片与伪锚的KL-divergence。</p> <p>G: 最大化伪图片与伪锚的KL-divergence(Original GAN是最小化伪图片和真锚距离)</p> <p>作者发现单纯最大化伪图片与伪锚KL距离效果并不好，因为它只是让图片看起来不那么假，而不能保证它足够真。因此加了一项小化伪图片和真锚距离，这样生成图片的真实度大大提高。</p> \[\min_G E_{z\sim P_G}[D_{KL}(A_1||D(G(z)))]-E_{z\sim P_G}[D_{KL}(A_0||D(G(z)))]\] <h2 id="三基于architecture的改进">三、基于Architecture的改进</h2> <h3 id="1-deep-convolutional-gandcgan">1. Deep Convolutional GAN(DCGAN)</h3> <p>DCGAN和GAN原理一样，只是把G和D换成CNN。DCGAN对卷积神经网络做了一些改变：</p> <p>· 取消所有pooling层。G网络中用微步幅卷积，D中用步幅卷积 · D和G中均使用batch normalization · 去掉FC层，使网络变成全卷积网络 · G网络中使用 ReLU 作为激活函数，最后一层使用 tanh · D网络中使用 LeakyReLU 作为激活函数</p> <h3 id="2-boundary-equllibrlum-ganbegan">2. Boundary Equllibrlum GAN(BEGAN)</h3> <p>针对问题：</p> <p>· D网络用Autoencoder不用classification网络。论文证明了在Auto encoder下损失函数和Wasserterin距离是等价的。 · 引入超参数 \(\gamma=\frac{E[L(G(z))]}{E[L(x)]}\) 平衡图像的多样性。</p> <h3 id="3-progressive-ganprogan">3. Progressive GAN(ProGAN)</h3> <p><img src="/img/GAN/proGAN.jpg" alt=""></p> <p><strong>针对问题</strong>：生成超高分辨率的清晰图像。</p> <p><strong>核心技术</strong>：渐进式增长GAN随着训练的进行，网络层数逐渐增加。一开始学习低分辨率4×4的图片生成，逐渐加深网络，学习更高分辨率的图片，最终不断更新直到学习1024×1024图片生成。速度也比传统GAN提升很多。</p> <h3 id="4-self-attention-gan-sagan">4. Self-Attention GAN (SAGAN)</h3> <p><strong>针对问题</strong>：卷积网络感受野的限制使其无法获取大范围的结构信息，例如人脸鼻子发生偏移或眼睛不对称。如何在不牺牲计算量的情况下，获取图像的全局信息？</p> <p><strong>核心思想</strong>：引入Attention，通过计算图像中任意两个像素点之间关系，获取图像的全局几何特征。 <img src="/img/GAN/SAGAN.jpg" alt=""></p> <h3 id="5-biggan">5. BigGAN</h3> <p><strong>针对问题</strong>：生成逼真精细、让人无法分辨真伪的高清图片。</p> <p><strong>核心技术</strong>：①增大Batch Size,增加Channel ②共享嵌入。BigGan将条件标签c和噪声向量z连接一并输入，降低计算量。③正交正则化。截断技巧能够提升图片质量，但是较大模型不适合截断技巧，BigGAN采用正交正则化（Orthogonal Regularization）使模型使用截断。让 W 权重矩阵尽可能是一个正交矩阵，这样权重系数彼此之间的干扰会非常低，截断之后的权重不会对结果产生太大影响。</p> <h3 id="6-your-local-gan-ylg">6. Your Local GAN (YLG)</h3> <p><strong>针对问题</strong>: 文章主要解决两个问题，①attention的计算效率问题。②feature map展开之后如何保留点的空间位置信息。</p> <p><strong>核心技术</strong>：对于①由于attention需要进行feature map之间的内积操作，YLG利用稀疏矩阵减少一部分计算。对于②二维的矩阵展开成一维失去了空间结构信息，文章引入了ESA (Enumerate, Shift, Apply)，其实就是按照曼哈顿距离展开而不是按行展开。总的来说，感觉创新不是很大。</p> <h3 id="7autogan">7.AutoGAN</h3> <p><strong>针对问题</strong>：如何为GAN自动设计最优的模型？</p> <p><strong>核心技术</strong>：引入NAS(Neural architecture search)，使用RNN控制器从其搜索空间中选择模块来构建 G 网络，并同时堆叠预定义模块来增加 D 的深度。</p> <h3 id="8multi-scale-gradient-gan-msg-gan">8.Multi-Scale Gradient GAN (MSG GAN)</h3> <p><strong>针对问题</strong>：特定数据集训练的GAN很难适应其它数据集，能否训练一个通用的GAN适用不同数据集？</p> <p><strong>核心技术</strong>：文章认为当真实分布和生成器虚假重叠度不高时，判别器传递给生成器梯度的信息不高。将G网络中间层输出的不同尺度的feature map encode成图片,再结合不同尺度大小的原图共起传递给D，这样使得G和D共享更多的信息。</p> <p><img src="/img/GAN/MSG-GAN.jpg" alt=""></p> <h2 id="四评价指标">四、评价指标</h2> <ul> <li> <strong>IS (Inception Score）</strong>: 将GAN生成的样本丢给Inception网络，输出类别概率，对于同一类别的图片，其输出的概率分布应该趋向于一个脉冲分布，可以保证生成样本的准确性。对于所有类别，其输出的概率分布应该趋向于一个均匀分布，这样不会出现mode dropping保证生成样本的多样性。</li> <li> <strong>FID (Fréchet Inception Distance )</strong>：计算真实样本和生成样本在特征空间之间的距离。首先利用Inception网络来提取特征，然后使用高斯模型对特征空间进行建模。根据高斯模型的均值和协方差来进行距离计算。</li> <li> <strong>Mode Score</strong>：Inception Score的改进版本，添加了生成样本和真实样本预测的概率分布相似性度量。</li> <li><strong>Kernel MMD(maximum mean discrepancy)</strong></li> <li><strong>Wasserstein distance</strong></li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/EBGAN/">Energy-based GAN</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2020/BreGAN/">Incorporate Bregman Divergence to generalize fGAN</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/Proximal-Descent/">近端梯度下降</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2019/VarienceReduction/">Variance Reduction</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/MirrorGS/">MirrorGS</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Tingting Liao. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>