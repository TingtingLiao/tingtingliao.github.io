<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://tingtingliao.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://tingtingliao.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-30T12:53:33+00:00</updated><id>https://tingtingliao.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Energy-based GAN</title><link href="https://tingtingliao.github.io/blog/2020/EBGAN/" rel="alternate" type="text/html" title="Energy-based GAN"/><published>2020-08-07T00:00:00+00:00</published><updated>2020-08-07T00:00:00+00:00</updated><id>https://tingtingliao.github.io/blog/2020/EBGAN</id><content type="html" xml:base="https://tingtingliao.github.io/blog/2020/EBGAN/"><![CDATA[<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <h2 id="0-evidence-lower-bound-elbo">0. Evidence Lower Bound ELBO</h2> <p>最大似然可以推导出最大ELBO</p> \[\begin{align} \log p(x) &amp;= \int_z q(z) \log p(x) dz \\ &amp;= \int_z q(z) \log \frac{p(x,z)}{p(z|x)} dz \\ &amp;= \int_z q(z) \log \frac{p(x,z)}{q(z)} \frac{q(z)}{p(z|x)}dz \\ &amp;= \int_z q(z) \log (\frac{p(x,z)}{q(z)}) dz+KL(q(z)||p(z|x)) \\ &amp;= L_b +KL(q(z)||p(z|x)) \\ \end{align}\] <p>记\(L_b = \int_z q(z) \log (\frac{p(x,z)}{q(z)}) dz\) 就是evidence lower bound, 当\(KL(q(z),p(z\| x))=0\)时，最大似然就等价于ELBO，最大似然就是最小化模型生成分布 \(p(z\|x)\) 和真实分布 \(q(z)\) 之间的KL距离。</p> <h2 id="1-vae">1. VAE</h2> <p>AE将输入encode成中间编码 \(z\) 再将其还原decode成 \(\hat{x}\), 它的局限性在于编码需要根据输入得到，随意输入一个中间编码生成图片可能会很奇怪。那么我们能否得到输入数据 \(X\)的分布\(p(x)\)，然后在 \(p(x)\)中采样生成图片即可。<strong>任何一个分布都可以看作是多个高斯分布的叠加</strong>。</p> \[p(x)=\int_z p(x|z)p(z)dz\\\] <p>和混合高斯不一样的是， \(z\) 服从连续分布。如果我们知道\(z\) 的分布那么就可以得到与输入近似的 \(\hat{x}\),这相当于是一个decode的过程， $z$ 的分布则可以通过encode输入得到。有两个encoder，一个encoder输出均值 \(\mu\) ,另一个输出方差 \(\sigma\), 这样就能得到 \(p(z\|x)\)的分布 \(N(\mu, \sigma^2)\) ,从 \(p(z\|x)\)中采样得到 \(z\) . 这里有两个问题：</p> <ol> <li>\(z\) 为什么是从$p(z|x)$中采样的而不是从 $q(z) $中采样的？</li> <li>采样得到的 \(z\)与真实数据的编码会有一定的误差如何解决？</li> </ol> <p><img src="https://pic3.zhimg.com/50/v2-975c73b5748459a9840341b5a7be3ab3_b.jpg" alt="img"/></p> <p><strong>第一个问题：p(z|x)和 q(z)是同分布的.</strong></p> \[p(z) = \int p(z|x)p(x) dx=N(\mu, \sigma^2)\int p(x)dx = N(\mu, \sigma^2)\] <p><strong>第二个问题：假设\(q(z)\)理想情况下服从正态分布</strong> N(0,1) <strong>，让</strong> p(z|x) <strong>逼近正态分布，这样就能让采样的</strong> <strong>z</strong> <strong>接近理想编码分布。</strong></p> \[\min KL(p(z|x)||q(z))\] <p>VAE的优化目标是最小化 \(KL(p(x,z) \| q(x,z))\)，<strong>它等价于最大化ELBO</strong>.</p> \[\begin{align} KL(p(x,z) || q(x,z)) &amp; = \int \int p(x,z) \log \frac{p(x,z)}{q(x,z)}dzdx\\ &amp; = \int \int p(z|x)p(x) \log \frac{p(z|x)p(x)}{q(x|z)q(z)}dzdx\\ &amp; = E_{x\sim p(x)} [ \int_z p(z|x)\log \frac{p(z|x)p(x)}{q(x|z)q(z)}dz]\\ &amp; = E_{x\sim p(x)} [\int_z p(z|x)\log \frac{p(z|x)}{ q(z)}dz + \int_z p(z|x)\log \frac{p(x)}{ q(x|z)}dz ]\\ &amp; = E_{x\sim p(x)} [KL( p(z|x)||q(z))-\int_z p(z|x) \log q(x|z)dz + p(x) ]\\ &amp; \rightarrow KL( p(z|x)||q(z))-\int_z p(z|x) \log q(x|z)dz + C \\ &amp; \rightarrow KL( p(z|x)||N(0,1))-E_{z \sim p(z|x) }[\log q(x|z)] \end{align}\] <p>第一项为KL正则项，第二项为重构损失(给定编码器 \(p(z\|x)\)的情况下解码器\(p(x\|z)\)的值尽可能高）。所以VAE可以看作是加了KL正则的Auto-Encoder。</p> <p><strong>VAE在重构损失的基础上，最大化ELBO，它的目的是最大化似然，等价于最小化生成分布 \(p(z\|x)\) 和编码真实分布 \(q(z)\) 之间的KL距离，并假设 \(q(z)\) 服从标准正态分布。</strong></p> <h2 id="2-energy-based-gan">2. Energy-Based GAN</h2> <p><img src="https://picb.zhimg.com/80/v2-60151c07ecffaeb33743679371d2cbcc_720w.jpg" alt="img"/><em>**</em></p> <p>生成器 \(G\) 将 \(z\) 作为输入， 输出 \(\hat{x}= G(z)\)</p> <p>判别器 \(D\) 是一个Auto-encoder, 输出重构误差 \(D(x)=\|Dec(Enc(x))-x\|\)。那么 \(D\) 目标函数应该让 \(D(x)\) 尽可能大，让 \(D(G(z))\) 尽可能小。\(G\) 的目标是最大化 \(D(G(z))\)</p> \[\begin{align} L_D(x,z)&amp;=D(x)-D(G(z))\\ L_G(z)&amp;=D(G(z)) \end{align}\] <p><strong>那么这和能量有什么关系？</strong> 生成器就是一个能量函数，输出的能量值 \(D(x)\) 低就将它分类为real, 能量值高就分类为fake, 对应了上面的重构损失。</p> <h3 id="21-能量判别器">2.1 能量判别器</h3> <p>定义能量函数 \(U_{\theta}(x), \theta\)是能量函数的参数，系统总能量 \(Z_\theta = \int e^{-U_{\theta}(x)}dx\), 样本概率和能量之间关系表示为：\(p_{\theta}(x) = \frac{e^{-U_{\theta}(x)}}{Z_{\theta}} \propto e^{-U_{\theta}(x)}\),最大似然目标函数</p> \[\max_\theta \prod_{x\in X} p_\theta(x) \\\] <p>上式取对数除以 \(N\) （输入样本个数），目标函数变成 \(\max_\theta E_{x\sim p_D} [\log p_\theta(x) ],p_D\)表示 \(X\) 的真实分布。</p> \[-\log p_\theta(x) = U_\theta(x) + \log Z_\theta \\\] \[\begin{aligned} -\frac{\partial \log p_\theta(x) }{\partial\theta }&amp;= \frac{\partial U_\theta(x)}{\partial\theta } + \frac{1}{Z_\theta }\frac{\partial Z_\theta }{\partial \theta}\\ &amp;= \frac{\partial U_\theta(x)}{\partial\theta } + \frac{1}{Z_\theta } \int -e^{-U_\theta(x)} \frac{\partial U_\theta(x)}{\partial \theta }dx\\ &amp;= \frac{\partial U_\theta(x)}{\partial\theta } - E_{x\sim p(x)}[\frac{\partial U_\theta(x)}{\partial \theta}] \end{aligned}\\\] <p>最大然就变成了最小化下式：</p> \[\begin{aligned} &amp; \frac{\partial E_{x\sim p_D} [-\log p_\theta(x) ] }{\partial \theta} \\ \rightarrow &amp; E_{x\sim p_D} [\frac{\partial U_\theta(x)}{\partial\theta }] - E_{x\sim p_{\theta}(x)}[\frac{\partial U_\theta(x)}{\partial \theta}] \end{aligned}\] <p>\(p_D\)是真实分布, \(p_\theta\)是模型近似出来的假分布.最大似然就变成找到一组最优的参数使得真实分布和假分布之间的能量\(U_\theta(x)\)越近越好。目标函数为：</p> \[\begin{aligned} &amp;\min_\theta E_{x\sim p_D} [U_\theta(x)] - E_{x\sim p_{\theta}(x)}[U_\theta(x)] \\ \rightarrow &amp;\min_\theta E_{x\sim p_D} [D(x)] - E_{x\sim p_{\theta}(x)}[D(x)] \\ \end{aligned}\] <p>可以看到可以用生成器 \(D\) 来替代能量函数 \(U_\theta\) 。<strong>但是这个公式和EBGAN的目标函数不完全一样，因为用判别其作为能量函数之后， \(\theta\) 应该与 \(D\) 的参数 \(W\) 是一致的, 所以 \(x\sim p_\theta (x)\) 不能直接替换成生成器 \(p_G\) 的采样。那么如何从 \(p_\theta\) 中采样 \(x\) ,即如何得到假样本？</strong></p> <h3 id="22--最大熵生成器">2.2 最大熵生成器</h3> <p>用生成器 \(G\) 的生成分布 \(p_G\) 近似替代 \(p_\theta\)，并使两分布距离尽可能的小以减小近似误差</p> \[\begin{align} \min_G KL(p_G||p_\theta) &amp;= p_G \log \frac{p_G}{p_\theta}\\ &amp;= p_G \log p_G - p_G \log p_\theta\\ &amp;= -H[p_G] - E_{p_G}[\log p_\theta]\\ &amp;= -H[p_G] + E_{p_G}[U_\theta(x)] +\log Z_\theta \end{align}\] <p>上式中\(\log Z_\theta\)和\(G\)无关，那么生成器的目标函数就变成了,从\(p_G\)中采样\(x\)相当于是从先验分布\(p(z)\)采样\(z\)经过生成器得到的\(G(z)\):</p> \[\begin{align} &amp;\min_G -H[p_G] + E_{x\sim p_G}[U_\theta(x)]\\ \rightarrow &amp;\min_G -H[p_G] + E_{z\sim p(z)}[U_\theta(G(z))] \end{align}\] <p>EBGAN的生成器目标函数是最小化生成样本的能量，<font color="blue">这里在EBGAN的基础上多了一项，最大化生成分布的熵 </font>\(H[p_G]\) 。</p> <p>接下来问题是<strong>如何计算 \(H[p_G]\) ? 这部分证明需要互信息(mutual information)的信息。</strong></p> <h3 id="23-互信息mutual-information">2.3 互信息(mutual information)</h3> <p><strong>互信息是两个变量之间共有的信息</strong>。定义为：</p> \[\begin{align} I(X,Y)&amp;=\int_X \int_Y p(X,Y)\log \frac{p(X,Y)}{p(X)p(Y)}\quad(*)\\ &amp;=KL(p(X,Y)||p(X)p(Y)) \end{align}\] <p>它有以下4条性质：</p> <p>1）当\(X,Y\)相互独立时，\(p(X,Y) =p(X)p(Y),I(X,Y)=0\)互信息为零</p> <p>2）当\(X,Y\)不独立时，\((*)\)式可以推导简化为：</p> \[I(X,Y)= H(X) - H(X|Y)\] <p>\(H(X)\)为\(X\)的熵，即\(X\)的不确定度，</p> <p>\(H(X\|Y)\)为已知 \(Y\) 的情况下\(X\) 的不确定度，</p> <p>\(I(X,Y)\)为已知 \(Y\) 的情况下\(X\) 不确定度减少的部分，减少的这部分就是 \(X\)和\(Y\) 的共同信息产生的。或者从 $KL$ 的角度也可以理解为，\(I(X,Y)\) 计算了\((X,Y)\)的联合分布与两者边缘分布乘积之间的\(KL\) 距离，也就是\(X,Y\) 的共有部分。</p> <p>3）\(I(X,Y)\geq 0\)</p> <p>4) 当\(X,Y\)知道一个就能推出另一个时，\(I(X,Y)=H(X)=H(Y)\)</p> <p>生成器中，我们希望输入和输出之间的互信息 \(I(G(Z),Z)\) 尽可能的大，根据性质4）可以得到</p> \[\begin{aligned} I(G(Z),Z) &amp;= H(G(Z)) - H(G(Z)|Z)\\ &amp;= H(G(Z)) \end{aligned}\] <p>最大化互信息 \(I(G(Z),Z)\) 等价于最大熵 \(H(p_G)\)，我们用 \(KL(p(\hat{x}\|z)p(z)\|p(\hat{x})p(z))\) 来优化。但是\(KL\) 散度是没有上限的，更好的做法是用\(Jensen-Shanno\) 散度，\(JSD\)是对称的\(KL\)散度，它有上界而且可以达到同样的效果。而在GAN Theory理论推导中，判别器的目标函数等价于最大化\(JS\)</p> \[\begin{align} &amp;\max_D E_{x\sim p_D}[\log D(x)] + E_{x\sim p_G}[\log (1-D(x))]\\ \rightarrow &amp; \max JSD(p_D,p_G) \end{align}\] <p>因此将 \(p_D,p_G\) 换成 \(p(\hat{x}\|z)p(z),p(\hat{x})p(z)\) 目标函数就变成：</p> \[\begin{align} I_{JSD}=\max_D E_{(x,z)\sim p(\hat{x}|z)p(z)}[\log D(x,z)] + E_{(x,z)\sim p(\hat{x})p(z)}[\log (1-D(x,z))]\\ \end{align}\] <p>综上GAN的能量模型损失函数为：</p> \[\begin{align} L_G &amp;= -I_{JSD}(G(Z),Z) + E_{z\sim p(z)}[D(G(z))]\\ L_D&amp;= E_{x\sim p_D}[D(x)]-E_{z\sim p(z)}D(G(z)) \end{align}\]]]></content><author><name>Tintin</name></author><category term="VAE"/><category term="GAN"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">MirrorGS</title><link href="https://tingtingliao.github.io/blog/2020/MirrorGS/" rel="alternate" type="text/html" title="MirrorGS"/><published>2020-08-07T00:00:00+00:00</published><updated>2020-08-07T00:00:00+00:00</updated><id>https://tingtingliao.github.io/blog/2020/MirrorGS</id><content type="html" xml:base="https://tingtingliao.github.io/blog/2020/MirrorGS/"><![CDATA[<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <h2 id="0">0.</h2>]]></content><author><name>Tingting</name></author><category term="VAE"/><category term="GAN"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Incorporate Bregman Divergence to generalize fGAN</title><link href="https://tingtingliao.github.io/blog/2020/BreGAN/" rel="alternate" type="text/html" title="Incorporate Bregman Divergence to generalize fGAN"/><published>2020-07-09T00:00:00+00:00</published><updated>2020-07-09T00:00:00+00:00</updated><id>https://tingtingliao.github.io/blog/2020/BreGAN</id><content type="html" xml:base="https://tingtingliao.github.io/blog/2020/BreGAN/"><![CDATA[<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <h2 id="一fenchel-legendre">一、Fenchel Legendre</h2> <p>Fenchel Duality和Legendre变换本质上是一样的，只是从不同的角度去解释，它描述了<strong>函数斜率与截距之间的关系。</strong></p> <table> <td> <img src="https://pic1.zhimg.com/80/v2-20901fce41b710cdba10d49045227b14_hd.jpg" width="600"/> </td> <td> <img src="/img/bGAN/FencelLegend.gif"/> </td> </table> <p>如上左图，过原点作一条斜线\(y=kx\)，将其向下平移与\(f(x)\)相切，该切线与\(y\)轴的截距与斜线向下平移的距离相等，\(f^*(k)是截距\):</p> \[f^*(k) = kx-f(x)\] \[f'(x)=k\] <p>这就是Legendre变换，它要求<strong>\(f(x)\)①可导（\(f'(x)=k\)） ②凸函数（函数具有唯一性）。</strong> Fenchel突破了凸可导的限制，将上述两个等式换成一个更general的表达式：</p> \[\begin{align} f^*(t) = \max_x\{xt-f(x)\} \\ \end{align}\] <p>\(f^*(t)\)称为\(f(x)\)的共轭。这样我们可以理解为<strong>函数是无数切线切出来的一个曲线</strong>。</p> <p><img src="/img/bGAN/fenchel2.jpg" alt=""/></p> <h6 id="例求gx--log1ex的共轭gy">例：求\(g(x) = \log(1+e^x)\)的共轭\(g^*(y)\)</h6> <ul> <li>切线斜率\(y = \frac{e^x}{1+e^x} \in (0,1)\),\(e^x = \frac{y}{1-y},x = \log \frac{y}{1-y}\)</li> <li> \[g(x)=\log(1+e^x)=\log \frac{1}{1-y}\] </li> </ul> \[\begin{split} g^*(y) &amp;= yx-g(x) \\ &amp;= y\log \frac{y}{1-y}-\log \frac{1}{1-y} \\ &amp;= y\log y +(1-y) \log(1-y) \end{split}\] \[\therefore g^*(y)=\left\{\begin{matrix} y\log y +(1-y) \log(1-y) &amp;\quad y\in (0,1)\\ 0 &amp;\quad otherwise \end{matrix}\right.\] <p>Fenchel共轭的性质：</p> <ol> <li>共轭的共轭等于原函数\(g^{**}(x) = g(x)\)</li> <li>\(g(x)\)是凸函数，那么共轭\(g^*(x)\)也为凸函数</li> <li>\(g(x)\)是\(L-smooth\),那么\(g^*(x)\)是\(\frac{1}{L}-SC(Strongly Convex)\)</li> </ol> <h2 id="二f-gan">二、f-GAN</h2> <p><a href="https://arxiv.org/pdf/1606.00709.pdf">f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization</a></p> \[\begin{align} &amp;f^*(t) = \max_x\{xt-f(x)\} \quad (f^*(t))'=x \\ \Leftrightarrow &amp;f(x) = \max_t\{xt-f^*(t)\}\quad f'(x)=t \end{align}\] <p>给定\(\,x\,\)和函数\(\,f\,\)找到一个最优的\(\,t\,\)使得\(\,xt-f^*(t)\,\)最大。</p> \[D_f (P||Q)=\int_{x}q(x)f(\frac{p(x)}{q(x)})dx\\\] <p>f-Divergence中\(\,f\,\)为凸函数且\(f(1)=0\,\). 判别器\(\,D\,\)的目标是最大化上式，而上式变量并不含\(\,D\,\)，可以利用Fenchel共轭对其进行变换,将\(\,t\,\)换成\(\,D(x)\,\)作为优化对象：</p> \[\begin{align} D_f (P||Q) &amp;=\int_{x}q(x)f(\frac{p(x)}{q(x)})dx\\ &amp;= \int_{x}q(x) \max_t \{ \frac{p(x)}{q(x)} t - f^*(t)\} dx \\ &amp; \geq \int_{x}q(x) \{ \frac{p(x)}{q(x)} D(x) - f^*(D(x))\} dx\\ &amp; = \int_{x} p(x) D(x) - q(x) f^*(D(x)) dx\\ \end{align}\] \[\begin{align} \therefore D_f (P||Q) &amp;\approx \max_D \int_{x} p(x) D(x) - q(x) f^*(D(x)) dx \quad (*)\\ &amp;\approx E_{x\sim P} [D(x)] - E_{x\sim Q} [ f^*(D(x))] \end{align}\] <p>\((*)\,\)式中可以简化为最大化\(\,p(x) D(x) - q(x) f^*(D(x)) \,\),我们令\(p(x)=A,q(x)=B,D(x)=X\),对\(\,D(x)\,\)进行求解：</p> \[\begin{align} \max_D \quad &amp;p(x) D(x) - q(x) f^*(D(x)) \\ &amp;\rightarrow A-B(f^*(X))'=0\\ &amp;\rightarrow (f^*(X))'=\frac{A}{B}=\frac{p(x)}{q(x)}\\ &amp;\rightarrow f'(\frac{p(x)}{q(x)})=X=D(x) \end{align}\] <p>训练判别器过程中，GAN的\(D(x)\)最优取\(\,\frac{p(x)}{p(x)+q(x)}\,\),f-GAN中\(D(x)\)最优取\(f'(\frac{p(x)}{q(x)})\,\),当\(\,f(x)=x\log x - (x+1)\log (x+1)\)时为GAN。</p> <h2 id="三b-gan">三、b-GAN</h2> <p><a href="https://openreview.net/pdf?id=S1JG13oee">B-GAN: UNIFIED FRAMEWORK OF GENERATIVE ADVERSARIAL NETWORKS</a></p> <h3 id="1-bregman-divergence">1. Bregman Divergence</h3> \[B_f(A,B) = f(A) - f(B) - f'(B)(A-B)\] <h3 id="2-bgan">2. bGAN</h3> <p>假设有两个分布\(p(x)\)和\(q(x)\), 真实的密度比\(r(x)=\frac{p(x)}{q(x)}\),模型的密度比为\(r_\theta(x)\), \(\theta\)为模型的参数。</p> \[\begin{align} BD_f(r||r_\theta) &amp;= E_{x\sim Q}[B_f(r,r_\theta)] \\ &amp;= \int (f(r(x)) - f(r_\theta(x)) - f'(r_\theta(x))(r(x)-r_\theta(x)))q(x)dx \end{align}\] <p>\(r(x)\)为常数，可以去除无关项只保留\(r_\theta\)相关项：</p> \[\begin{align} BR_f(r_\theta) &amp;= \int (- f(r_\theta(x)) - f'(r_\theta(x))(r(x)-r_\theta(x)))q(x)dx \\ &amp;= \int (f'(r_\theta(x)) r_\theta(x) - f(r_\theta(x)))q(x)dx - \int f'(r_\theta(x)) p(x) dx \\ &amp;= E_{x\sim Q} [f'(r_\theta(x)) r_\theta(x) - f(r_\theta(x))] - E_{x\sim P} [f'(r_\theta(x))] \end{align}\] <p>目标是最小化上式的密度比估计，换成下式就和fGAN有相同的形式, \(D(x) = f'(r_\theta(x))\)</p> \[\begin{align} \max_{r_\theta} &amp;E_{x\sim P} [f'(r_\theta(x))] - E_{x\sim Q} [f'(r_\theta(x)) r_\theta(x) - f(r_\theta(x))] \\ \rightarrow \max_D &amp;E_{x\sim P} [D(x)] - E_{x\sim Q} [ f^*(D(x))] \end{align}\] <p>可以看出\(Bregman Div\)和fGAN之间存在对偶关系。</p> <h2 id="四-scaled-bregman-gan">四、 scaled-Bregman GAN</h2> <p><a href="https://arxiv.org/pdf/1906.00313.pdf">BreGMN: scaled-Bregman Generative Modeling Networks</a></p> \[\begin{align} B_f(P,Q) &amp;= \int_{\chi } f(p(x)) - f(q(x)) - f'(q(x))(p(x)-q(x)) dx\\ B_f(P,Q|M) &amp;= \int_{\chi } f(\frac{p(x)}{m(x)}) - f(\frac{q(x)}{m(x)}) - f'(\frac{q(x)}{m(x)})( \frac{p(x)}{m(x)} - \frac{q(x)}{m(x)})dM \\ &amp;= \int_{\chi }B_f(\frac{p(x)}{m(x)},\frac{q(x)}{m(x)})\:m(x)dx \end{align}\] <p>上式和bGAN很相似，bGAN是\(\int_{\chi }B_f(\frac{p(x)}{q(x)},r_\theta(x))\:q(x)dx\). 下面我们令\(m(x)=q(x)\)</p> \[\begin{align} B_f(P,Q|M) &amp;= \int_{\chi } (f(\frac{p(x)}{q(x)}) - f(1) - f'(1)( \frac{p(x)}{q(x)} - f(1)))q(x)dx \\ &amp;= \int_{\chi }f(\frac{p(x)}{q(x)})q(x)dx \quad (f(1)=0,f'(1)=0) \end{align}\] <p>这样就得到f-Divergence,它要求\(f(1)=0\),\(f(x)\)为凸函数且\(f(x)\geq 0\)则\(f'(1)=0\)</p> <h2 id="五总结">五、总结</h2> <table> <thead> <tr> <th style="text-align: center">Method</th> <th style="text-align: center">Div in Bregman form</th> <th style="text-align: center">Estimate D(x)</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(GAN\)</td> <td style="text-align: center"> </td> <td style="text-align: center">\(\frac{p}{p+q}\)</td> </tr> <tr> <td style="text-align: center">\(fGAN\)</td> <td style="text-align: center">\(\int B_f(\frac{p(x)}{q(x)},1)q(x)dx\)</td> <td style="text-align: center">\(f'(\frac{p}{q})\)</td> </tr> <tr> <td style="text-align: center">\(bGAN\)</td> <td style="text-align: center">\(\int B_f(\frac{p(x)}{q(x)},r_\theta(x))q(x)dx\)</td> <td style="text-align: center">\(\begin{align} &amp;r(x) =\frac{p(x)}{q(x)}\\ Dual\, &amp;relation\, with \,fGAN \end{align}\)</td> </tr> <tr> <td style="text-align: center">\(BreGMN\)</td> <td style="text-align: center">\(\int B_f(\frac{p(x)}{m(x)},\frac{q(x)}{m(x)})m(x)dx\)</td> <td style="text-align: center"> </td> </tr> </tbody> </table>]]></content><author><name>Tintin</name></author><category term="GAN"/><category term="Bregman Divergence"/><category term="Fenchel Legendre"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">GAN Review</title><link href="https://tingtingliao.github.io/blog/2020/GAN/" rel="alternate" type="text/html" title="GAN Review"/><published>2020-06-24T00:00:00+00:00</published><updated>2020-06-24T00:00:00+00:00</updated><id>https://tingtingliao.github.io/blog/2020/GAN</id><content type="html" xml:base="https://tingtingliao.github.io/blog/2020/GAN/"><![CDATA[<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <h2 id="一introduction">一、Introduction</h2> <table> <thead> <tr> <th style="text-align: center">Time</th> <th style="text-align: center">Method</th> <th style="text-align: center">Describe</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(14年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1406.2661.pdf">\(GANs\)</a></td> <td style="text-align: center">生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(14年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1411.1784.pdf">\(CGAN\)</a></td> <td style="text-align: center">条件生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(15年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1506.05751.pdf">\(LAPGAN\)</a></td> <td style="text-align: center">拉普拉斯金字塔GAN</td> </tr> <tr> <td style="text-align: center">\(15年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1511.06434.pdf">\(DCGAN\)</a></td> <td style="text-align: center">深度卷积生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(15年12月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1512.09300.pdf">\(VAEGAN\)</a></td> <td style="text-align: center">变分自编码GAN</td> </tr> <tr> <td style="text-align: center">\(16年05月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1605.09782.pdf">\(BiGAN\)</a></td> <td style="text-align: center">双向生成生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1606.07536.pdf">\(CoGAN\)</a></td> <td style="text-align: center">耦合生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1606.00709.pdf">\(fGAN\)</a></td> <td style="text-align: center">f-散度生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1606.03498.pdf">\(ImprovedDCGAN\)</a></td> <td style="text-align: center">提升DCGAN</td> </tr> <tr> <td style="text-align: center">\(16年06月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1606.03657.pdf">\(InfoGAN\)</a></td> <td style="text-align: center">互信息生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年09月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1609.03126.pdf">\(EBGAN\)</a></td> <td style="text-align: center">基于能量的生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年09月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1609.04802.pdf">\(SRGAN\)</a></td> <td style="text-align: center">超分辨率生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1611.04076.pdf">\(LSGAN\)</a></td> <td style="text-align: center">最小二乘生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(16年12月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1612.03242.pdf">\(StackGAN\)</a></td> <td style="text-align: center">堆栈式生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(17年01月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1701.07875.pdf">\(WGAN\)</a></td> <td style="text-align: center">Wasserstein距离GAN</td> </tr> <tr> <td style="text-align: center">\(17年03月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1703.10717.pdf">\(BEGAN\)</a></td> <td style="text-align: center">边界均衡生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(17年03月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1703.10593.pdf">\(CycleGAN\)</a></td> <td style="text-align: center">循环生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(17年03月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1703.02291.pdf">\(TripleGAN\)</a></td> <td style="text-align: center">三部分生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(17年04月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1704.00028.pdf">\(WGAN-GP\)</a></td> <td style="text-align: center">加强版WGAN</td> </tr> <tr> <td style="text-align: center">\(17年05月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1705.07215.pdf">\(DRAGAN\)</a></td> <td style="text-align: center">深度回归分析GAN</td> </tr> <tr> <td style="text-align: center">\(17年05月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1705.07215.pdf">\(DRAGAN\)</a></td> <td style="text-align: center">深度回归分析GAN</td> </tr> <tr> <td style="text-align: center">\(17年10月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1710.10196.pdf">\(PGGAN\)</a></td> <td style="text-align: center">渐进生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(17年10月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1710.10916.pdf">\(StackGAN++\)</a></td> <td style="text-align: center">提升的堆栈式GAN</td> </tr> <tr> <td style="text-align: center">\(17年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1711.09020.pdf">\(StarGAN\)</a></td> <td style="text-align: center">星型结构GAN</td> </tr> <tr> <td style="text-align: center">\(17年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1711.05139.pdf">\(XGAN\)</a></td> <td style="text-align: center">X型结构GAN</td> </tr> <tr> <td style="text-align: center">\(17年12月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1712.06909.pdf">\(ComboGAN\)</a></td> <td style="text-align: center">合一式生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(18年02月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1802.05957.pdf">\(SNGAN\)</a></td> <td style="text-align: center">频谱归一化生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(18年05月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1805.08318.pdf">\(SAGAN\)</a></td> <td style="text-align: center">自注意力生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(18年07月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1807.00734.pdf">\(RGAN\)</a></td> <td style="text-align: center">相对生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(18年09月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1809.11096.pdf">\(BigGAN\)</a></td> <td style="text-align: center">大规模的生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(18年12月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1812.04948.pdf">\(StyleGAN\)</a></td> <td style="text-align: center">基于样式的生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(19年03月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1903.02271.pdf">\(S3GAN\)</a></td> <td style="text-align: center">更少标签的生成对抗网络</td> </tr> <tr> <td style="text-align: center">\(19年03月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1903.07291.pdf">\(GuaGAN\)</a></td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: center">\(19年05月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1905.01164.pdf">\(SinGAN\)</a></td> <td style="text-align: center">单幅自然图像学习的非条件生成模型</td> </tr> <tr> <td style="text-align: center">\(19年07月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1907.02544.pdf">\(BigBiGAN\)</a></td> <td style="text-align: center">超大规模生成对抗模型</td> </tr> <tr> <td style="text-align: center">\(19年08月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1908.03835.pdf">\(AutoGAN\)</a></td> <td style="text-align: center">自动搜索生成对抗网络的结构</td> </tr> <tr> <td style="text-align: center">\(CVPR2020\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1903.06048.pdf">\(MSG-GAN\)</a></td> <td style="text-align: center">用于稳定图像合成的多尺度梯度GAN</td> </tr> <tr> <td style="text-align: center">\(2019年11月\)</td> <td style="text-align: center"><a href="https://arxiv.org/pdf/1911.12287.pdf">\(YLG\)</a></td> <td style="text-align: center">用于稳定图像合成的多尺度梯度GAN</td> </tr> </tbody> </table> <p><img src="/img/GAN/GANs.jpg" alt=""/></p> <h2 id="二基于loss的改进">二、基于Loss的改进</h2> <h3 id="0-基础知识">0. 基础知识</h3> \[KL(p_1||p_2)=E_{X\sim p_1}\log\frac{p_1}{p_2}\\ JS(p_1||p_2)=\frac{1}{2}KL(p_1||\frac{p_1+p_2}{2})+\frac{1}{2}KL(p_2||\frac{p_1+p_2}{2})\] <h3 id="1最大似然推导出kl散度">1.最大似然推导出KL散度</h3> <p>从真实分布 \(P_{data}(x)\) 抽样部分数据 \(\{x^1,x^2,...,x^m\}\),最大似然就是找到一组 \(\theta\) 使得抽样的样本概率最大,\(\theta\) 是模拟真实分布的参数。</p> \[\max_\theta L=\prod_{i=1}^mP_G(x^i,\theta)\] <p>根据取对数推导可以得出最大似然等价于最小化真实分布与生成器分布的\(KL\)距离。</p> \[\min_{\theta} KL(P_{data}||P_{G})\] <p><strong>\(KL\)散度问题：不是对称的衡量</strong></p> <ul> <li>当\(P_g(x)\rightarrow 0\)而\(P_r(x)\rightarrow 1\)时，\(KL(P_g \|\| P_r)\rightarrow 0\)</li> <li>当\(P_g(x)\rightarrow 1\)而\(P_r(x)\rightarrow 0\)时，\(KL(P_g \|\| P_r) \rightarrow +\infty\)</li> </ul> <p>这就好比将 \(A\) 和 \(B\) 互换位置， \(D_{KL}(A,B)\) 和 \(D_{KL}(B,A)\) 距离不相等。而<strong>JSDiv</strong>能够很好解决这个问题。</p> <h3 id="2gan">2.GAN</h3> \[\min_G \max_D V(G,D) = E_{x\sim P_{data}}[logD(x)] + E_{x\sim P_{G}}[log(1-D(x))]\] <p>判别器 \(D\) 的目标函数可以推导出\(JS Div\)(推导略)</p> \[\max_D V(G,D) = E_{x\sim P_{data}}[logD(x)] + E_{x\sim P_{G}}[log(1-D(x))] \\ =-2log2 + 2JSD(P_{data}||P_G)\] <p>其中\(D^*(x)=\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}\),优化生成器\(G\)则变为最小化真实分布与生成器分布的\(JS\)距离.</p> <p>在固定判别器为 \(D^*(x)\) 训练 \(G\) 时候，\(JSDiv\)存在两个问题：</p> <p>①训练前期，真实分布和生成分布 <strong>重叠度很低时，JSDiv无法衡量两个分布之间的距离</strong>。举个例子：两个不重叠的圆\(A\)和\(B\)，无论圆心的距离是无穷远还是\(AB\)刚好相切，\(JS(A,B)\)都不变。如下图当两分布overlap很小Distance很大时，JSDiv很大，梯度更新几乎为0，这导致前期训练很慢效率不高。</p> <p><img src="/img/GAN/GAN gradient.jpg" alt=""/></p> <p>② <strong>优化 \(G\) 时不再是 JS Div而主要是Reverse KL Div，导致mode dropping问题，生成的图片缺乏多样性。</strong> 训练过程\(G\)过程中，损失函数 \(-E_{x\sim P_{G}}log[D(x)]\),根据推导这一项等价于Reverse KL Div。</p> \[\begin{align} &amp;-E_{X\sim P_{G}}log[D^*(x)]\\ =&amp; KL(P_G||P_{data})-2JS(P_{data}||P_{G})+2\log2+E_{x\sim P_x}log[D^*(x)] \end{align}\] <p>后两项为常数，只看前两项，由于 \(JS(P_{data} \|\| P_{G})\) 范围为 \([0,\log2]\)对结果几乎无影响，\(KL(P_G \|\| P_{data})\) 占主导，它为逆 \(KL(P_{data} \|\| P_G)\)。</p> <p><img src="/img/GAN/Reverse KL.jpg" alt=""/></p> <p>逆\(KL\)会造成模式丢失和模式坍塌问题。真实数据分布一般都存在多种特征模式如肤色、发型、性别等，如上图蓝色线为双模式分布， \(q\) 为生成分布，\(KL\)会让\(q\) 包含两个模式，而reverse KL的\(q\)分布丢失了一部分的mode, 实际生成图片就会缺乏多样性。</p> <h3 id="3wgan">3.WGAN</h3> <p>WGAN就很好解决了上述两个问题，它采用Earth Move（EM）距离（也叫Wasserstein距离）作为损失度量：</p> \[W(P_{data}, P_G)=\inf_{ \gamma\in \prod(P_{data}, P_G)} E_{(x,y)\sim \gamma}||x-y||\] <p>上述式子表示， \(P_{data}\) 为真实分布，穷举生成器所有可能的分布\(P_G , \prod(P_{data}, P_G)\)为所有联合分布集合, 取一组最优的联合分布 \(\gamma\),使真实分布和生成分布产生的 \(x,y\) 平均距离最小。优点：即使两个分布不重叠依然能够反映它们之间的距离，Was距离平滑可导，即使真假分布不重叠更新的梯度也是有意义的。</p> <p>但是上式求解很麻烦，需要穷举所有的 \(P_G\) 再取最优，作者将其转化为下式：</p> \[V(G,D)=\max_{D\in 1-Lipschitz} \{E_{x\sim P_{data}}[D(x)]-E_{x\sim P_{G}}[D(x)]\}\qquad (*)\\ ||f(x_1)-f(x_2)||\leq K||x_1-x_2||\] <p>\(D\)网络将从真假分布抽样的\(x\)映射到一个空间中，在这个空间他们的\(L_1\)距离最大。并且\(D\)满足1-Lipschitz连续，即一阶导上界为 \(1\). WGAN相比于GAN做了以下改动：</p> <ul> <li>把\(D\)参数的绝对值截断到不超过常数c（满足1-Lipschitz条件）</li> <li>生成器和判别器的loss不取log(Was距离)</li> <li>判别器最后一层去掉sigmoid（\(D\)不再是判别器而是距离的回归网络）</li> <li>不要用基于动量的优化算法包括momentum和Adam，推荐RMSProp/SGD（实验trick）</li> </ul> <p>● <strong>思考</strong></p> <p><strong>第一点，</strong>式 \((*)\)字面上理解是真实分布和生成分布生成图片经过判别器均值的L1距离， \(D(x)\) 可以看作一个映射函数mapping function。先举个例子，看一下马氏距离：</p> <p>马氏距离解释：将输入映射到另外一个空间，在这个空间中它们的欧式距离最小。</p> \[\begin{align} &amp;(X-Y)^TM(X-Y)\\ =&amp; (X-Y)^TW^TW(X-Y)\qquad M=W^TW\\ =&amp;(WX-WY)^T(WX-WY) \end{align}\] <p>\(X,Y\) 为 \(d\) 维向量， \(M\) 为对角正定矩阵，表示每一维的权重系数，因为 \(M\) 正定可以开根号分解为矩阵 \(W\) ，再将\(W\)放入阔号里马氏距离又变成特殊的欧式距离，而 W 矩阵可以看作是对 \(X,Y\) 的线性变换，通过一层的FC网络即可实现。将矩阵 \(W\) 扩展为非线性就是多层神经网络， \(W\) 更加general的意义就是一个mapping function \(f(·)\)，原始的输入通过 \(f\) 能够更加可分。而判别器 D 实际上也是一个函数映射。</p> <p><strong>第二点，能否将 D(x) 看作距离的度量函数</strong>，也就是将 \(D(x)\) 看作为一种divergence，\(D(x)\)可以为任意的divergence，我们只需定义一个通用的divergence损失就能训练出\(D(x)\)。我们知道Bregman divergence包含了对一切距离的定义，它的几何思想为：两点距离为一阶泰勒展开的差。</p> \[d_{\varphi}(x,y) = \varphi(x)-(\varphi(y)+\triangledown \varphi(y)(y-x))\] <p>如欧式距离\(\varphi(x)=x^2,d_\varphi(x,y) = x^2-y^2-2y (y-x))=(x-y)^2,\varphi\)选取不同表达式表示不同度量方式。具体如下图。</p> <p><img src="/img/GAN/BregmanDiv.png" alt=""/></p> <p>可以结合Bregman divergence，令 \(D(x)\equiv\varphi(x)\) ,判别器的目标函数为:</p> \[\max_D E_{(x,y)\sim (P_{data}, P_G)}[D(x)-D(y)-\triangledown D(y)(x-y)]\] <p>这样就能通过 \(d_\varphi(x,y)\)训练出 \(\varphi(x)\) . 上式距离等价于WGAN判别器目标函数额外加上 \(\triangledown D(y)(x-y)\)，这也解释了为什么WGAN需要满足Lipchitz连续限制一阶导的大小，我觉得也正是这一点导致了用加速算法（momentum Adam）loss会崩掉。从Bregman的角度就无需再对一阶导进行限制。</p> <p>相关论文：b-GAN BreGMN</p> <h3 id="4-wgan-gp">4. WGAN-GP</h3> <p><strong>解决问题</strong>: WGAN未能将D真的限制在1-Lipschitz内。</p> \[\max_D E_{x\sim P_{data}}[D(x)] - E_{x\sim P_{G}}[D(x)] -\lambda\int_{x}max(0,||\triangledown_xD(x)-1||)dx\] <p><strong>核心思想</strong>：WGAN-GP为判别器目标函数增加对D约束： \(\max_D E_{x\sim P_{data}}[D(x)] - E_{x\sim P_{G}}[D(x)] -\lambda\int_{x}max(0,||\triangledown_xD(x)-1||)dx\)<br/> 这个表达式的问题在于，前两项都是均值期望，添加的第三项是积分，直接导致第三项惩罚过高。于是作者将其改为下式，惩罚项改为在真假分布之间抽样计算梯度是否小于1. （为什么不直接给上式第三项加 \(1/N\) ？)</p> <p><img src="/img/GAN/WGAN-GP.png" alt=""/></p> <p>作者发现 \(\| \| \triangledown_xD(x)\|\|\) 越接近 1 ，训练得越快，效果也越好，于是不表达式直接改成：</p> \[\max_D E_{x\sim P_{data}}[D(x)] - E_{x\sim P_{G}}[D(x)] -\lambda E_{x\sim P_{penalty}} [(||\triangledown_xD(x)||-1)^2]dx\] <p><strong>WGAN-PG问题：① 没有从根本上解决1-Lipschitz问题</strong>。让 \(\|\|\triangledown_x D(x)\|\|\) 尽量接近 1，并没有真的将\(\|\| \triangledown_xD(x)\|\|\)限制在小于等于1内。</p> <p><strong>②\(P_{penalty}\)可能改变了原始 \(P_G\)向\(P_{data}\)移动的方向。</strong></p> <h3 id="5-f-gan">5. f-GAN</h3> <p>生成器的目标其实是最小化真实分布与生成器分布之间的距离：</p> \[\min_G Div(P_G, P_{data})\] <p><strong>fGAN提出的问题是：能否用一种通用的框架表示所有可能的距离形式？</strong>fGAN提出了f-Divergence用 \(D_f\) 表示</p> \[D_f (P||Q)=\int_{x}q(x)f(\frac{p(x)}{q(x)})dx\\\] <p>其中函数\(f\)为凸函数且\(f(1)=0\) . \(f\) 选取不同的函数, \(D_f\)表示不同的Divergence</p> \[\begin{array}[b] {|c|c|} \hline f(x) &amp; D_f (p||q)&amp; Divergence\\ \hline x\log(x) &amp; \int_{x}p(x)log(\frac{p(x)}{q(x)}) &amp; KL \\ \hline -\log(x) &amp; \int_{x}q(x)log(\frac{q(x)}{p(x)}) &amp; 逆KL \\ \hline (x-1)^2 &amp; \int_{x}\frac{(p(x)-q(x))^2}{q(x)} &amp; Chi \:Square \\ \hline \end{array}\] <p>以上是生成器G的目标函数,对于判别器D，再根据Fenchel共轭可以推导出（1）对应的形式：</p> \[\max_D E_{x\sim P_{data}}[D(x)] - E_{x\sim P_{G}}[f^*(D(x))] \\\] <p>综上，fGAN的目标函数为：</p> \[\begin{align} &amp;\min_G\max_D E_{x\sim P_{data}}[D(x)] - E_{x\sim P_{G}}[f^*(D(x))] \\ =&amp;\min_G\max_D D_f(P_{data}||P_G) \end{align}\] <h3 id="6-geometric-gan">6. Geometric GAN</h3> <p>核心思想：将SVM的分割超平面思想运用在GAN上。</p> \[\begin{align} L_D&amp;=E_{x\sim P_r}[1-D(x)]_+ + E_{z\sim P_z}[1+D(G(z))]_+ \\ L_G&amp;= -E_{z\sim P_z}D(G(z)) \end{align}\] <p><img src="/img/GAN/Geometric GAN.png" alt=""/></p> <h3 id="7-sphere-gan">7. Sphere GAN</h3> <p><a href="http://cau.ac.kr/~jskwon/paper/SphereGAN_CVPR2019.pdf">CVPR2019 Oral Sphere Generative Adversarial Network Based on Geometric Moment Matching </a></p> \[\min_G \max_D \sum_r E_x[d_s^r(N,D(x))]-\sum_r E_z[d_s^r(N,D(G(z)))]\] <p>WGAN中 \(D(x)\) 将输入映射为一个数值 \(D: x\in \boldsymbol{\chi}\rightarrow \mathbb{R}\) , 判别器求一维的欧式距离。</p> \[\max_D E_x[D(x)]-E_z[D(G(z))]\] <p>Sphere GAN将 其扩展为求高维的欧式距离， \(D: x\in \boldsymbol{\chi}\rightarrow \mathbb{S}^n\),D将输入映射为一个向量。下面以二维为例：</p> <p>①将点映射到球面上。</p> <p>球心为原点，球半径为1，根据相似三角形可得点在球面上的坐标。</p> \[\prod (p)=(x,y)=(\frac{2p}{||p||^2+1}, \frac{||p||^2-1}{||p||^2+1})\] <p><img src="/img/GAN/SphereGAN.jpg" alt=""/></p> <p>②计算球面上点的距离。</p> <p>如图，绿点真分布 \(D(x)\) ，紫点假分布 \(D(G(z))\) ， \(N\)为球的北极坐标。 \(d_s\)计算真假分布到 \(N\)的距离 \(d_s^r(N,D(x)) , d_s^r(N,D(G(z)))\) 。</p> \[d_s(\prod(p),\prod(q))=\arccos(\frac{||p||^2||q||^2-||p||^2-||q||^2+4p·q+1}{(||p||^2+1)(||q||^2+1)})\] <p><img src="/img/GAN/SphereGAN 2.jpg" alt=""/></p> <h3 id="8-realness-gan">8. Realness GAN</h3> <p><a href="https://openreview.net/pdf?id=B1lPaCNtPB">ICLR2020 REAL OR NOT REAL, THAT IS THE QUESTION </a></p> <p><a href="https://zhuanlan.zhihu.com/p/105171680">原作者知乎回答</a></p> <p>Original GAN目标表达式</p> \[\min_G\max_D E_{x\sim P_{data}}[\log (D(x)-0)]+E_{x\sim P_G}[\log(1-D(x))]\] <p>D的目标是让 \(D(x_{real})\) 靠近0，\(D(x_{fake})\)靠近1; G目标是\(D(x_{fake})\)靠近0。这样可以将“0”和“1”看作是真假分布的锚，设真锚为 \(A_1\) , 伪锚为 \(A_0\)，RealnessGAN目标函数为：</p> \[\max_G\min_D E_{x\sim P_{data}}[D_{KL}(A_1||D(x))]+E_{x\sim P_G}[D_{KL}(A_0||D(x))]\] <p>D: 最小化真图片与真锚、伪图片与伪锚的KL-divergence。</p> <p>G: 最大化伪图片与伪锚的KL-divergence(Original GAN是最小化伪图片和真锚距离)</p> <p>作者发现单纯最大化伪图片与伪锚KL距离效果并不好，因为它只是让图片看起来不那么假，而不能保证它足够真。因此加了一项小化伪图片和真锚距离，这样生成图片的真实度大大提高。</p> \[\min_G E_{z\sim P_G}[D_{KL}(A_1||D(G(z)))]-E_{z\sim P_G}[D_{KL}(A_0||D(G(z)))]\] <h2 id="三基于architecture的改进">三、基于Architecture的改进</h2> <h3 id="1-deep-convolutional-gandcgan">1. Deep Convolutional GAN(DCGAN)</h3> <p>DCGAN和GAN原理一样，只是把G和D换成CNN。DCGAN对卷积神经网络做了一些改变：</p> <p>· 取消所有pooling层。G网络中用微步幅卷积，D中用步幅卷积 · D和G中均使用batch normalization · 去掉FC层，使网络变成全卷积网络 · G网络中使用 ReLU 作为激活函数，最后一层使用 tanh · D网络中使用 LeakyReLU 作为激活函数</p> <h3 id="2-boundary-equllibrlum-ganbegan">2. Boundary Equllibrlum GAN(BEGAN)</h3> <p>针对问题：</p> <p>· D网络用Autoencoder不用classification网络。论文证明了在Auto encoder下损失函数和Wasserterin距离是等价的。 · 引入超参数 \(\gamma=\frac{E[L(G(z))]}{E[L(x)]}\) 平衡图像的多样性。</p> <h3 id="3-progressive-ganprogan">3. Progressive GAN(ProGAN)</h3> <p><img src="/img/GAN/proGAN.jpg" alt=""/></p> <p><strong>针对问题</strong>：生成超高分辨率的清晰图像。</p> <p><strong>核心技术</strong>：渐进式增长GAN随着训练的进行，网络层数逐渐增加。一开始学习低分辨率4×4的图片生成，逐渐加深网络，学习更高分辨率的图片，最终不断更新直到学习1024×1024图片生成。速度也比传统GAN提升很多。</p> <h3 id="4-self-attention-gan-sagan">4. Self-Attention GAN (SAGAN)</h3> <p><strong>针对问题</strong>：卷积网络感受野的限制使其无法获取大范围的结构信息，例如人脸鼻子发生偏移或眼睛不对称。如何在不牺牲计算量的情况下，获取图像的全局信息？</p> <p><strong>核心思想</strong>：引入Attention，通过计算图像中任意两个像素点之间关系，获取图像的全局几何特征。 <img src="/img/GAN/SAGAN.jpg" alt=""/></p> <h3 id="5-biggan">5. BigGAN</h3> <p><strong>针对问题</strong>：生成逼真精细、让人无法分辨真伪的高清图片。</p> <p><strong>核心技术</strong>：①增大Batch Size,增加Channel ②共享嵌入。BigGan将条件标签c和噪声向量z连接一并输入，降低计算量。③正交正则化。截断技巧能够提升图片质量，但是较大模型不适合截断技巧，BigGAN采用正交正则化（Orthogonal Regularization）使模型使用截断。让 W 权重矩阵尽可能是一个正交矩阵，这样权重系数彼此之间的干扰会非常低，截断之后的权重不会对结果产生太大影响。</p> <h3 id="6-your-local-gan-ylg">6. Your Local GAN (YLG)</h3> <p><strong>针对问题</strong>: 文章主要解决两个问题，①attention的计算效率问题。②feature map展开之后如何保留点的空间位置信息。</p> <p><strong>核心技术</strong>：对于①由于attention需要进行feature map之间的内积操作，YLG利用稀疏矩阵减少一部分计算。对于②二维的矩阵展开成一维失去了空间结构信息，文章引入了ESA (Enumerate, Shift, Apply)，其实就是按照曼哈顿距离展开而不是按行展开。总的来说，感觉创新不是很大。</p> <h3 id="7autogan">7.AutoGAN</h3> <p><strong>针对问题</strong>：如何为GAN自动设计最优的模型？</p> <p><strong>核心技术</strong>：引入NAS(Neural architecture search)，使用RNN控制器从其搜索空间中选择模块来构建 G 网络，并同时堆叠预定义模块来增加 D 的深度。</p> <h3 id="8multi-scale-gradient-gan-msg-gan">8.Multi-Scale Gradient GAN (MSG GAN)</h3> <p><strong>针对问题</strong>：特定数据集训练的GAN很难适应其它数据集，能否训练一个通用的GAN适用不同数据集？</p> <p><strong>核心技术</strong>：文章认为当真实分布和生成器虚假重叠度不高时，判别器传递给生成器梯度的信息不高。将G网络中间层输出的不同尺度的feature map encode成图片,再结合不同尺度大小的原图共起传递给D，这样使得G和D共享更多的信息。</p> <p><img src="/img/GAN/MSG-GAN.jpg" alt=""/></p> <h2 id="四评价指标">四、评价指标</h2> <ul> <li><strong>IS (Inception Score）</strong>: 将GAN生成的样本丢给Inception网络，输出类别概率，对于同一类别的图片，其输出的概率分布应该趋向于一个脉冲分布，可以保证生成样本的准确性。对于所有类别，其输出的概率分布应该趋向于一个均匀分布，这样不会出现mode dropping保证生成样本的多样性。</li> <li><strong>FID (Fréchet Inception Distance )</strong>：计算真实样本和生成样本在特征空间之间的距离。首先利用Inception网络来提取特征，然后使用高斯模型对特征空间进行建模。根据高斯模型的均值和协方差来进行距离计算。</li> <li><strong>Mode Score</strong>：Inception Score的改进版本，添加了生成样本和真实样本预测的概率分布相似性度量。</li> <li><strong>Kernel MMD(maximum mean discrepancy)</strong></li> <li><strong>Wasserstein distance</strong></li> </ul>]]></content><author><name>Tintin</name></author><category term="GAN"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Mean Field Theory Solution of the Ising Model</title><link href="https://tingtingliao.github.io/blog/2020/MeanFieldTheory/" rel="alternate" type="text/html" title="Mean Field Theory Solution of the Ising Model"/><published>2020-03-21T00:00:00+00:00</published><updated>2020-03-21T00:00:00+00:00</updated><id>https://tingtingliao.github.io/blog/2020/MeanFieldTheory</id><content type="html" xml:base="https://tingtingliao.github.io/blog/2020/MeanFieldTheory/"><![CDATA[<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <p> </p> <h3 id="一相变">一、相变</h3> <ul> <li><strong>相</strong>： 具有均匀物理性质的热力学系统。如水固相、液相、气相。</li> <li><strong>相变</strong>： 从一种相转变成另一种相。如冰融化成水是固-液相变，铁磁-顺磁相变，超导体-正常导体相变，几何相变（渗流），量子相变等。</li> <li><strong>相变产生因素？</strong><br/> 导致相变产生的物理量有：温度T、压强P等。这些物理量本质上影响的是①物质内部粒子间的相互作用 ②粒子自身的热运动。</li> <li><strong>如何描述相？</strong> <ol> <li>状态转换成能量。 Hamiltonian 哈密尔顿量 \(H\) 表示某一状态 \(\Gamma\) 下系统能量。</li> </ol> </li> </ul> \[H=H(\Gamma)\] <ol> <li>能量转换成概率。即出现这一状态的概率，这就是玻尔兹曼分布。</li> </ol> \[F(state) \propto e^{-\frac{H(state)}{kT}}\] \[p = \frac{e^{-\frac{H}{kT}}}{Z} \quad \quad Z = \sum_{\Gamma} e^{-\frac{H(\Gamma)}{kT}}\] <ul> <li>\(k\) 为玻尔兹曼常数。</li> <li>\(Z\) 为配分函数(partition function). 所有状态下能量和，可看做是归一化函数。 \(Z\) 为定值。</li> <li>\(p\) 与\(H\) 成反比。系统中粒子间对抗性越强，能量越高，相变概率高，该状态出现概率低。</li> <li>\(p\) 与 \(T\) 成正比。</li> </ul> <h3 id="二-ising-model">二、 Ising model</h3> <h4 id="21-哈密尔顿量-h">2.1 哈密尔顿量 H</h4> <p>伊辛模型用于描述物质磁铁性模型。 <img src="\img\MeanFieldTheory\ising1.png" alt=""/> 假设有 \(N\)个粒子，每个粒子有两个自旋方向\(s \in \{-1,+1\}\)分别表示向下和向上，系统共有 \(2^N\) 种状态。状态 \(s\) 下系统哈密尔顿量由两部分组成：</p> \[H(s)=-J\sum_{ \left \langle i,j \right \rangle }s_is_j -h\sum_{i=1}^N s_i \\\] <ul> <li>相邻粒子对间作用。 \(J\)是正常数，表示粒子对之间的磁铁性， \(\left \langle i,j \right \rangle\) 表示所有响铃自旋对。若 \(i, j\)同号能量小\(-s_is_j\) 为负数。若 \(i, j\)异号对抗性大，能量大 \(-s_is_j\)正数。</li> <li>外场对粒子作用。 \(h\) 为沿 \(z\) 方向的磁场。</li> </ul> <h4 id="22-配分函数-z">2.2 配分函数 Z</h4> \[Z = \sum_{\Gamma} e^{-\beta H} \quad \quad (\beta=\frac{1}{kT})\] \[\sum_{\Gamma} = \sum_{s_1=\pm 1}\sum_{s_2=\pm 1}\dots\sum_{s_N=\pm 1} =\prod_{i=1}^N\left ( \sum_{s_i \in \{+1,-1\}} \right )\] \[\begin{split} \sum_{\Gamma} \rightarrow Tr \end{split}\] <p>\(Tr\)表示所有可能状态之和。</p> \[Z = Tr(e^{-\beta H})\] <p><strong>配分函数\(Z\) 需要计算\(2^N\)个状态，随着 N 增加，计算量呈指数增长。而且当维度扩展到高维空间时，这种计算方式就无法求解。有没有一种方法能够在任意维度下都是通用的，且计算更简单？平均场理论。</strong></p> <h3 id="三weiss-molecular-filed-theory">三、Weiss Molecular Filed Theory</h3> <h4 id="31-分解hamiltonian">3.1 分解Hamiltonian</h4> \[\begin{split} s_i=\left \langle s_i \right \rangle\:&amp;+ \quad \delta_i\\ [mean] &amp;\quad [fluctuation] \\ \delta_i = s_i-\: &amp;\left \langle s_i \right \rangle \\ \left \langle s_i \right \rangle = m\quad&amp; \end{split}\] <p>将自旋取值用均值和波动表示，均值是整个系统粒子取值的期望，那么每个粒子不同的则是波动部分。根据上式，粒子间的作用可以转化为：</p> \[\begin{split} s_is_j &amp;= (\left \langle s_i \right \rangle + \delta_i)(\left \langle s_j \right \rangle + \delta_j)\\ &amp; \approx \left \langle s_i \right \rangle\left \langle s_j \right \rangle + \left \langle s_i \right \rangle \delta_j +\left \langle s_j \right \rangle \delta_i \quad \quad (\delta_i\delta_j很小忽略不计)\\ &amp;=m^2 + m(s_j - m) + m(s_i-m)\\ &amp;=m(s_i+s_j-m)\\ \end{split}\] <p>将其代入 \(H\) 中，</p> \[\begin{split} H&amp;=-J\sum_{\left \langle i,j \right \rangle}s_is_j-h\sum_{i}^{N}s_i\\ &amp;= -J\sum_{\left \langle i,j \right \rangle}m(s_i+s_j-m)-h\sum_{i}^{N}s_i\\ &amp;= -mJ\sum_{\left \langle i,j \right \rangle}(2s_i-m)-h\sum_{i}^{N}s_i\\ \end{split}\] <p>其中 \(\sum_{\left \langle i,j \right \rangle}\)是对所有相邻粒子对求和，可以进一步表示为以下形式， \(neighbor(i)\)表示粒子\(i\)的邻居，所有的点都会计算两次所以系数为 \(\frac{1}{2}\) 。而求和只与\(i\) 有关，因此 \(\sum_{j\in neighor(i)}\)为邻居个数 \(q\) ,一维空间 \(q=2\) ，二维空间 \(q=4\)，三维空间 \(q=6\) .</p> \[\sum_{\left \langle i,j \right \rangle}=\frac{1}{2}\sum_{i=1}^N\sum_{j\in neighor(i)}=\frac{q}{2}\sum_{i=1}^N\] <p>继续对 \(H\) 进行简化：</p> \[\begin{split} H&amp;=-mJ\sum_{\left \langle i,j \right \rangle}(2s_i-m)-h\sum_{i}^Ns_i\\ &amp;=-\frac{qmJ}{2}\sum_{i=1}^N(2s_i-m)-h\sum_{i}^{N}s_i\\ &amp;=\frac{Nqm^2J}{2}-(qmJ+h)\sum_{i=1}^Ns_i\\ \end{split}\] <p>原来的哈密尔顿量\(H\) 需要对电子对之间作用\(s_is_j\)以及外场作用 \(s_i\)分别求和。经过平均场变换过后，只需对 \(s_i\)求和，无需考虑电子对之间的相互作用。<strong>简而言之，用平均场代替所有其它粒子对该粒子的相互作用，粒子之间无需进行交互，所有粒子只与平均场交互，使得多体问题转变为单体问题。</strong></p> \[H =\frac{Nqm^2J}{2}-h_{eff}\sum_{i=1}^Ns_i\quad [h_{eff}=qmJ+h]\] <p>注：整个式子中m是未知的。</p> <h4 id="32-配分函数-z">3.2 配分函数 Z</h4> \[\begin{split} Z&amp;=Tr(e^{-\beta H})\\ &amp;=\prod_{i=1}^{N}\sum_{s_i \in \{-1, 1\}} e^{-\frac{\beta NqJm^2}{2}}e^{\beta h_{eff}\sum_{i=1}^{N}s_i} \quad \quad \\ &amp;=e^{-\frac{\beta NqJm^2}{2}} \sum_{s_1\in \{-1, 1\}}\dots\sum_{s_n \in \{-1, 1\}}(e^{\beta h_{eff}s_1}e^{\beta h_{eff}s_2}\dots e^{\beta h_{eff}s_n})\\ &amp;=e^{-\frac{\beta NqJm^2}{2}}\prod_{i=1}^{N}\sum_{s_i \in \{-1, 1\}} e^{\beta h_{eff}s_i}&amp; \\ &amp;=e^{-\frac{\beta NqJm^2}{2}}\prod_{i=1}^{N}( e^{\beta h_{eff}} + e^{-\beta h_{eff}}) \\ &amp;=e^{-\frac{\beta NqJm^2}{2}}(2\cosh(\beta h_{eff}))^N\quad \quad[\cosh x=\frac{e^{x}+e^{-x}}{2}]\\ \end{split}\] <h4 id="33-求解平均场m">3.3 求解平均场M</h4> <p>\(m\) 表示整个系统的平均值, \(\left \langle s_i \right \rangle\) 表示粒子\(i\) 的平均值，注：这里 \(\left \langle s_i \right \rangle\)不再是\(m\)而是粒子\(i\)实际计算出来的均值。</p> \[m=\frac{1}{N}\sum_{i=1}^N \left \langle s_i \right \rangle\] <p>粒子 \(i\) 的平均值表示，所有状态下粒子 i 取值与其概率乘积总和。以下忽略下标 \(i\) ,粒子 \(s\)的均值：</p> \[\begin{split} \left \langle s \right \rangle &amp; = \sum_{\Gamma} ps\\ &amp;= Tr(ps)\\ &amp;=Tr( \frac{e^{-\beta H}}{Z}s)\\ &amp;=\frac{1}{Z}Tr(se^{-\beta H}) \\ \end{split} \\ \begin{split} m&amp;=\frac{1}{N}\sum_{i=1}^N \left \langle s_i \right \rangle\\ &amp;=\frac{1}{N}\frac{1}{Z}\sum_{i=1}^N Tr(s_ie^{-\beta H})\\ &amp;=\frac{1}{N}\frac{1}{Z} Tr(\sum_{i=1}^Ns_ie^{-\beta H})\\ \end{split}\] <p>到这里好像不知道怎么进行化简了。而 \(Z=Tr(e^{-\beta H})\)与[1]式有相似的形式，少了一项 \(\sum_{i=1}^N s_i\)， 可以对\(H\)求导得到\(\sum_{i=1}^N s_i = -\frac{\partial H}{\partial h_{eff}}\)</p> \[\begin{split} Tr(\sum_{i=1}^N(s_ie^{-\beta H}))&amp;\rightarrow Tr(e^{-\beta H}\sum_{i=1}^Ns_i ) \quad [1]\\ &amp;\rightarrow Tr(-e^{-\beta H} \frac{\partial H}{\partial h_{eff}} )\\ &amp;\rightarrow Tr(\frac{1}{\beta}\frac{\partial e^{-\beta H} }{\partial h_{eff}} )\\ &amp;\rightarrow \frac{1}{\beta}\frac{\partial Tr(e^{-\beta H} )}{ \partial h_{eff}}\\ &amp; \rightarrow\frac{1}{\beta} \frac{\partial Z}{ \partial h_{eff}} \end{split}\] <p>从而</p> \[\begin{split} m&amp;=\frac{1}{N}\frac{1}{Z}\frac{1}{\beta} \frac{\partial Z}{ \partial h_{eff}}\\ &amp;=\frac{1}{N}\frac{1}{\beta} \frac{\partial \ln Z}{ \partial h_{eff}}\\ \end{split}\] <p>对 Z 的化简形式取对数求导：</p> \[\begin{split} Z &amp;=e^{-\frac{\beta NqJm^2}{2}}(2\cosh(\beta h_{eff}))^N\quad \\ \ln Z &amp;=-\frac{\beta NqJm^2}{2}+N\ln2 + N\ln \cosh(\beta h_{eff})\\ \frac{\partial \ln Z}{ \partial h_{eff}}&amp;= N\beta \tanh (\beta h_{eff}) \end{split}\] <p>即可得到最终的 \(m\) ，形式特别优美</p> \[\begin{split} m&amp;=\tanh (\beta h_{eff})\\ m&amp;=\tanh (\beta(qJm+h)) \quad \beta=\frac{1}{kT} \end{split}\] <p>这个式子中右边也有 \(m\) , 很难对方程直接求解，给定参数 \(\beta, q,J,h\)可以通过画图的方式寻找两函数交点. 我们考虑 \(h=0\) 即没有外场作用的情况，这时方程求解有两种情况：</p> <ul> <li>\(\beta qJ\leq 1\:(kT\geq qT)\)：有唯一解 \(m=0\) 系统为顺磁态。</li> <li>\(\beta qJ&gt; 1\:(kT&lt;qT)\)：有三个解 \(m=0\) 以及\(m=\pm m_0, m_0\leq 1， m_0\) 时候系统为铁磁态。而 \(m=0\)时，系统中粒子不再与平均场交互，系统随机性很强不稳定，因此我们只考虑 \(m=\pm m_0\) 两种解。</li> </ul> <p>上述我们可以看到，临界状态为 \(\beta qJ=1\),即</p> \[kT=qJ\] <p>一维空间 \(q=2,kT=2J\) ；二维空间 \(kT=4J\) ；</p> <h4 id="34-总结">3.4 总结</h4> <p>根据上面的推导过程，给定参数，从而确定平均场 \(m\) 的值，进而计算出Hamiltonian和配分函数</p> \[\begin{split} m&amp;=\tanh (\beta h_{eff})\\ H &amp;=\frac{Nqm^2J}{2}-h_{eff}\sum_{i=1}^Ns_i\\ Z&amp;=e^{-\frac{\beta NqJm^2}{2}}(2\cosh(\beta h_{eff}))^N \\ \end{split}\] <p>通过平均场理论， \(H\) 与 \(Z\) 的计算大大简化了，并且可以适用于高维空间2D，3D等。</p>]]></content><author><name>Tintin</name></author><category term="Physics"/><category term="Main Filed Theory"/><category term="Boltzman Distribution"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Faster RCNN</title><link href="https://tingtingliao.github.io/blog/2020/FasterRCNN/" rel="alternate" type="text/html" title="Faster RCNN"/><published>2020-02-12T00:00:00+00:00</published><updated>2020-02-12T00:00:00+00:00</updated><id>https://tingtingliao.github.io/blog/2020/FasterRCNN</id><content type="html" xml:base="https://tingtingliao.github.io/blog/2020/FasterRCNN/"><![CDATA[<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <p> </p> <h2 id="简介">简介</h2> <p></p> <p>\(Faster \: RCNN\)主要包含：</p> <ul> <li>\(Head\: (CNN)\).</li> <li>\(Region\: Proposal\: Network\: (RPN)\).</li> <li>\(RoI \: Pooling\).</li> <li>\(Classification\: Network\). <img src="http://www.telesens.co/wp-content/uploads/2018/03/img_5aa70ff399c57.png"/></li> </ul> <p>在介绍\(Region \: Proposal\: Network\)之前，先了解下\(Anchor\)：</p> <font color="blue">1. Anchor是什么？它的作用是什么？</font> <p>目标检测不同于分类，不仅需要输出物体的类别，还需要定位物体的位置。训练过程是对损失函数优化求解过程，损失函数需要真实值（Ground Truth GT）与预测值（Prediction）构造，目标检测中GT由物体真实class+bbox组成，关键是相应的bbox_pred如何得到？构造。就像神经网络中权重最开始是随机初始化，前向得到不准确的值，再反馈调整权重使得预测值逼近真实值。同样的，我们先生成很多个框（Anchor），再后续进行调整。</p> <font color="blue">2. Anchor如何构造，需要考虑什么因素？</font> <ul> <li>大小（scale）。 比如桌子上的杯子，桌子与杯子的面积大小不一。</li> <li>长宽比（ratio）。比如人脸与行人的长宽比例是不一样的。</li> <li>位置（Location）。除了框的形状，还需要空间位置信息，即Anchor的坐标。</li> </ul> <p>本文内容：</p> <blockquote> <ol> <li>Anchor Generation Layer: 生成Anchor</li> <li>RPN Network: Featutre Maps经过该层得到Anchor的前景/背景概率，以及类别信息</li> <li>Proposal Layer: 筛选Anchor</li> <li>RoI Pooling: 对feature变换为统一长度输入到FC层。</li> </ol> </blockquote> <h3 id="1-generate-anchor">1. Generate Anchor</h3> <p><strong>只考虑scale和ratio</strong>。假设原图\(400×400\)。我们选取三种长宽比[2, 1, 0.5],三种scale[0.5,0.25,0.125],得到\(9\)个不同的anchor.</p> <table> <thead> <tr> <th style="text-align: center">scale\ratio</th> <th style="text-align: center">2:1</th> <th style="text-align: center">1:1</th> <th style="text-align: center">1:2</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(200×200（\frac{1}{2}）\)</td> <td style="text-align: center">\(282.8×141.4\)</td> <td style="text-align: center">\(200×200\)</td> <td style="text-align: center">\(141.4 × 282.8\)</td> </tr> <tr> <td style="text-align: center">\(100×100（\frac{1}{4}）\)</td> <td style="text-align: center">\(141.4×70.7\)</td> <td style="text-align: center">\(100×100\)</td> <td style="text-align: center">\(70.7×141.4\)</td> </tr> <tr> <td style="text-align: center">\(50×50（\frac{1}{8}）\)</td> <td style="text-align: center">\(70.7×35.3\)</td> <td style="text-align: center">\(50×50\)</td> <td style="text-align: center">\(35.3×70.7\)</td> </tr> </tbody> </table> <p><img src="/img/fasterRCNN/anchor.png" alt=""/> 计算过程如下： <br/> ① 计算anchor的长宽 \(w = 400 * scale , h = 400 * scale\)<br/> ② anchor面积 \(s = w * h\) <br/> ③ 根据ratio计算anchor长宽 \(w = \sqrt{\frac{s}{ratio}}, h= \sqrt{s*ration} \quad (\frac{h}{w}=ratio)\) <br/> ④ 以原点为中心计算对角顶点坐标。 \(x_1, y_1 = - \frac{w}{2}, - \frac{h}{2}; x_2, y_2 = \frac{w}{2}, \frac{h}{2}\)</p> <p><strong>考虑位置。</strong>这9个anchor放在图片的哪些位置？我们并不知道，那么就遍历整张图片，将每个像素点作为中心点生成9个anchor，如下左图，黑色边框为原图。这样生成的anchor就足以覆盖整张图片（下右图）。 <img src="/img/fasterRCNN/anchor_2.png" alt=""/></p> <p><img src="/img/fasterRCNN/new.gif" alt=""/> <img src="https://imgedu.lagou.com/1519578-20190519142329908-1012988523.png"/></p> <p>长宽比scale\((0.5, 1, 2)\)<br/> 面积大小\(（8*8， 16*16， 32*32）\) <br/> 输入图片大小为\(800*600\)<br/> stride=16的意思是每隔16个点取一个点生成9个anchor,那么则有\(\frac{800}{16}*\frac{600}{16}*9 = 1900*9\)个anchor。计算过程也很简单，首次计算9个anchor的顶点坐标后,取下一个点直接将9个anchor的对应坐标平移一位即可，一直重复向右向下平移即可得到上右图红色框。</p> <h2 id="2-region-proposal-network">2. Region Proposal Network</h2> <p> </p> <p><img src="/img/fasterRCNN/RPN.png" alt=""/></p> <h4 id="21-anchor分类为前景和背景">2.1 anchor分类为前景和背景</h4> <p>① feature map\(（W×H）\)经过3×3卷积大小不变，因为padding=1,相当于长宽都扩充了2个像素。<br/> ② 再经过1×1的卷积核（channel=18）变为\(W×H×18\)<br/> ③ reshape成\((W×H×9, 2)，W×H×9\)表示anchor数量，2表示前景/背景。<br/> ④ softmax得到最终每个anchor的二分类概率。</p> \[Classification\: Loss = cross\_entropy(pred\_class, actual\_class)\] <h4 id="22-bbox-regression">2.2 Bbox Regression</h4> <p>同样的，bbox的shape为\(（M×N×9，4）\)，表示每个anchor的左上顶点与长宽\(（x_a, y_a, w_a, h_a）\)。那么这里的损失函数如何构造？预测的anchor如何与ground truth的boxes联系起来？</p> \[t_x = \frac{x_a - x}{w_a}\quad t_y = \frac{y_a - y}{h_a}\] \[t_w = \log(\frac{w}{w_a}) \quad t_h=\log(\frac{h}{h_a})\] <p>回归系数\((t_x, t_y, t_w, t_h)\)表示bbox的平移量和缩放量。如果用回归系数的绝对值作为损失函数即为\(L_1\)损失，但是这样在零点处不可导，且梯度在训练过程中一直不变，导致再后期很难收敛。</p> \[L_1 = |x| \qquad \frac{d L_1}{dx}=\left\{\begin{matrix} 1,\quad x\geq 0\\ -1, \quad otherwise \end{matrix}\right.\] <p>而\(L_2\)损失在随着\(x\)的变化更新梯度，但是在训练前期差异很大时，梯度也很大训练不稳定。</p> \[L_2 = x^2 \qquad \frac{d L_2}{dx}=2x\] <p>\(smooth_{L_1}\)损失则考虑：（1）当预测值与真实值差别很大时，梯度不至于过大。（2）当预测值与真实值差别很小时，梯度足够小。</p> \[smooth_{L_1} = \left\{\begin{matrix} 0.5 x^2, \quad |x|&lt;1\\ |x|-0.5, \quad otherwise \end{matrix}\right. \qquad \frac{d\,smooth_{L_1}}{dx}=\left\{\begin{matrix} x, \quad |x|&lt;1\\ \pm 1 , \quad |x|&gt;1 \end{matrix}\right.\] <h4 id="23-anchor-target-layer">2.3 Anchor Target Layer</h4> <p>在计算损失时，并不是将所有的Anchor都拿去计算。举个例子，班级中学生成绩参差不齐，老师的目标不是让每个学生都上清华北大，而是选出一批潜力大的学生来培养即可。对于“差生”来说这个目标不太实际，同样的将差异悬殊的Anchor与Ground Truth进行BBox训练回归也是无效任务。</p> <p>那么，“优等生”与“差生”需要一个评价标准：<strong>IoU（Intersection of Union）</strong>。IoU用来衡量两个区域交叉重叠的程度。Anchor与Ground Truth的交叉区域大于前景阈值（RPN_POSITIVE_OVERLAP）时，将其标为前景（foreground），小于背景阈值（RPN_NEGATIVE_OVERLAP）标为背景（background），忽略既不是前景也不是背景的anchor。</p> <p>将选出来的Anchor计算损失训练RPN Network。注：Bounding Box Loss只用前景的Anchor计算，因为Gound Truth只有前景物体。</p> <h2 id="3-proposal-layer">3. Proposal Layer</h2> <p><img src="https://imgedu.lagou.com/1519578-20190519142328864-596380774.png"/> </p> <h2 id="3-roi-pooling">3. ROI Pooling</h2> <p>ROI Pooling是在SPPNet对RCNN的改进。将feature map中对应ROI区域扣出来，即原图ROI在feature map上位置的映射，再划分网格统一大小输入到FC层。</p>]]></content><author><name>Tintin</name></author><category term="CV"/><category term="Detection"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Object Detection Milestones</title><link href="https://tingtingliao.github.io/blog/2020/ObjectDetection/" rel="alternate" type="text/html" title="Object Detection Milestones"/><published>2020-02-02T00:00:00+00:00</published><updated>2020-02-02T00:00:00+00:00</updated><id>https://tingtingliao.github.io/blog/2020/ObjectDetection</id><content type="html" xml:base="https://tingtingliao.github.io/blog/2020/ObjectDetection/"><![CDATA[<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <p>本文参考：<a href="https://arxiv.org/pdf/1905.05055.pdf">Object Detection in 20 Years: A Survey</a>. <br/> 以下仅对目标检测领域的发展历史做总结性介绍，不描述算法详细细节。</p> <p><img src="https://www.researchgate.net/profile/Zhengxia_Zou/publication/333077580/figure/fig2/AS:758306230501380@1557805702766/A-road-map-of-object-detection-Milestone-detectors-in-this-figure-VJ-Det-10-11-HOG.ppm" width="700"/></p> <h3 id="一-传统算法">一、 传统算法</h3> <table> <thead> <tr> <th style="text-align: center">Year</th> <th style="text-align: center">Algorithm</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(2001\)</td> <td style="text-align: center">\(Viola \: Jones\: Detectors\)</td> </tr> <tr> <td style="text-align: center">\(2005\)</td> <td style="text-align: center">\(HOG\: Detector\)</td> </tr> <tr> <td style="text-align: center">\(2008\)</td> <td style="text-align: center">\(Deformable\: Part-based\: Model (DPM)\)</td> </tr> </tbody> </table> <h3 id="二-two-stage-detector">二. Two-stage Detector</h3> <p>2001-2012是传统算法的时代，从2012年自AlexNet起深度学习开始风起云涌。</p> <table> <thead> <tr> <th style="text-align: center">Year</th> <th style="text-align: center">Mathod</th> <th style="text-align: center">Algorithm</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(2014\)</td> <td style="text-align: center">\(RCNN\)</td> <td style="text-align: center">\(Selective\: Search+CNN+SVM\)</td> </tr> <tr> <td style="text-align: center">\(2014\)</td> <td style="text-align: center">\(SPPNet\)</td> <td style="text-align: center">\(CNN+Selective\: Search+SPP+SVM\)</td> </tr> <tr> <td style="text-align: center">\(2015\)</td> <td style="text-align: center">\(Fast \: RCNN\)</td> <td style="text-align: center">\(CNN +Selective\: Search+ ROI + Softmax\)</td> </tr> <tr> <td style="text-align: center">\(2015\)</td> <td style="text-align: center">\(Faster \: RCNN\)</td> <td style="text-align: center">\(CNN+RPN+ ROI+BBoxReg+Classify\)</td> </tr> </tbody> </table> <p><img src="/img/2020_object_detection/rcnn1.png" alt=""/></p> <p>以下列出了每个算法所需要了解的相关算法：<br/> <strong>RCNN:</strong> selective search, 基于图的图像分割算法Graph-Based Image Segmentation<br/> <strong>SPPNet:</strong> SPPNet原理<br/> <strong>Fast RCNN:</strong> ROI Pooling<br/> <strong>Faster RCNN:</strong> Anchor生成、Region Proposal Network（RPN），NMS非极大值抑制</p> <p><img src="/img/2020_object_detection/twostage.jpg" alt=""/></p> <p>two-stage中常见的算法</p> <h3 id="三-one-stage-detector">三. One-stage Detector</h3> <table> <thead> <tr> <th style="text-align: center">Year</th> <th style="text-align: center">Method</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(2015\)</td> <td style="text-align: center">\(YOLO\)</td> </tr> <tr> <td style="text-align: center">\(2016\)</td> <td style="text-align: center">\(SSD\)</td> </tr> <tr> <td style="text-align: center">\(2017\)</td> <td style="text-align: center">\(FPN\)</td> </tr> <tr> <td style="text-align: center">\(2017\)</td> <td style="text-align: center">\(RetinaNet\)</td> </tr> </tbody> </table>]]></content><author><name>Tintin</name></author><category term="CV"/><category term="Detection"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Variance Reduction</title><link href="https://tingtingliao.github.io/blog/2019/VarienceReduction/" rel="alternate" type="text/html" title="Variance Reduction"/><published>2019-05-07T00:00:00+00:00</published><updated>2019-05-07T00:00:00+00:00</updated><id>https://tingtingliao.github.io/blog/2019/VarienceReduction</id><content type="html" xml:base="https://tingtingliao.github.io/blog/2019/VarienceReduction/"><![CDATA[<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <p>本文证明了在凸与非凸两种情况下，方差缩减算法的梯度方差期望的bound。 以及在目标函数分别为：强凸、非强凸、非凸组合\(f_i(x)\)与非强凸函数\(f(x)\)三种情况下SVRG的收敛速率。</p> <h1 id="1-lemma">1. Lemma</h1> <h4 id="lemma-1l-smooth"><strong>Lemma 1</strong>：【\(L-smooth\)】</h4> \[g(x_{k+1}) \leq g(x_k)-\frac{1}{2L}\|\triangledown g(x_k)\|^2\] <p><strong>Proof</strong>:</p> \[\begin{split} g(x_{k+1})&amp;\leq g(x_k) + \triangledown g(x_k)(x_{k+1}-x_k) + \frac{L}{2}||x_{k+1}-x_k||^2\\ &amp;\leq g(x_k)-\eta ||\triangledown g(x_k)||^2 + \frac{L\eta^2}{2}||\triangledown g(x_k)||^2\\ &amp; \leq g(x_k)-\frac{1}{2L}||\triangledown g(x_k)||^2 \end{split}\] <p>第一个不等式根据\(L-smooth\),第二个不等式根据\(x_{k+1}-x_k = -\eta \triangledown g(x_k)\),第三个不等式取\(\eta = \frac{1}{L}\).</p> <h4 id="lemma-2凸"><strong>Lemma 2</strong>：【凸】</h4> \[\|\triangledown f(x_k)- \triangledown f(x^*)\|^2 \leq 2L (f(x_k)-f(x^*)-\triangledown f(x^*)(x_k-x^*))\] <p><strong>Proof</strong>: 假若有凸函数\(f(x)\),\(令 g(x) = f(x)-f(x^*)-\triangledown f(x^*)(x-x^*)\),根据凸性质\(\forall x\in R^d\)有\(g(x)\geq 0\),根据定理1:</p> \[\begin{split} 0=g(x^*)&amp;\leq g(x_{k+1}) = g(x_k)-\frac{1}{2L}||\triangledown g(x_k)||^2\\ ||\triangledown f(x_k)- \triangledown f(x^*)||^2 &amp;\leq 2L (f(x_k)-f(x^*)-\triangledown f(x^*)(x_k-x^*)) \end{split}\] <h4 id="lemma-3-非凸"><strong>Lemma 3</strong>： 【非凸】</h4> \[\|\triangledown f(x_k)- \triangledown f(x^*)\|^2 \leq 4(L+l) (f(x_k)-f(x^*)-\triangledown f(x^*)(x_k-x^*)) + (4l^2+2Ll)\|x_k-x^*\|^2\] <p>下面先回顾非凸定义再给出证明。我们知道函数\(f(x)\)是L-smooth满足：</p> \[- \frac{L}{2}\|y-x\|^2\leq f(y) - f(x)+\left \langle \triangledown f(x),y-x \right \rangle \leq \frac{L}{2}\|y-x\|^2\] <p>下面我们定义\(L-\)upper smooth以及\(l-\)lower smooth满足：</p> \[- \frac{l}{2}\|y-x\|^2\leq f(y) - f(x)+\left \langle \triangledown f(x),y-x \right \rangle \leq \frac{L}{2}\|y-x\|^2\] <p>举个例子，凸函数有\(0-\) lower smooth,\(L-smooth\)函数有\(L-\)upper smooth和\(L-\)lower smooth,一个凸且L光滑函数有\(0-\) lower smooth和\(L-\)upper smooth。</p> <p>这里需要注意的是，当函数\(f(x)\)的lower smooth\(l=0\)时函数是凸的，当\(l&gt;0\)时是非凸的。</p> <p><strong>Proof</strong>: 对于非凸函数\(f(x)\),\(令 g(x) = f(x)-f(x^*)-\triangledown f(x^*)(x-x^*)+\frac{l}{2}\|x_k-x^*\|^2\)这时\(g(x)\)依旧为凸函数且为\((L+l)-smooth\)：</p> \[\begin{split} 0 &amp;\leq g(x_k)-\frac{1}{2(L+l)}||\triangledown g(x_k)||^2\\ ||\triangledown f(x_k)- \triangledown f(x^*)+l(x_k-x^*)||^2 &amp;\leq 2(L+l) (f(x_k)-f(x^*)-\triangledown f(x^*)(x_k-x^*)+\frac{l}{2}\|x_k-x^*\|^2) \end{split}\] <p>下面计算\(\|\triangledown f(x_k)- \triangledown f(x^*)\|^2\)</p> \[\begin{split} \|\triangledown f(x_k)- \triangledown f(x^*)]\|^2 &amp;\leq 2 \|\triangledown f(x_k)- \triangledown f(x^*)+l(x_k-x^*)\|^2 +2\|l(x_k-x^*)\|^2 \\ &amp;\leq 4(L+l) (f(x_k)-f(x^*)-\triangledown f(x^*)(x_k-x^*)) + (2Ll+4l^2)\|x_k-x^*\|^2 \end{split}\] <h1 id="2-varience-bound">2. Varience Bound</h1> <p><strong>Proof</strong>:</p> \[\tilde{\triangledown}f(x_k) = \triangledown_i f(x_k) - \triangledown_i f(\tilde{x})+\triangledown f(\tilde{x})\] \[\begin{split} E||\tilde{\triangledown}f(x_k) - \triangledown f(x_k)||^2 &amp;= E ||\triangledown_i f(x_k) - \triangledown_i f(\tilde{x})+\triangledown f(\tilde{x})-\triangledown f(x_k)||^2 \\ &amp; \leq E ||\triangledown_i f(x_k) - \triangledown_i f(\tilde{x})||^2 \\ &amp; \leq 2E ||\triangledown_i f(x_k) - \triangledown_i f(x^*)||^2 +2E||\triangledown_i f(\tilde{x}) -\triangledown_i f(x^*)||^2 \\ &amp;= 2 ||\triangledown f(x_k) - \triangledown f(x^*)||^2 +2 ||\triangledown f(\tilde{x}) -\triangledown f(x^*)||^2 \\ \end{split}\\\] <p>第一个不等式根据\(E\|\zeta - E\zeta \|^2 = E\|\zeta\|^2 - \|E \zeta\|^2\leq E\|\zeta\|^2\),第二个不等式根据\(\|a^2\pm b^2\| \leq 2\|a\|^2+2\|b\|^2\)</p> <h4 id="21-convex">2.1 Convex</h4> <p>当\(f(x)\)为凸函数时，根据Lemma 2，其中\(\triangledown f(x^*) = 0\)可以得到：</p> \[E||\tilde{\triangledown}f(x_k) - \triangledown f(x_k)||^2 \leq 4L (f(x_k)-f(x^*) + f(\tilde{x})-f(x^*)\] <h4 id="22-nonconvex">2.2 Nonconvex</h4> <p>当\(f(x)\)为非凸函数时，根据Lemma 3，其中\(\triangledown f(x^*) = 0\)可以得到：</p> \[E||\tilde{\triangledown}f(x_k) - \triangledown f(x_k)||^2 \leq 8(L+l) (f(x_k)-f(x^*)+f(\tilde{x})-f(x^*)) + (8l^2+4Ll)(\|x_k-x^*\|^2 +\|\tilde{x}-x^*\|^2)\] <h1 id="3-svrg收敛速率">3. SVRG++收敛速率</h1> <h3 id="31-non-strongly-convex-objective">3.1 Non Strongly Convex Objective</h3> <p><strong>Problem Definition：</strong></p> \[\min_x F(x) := \frac{1}{n} \sum_{i=1}^{n} f_i (x) + \psi(x)\] <p>\(f(x)\)为凸函数且\(L-smooth\),\(\psi(x)\)不光滑.当\(\psi(x)=0\)上式依旧成立。</p> <p><strong>Key Lemma:</strong></p> \[F(x_{k+1})-F(x^*)\leq \frac{ \eta}{2(1-\eta L)}\|\tilde{\triangledown} f(x_k)-\triangledown f(x_k)\|^2 + \frac{\|x_k-x^*\|^2-\|x_{k+1}-x^*\|^2}{2\eta}\] <p><strong>Proof</strong>：</p> \[\begin{split} F(x_{k+1})-F(x^*) &amp;= f(x_{k+1})-f(x^*)+\psi(x_{k+1})-\psi (x^*)\\ &amp;\leq f(x_k) - \triangledown f(x_k)(x_{k+1}-x_k) +\frac{L}{2}\|x_{k+1}-x_k \|^2-f(x^*)+\psi(x_{k+1})-\psi (x^*) \\ &amp;\leq \left \langle \triangledown f(x_k), x_k-x^* \right \rangle - \triangledown f(x_k)(x_{k+1}-x_k) +\frac{L}{2}\|x_{k+1}-x_k \|^2+\psi(x_{k+1})-\psi (x^*) \end{split}\] <p>第一个不等式根据<strong>L-smooth</strong>，第二个不等式根据<strong>凸性值</strong>。</p> \[\begin{split} &amp; \left \langle \triangledown f(x_k), x_k-x^* \right \rangle +\psi(x_{k+1})-\psi (x^*)\\ \leq&amp; \left \langle \tilde{\triangledown} f(x_k), x_k-x_{k+1} \right \rangle +\left \langle \tilde{\triangledown} f(x_k), x_{k+1}-x^* \right \rangle +\left \langle g, x_{k+1}-x^* \right \rangle \\ =&amp; \left \langle \tilde{\triangledown} f(x_k), x_k-x_{k+1} \right \rangle + \left \langle \tilde{\triangledown} f(x_k)+g, x_{k+1}-x^* \right \rangle \\ = &amp; \left \langle \tilde{\triangledown} f(x_k), x_k-x_{k+1} \right \rangle + \left \langle -\frac{1}{\eta}(x_{k+1} -x_k), x_{k+1}-x^* \right \rangle\\ =&amp;\left \langle \tilde{\triangledown} f(x_k), x_k-x_{k+1} \right \rangle + \frac{\|x_k-x^*\|^2}{2\eta}-\frac{\|x_{k+1}-x^*\|^2}{2\eta}-\frac{\|x_{k+1}-x_{k}\|^2}{2\eta} \end{split}\] <p>其中第一个不等式根据\(\psi(x)\)的凸性质，\(g\in \partial \psi(x)\)是次梯度;第二个等号根据近似梯度\(x_{k+1} = \min_y \{ \triangledown f(x_k)(y-x_k) + \frac{1}{2\eta} \|y-x_k\|^2 + \psi(y) \}\)，其满足\(\triangledown f(x_k) +\frac{1}{\eta}(x_{k+1} -x_k) +g = 0\)。当\(\psi(x)=0\)时，\(\triangledown f(x_k) +\frac{1}{\eta}(x_{k+1} -x_k)= 0\)，上式依成立。结合上式子可以得到：</p> \[\begin{split} &amp;F(x_{k+1})-F(x^*)\\ \leq &amp; \left \langle \tilde{\triangledown} f(x_k)-\triangledown f(x_k), x_k-x_{k+1} \right \rangle-\frac{1-\eta L}{2\eta}\|x_{k+1}-x_{k}\|^2 + \frac{\|x_k-x^*\|^2-\|x_{k+1}-x^*\|^2}{2\eta}\\ \leq &amp; \frac{ \eta}{2(1-\eta L)}\|\tilde{\triangledown} f(x_k)-\triangledown f(x_k)\|^2 + \frac{\|x_k-x^*\|^2-\|x_{k+1}-x^*\|^2}{2\eta} \end{split}\] <p>第二个不等式根据杨氏不等式\(\left \langle a, b \right \rangle \leq \lambda \frac{\|a\|^2}{2}+ \frac{1}{\lambda}\frac{\|b\|^2}{2}\)，最后利用SVRG方差<strong>Key Lemma</strong>替换第一项即可得到：</p> <h3 id="33-sigma-strongly-convex">3.3 \(\sigma-\)Strongly Convex</h3> <p>本节中讨论当\(f_i(x)\)为非凸函数，而它的平均\(f(x):=\frac{1}{n}\sum_{i=0}^{n-1}f_i(x)\)为凸函数且为\(\sigma-\)强凸时的收敛速率。</p> <p><strong>Key Lemma</strong>:</p> \[F(x_{k+1})-F(x^*)\leq \frac{ \eta}{2(1-\eta L)}\|\tilde{\triangledown} f(x_k)-\triangledown f(x_k)\|^2 + \frac{(1-\sigma\eta)\|x_k-x^*\|^2-\|x_{k+1}-x^*\|^2}{2\eta}\] <p><strong>Proof</strong>:</p> \[\begin{split} F(x_{k+1})-F(x^*) &amp;= f(x_{k+1})-f(x^*)+\psi(x_{k+1})-\psi (x^*)\\ &amp;\leq f(x_k) - \triangledown f(x_k)(x_{k+1}-x_k) +\frac{L}{2}\|x_{k+1}-x_k \|^2-f(x^*)+\psi(x_{k+1})-\psi (x^*) \\ &amp;\leq \left \langle \triangledown f(x_k), x_k-x^* \right \rangle -\frac{\sigma}{2}\|x_k-x^*\|^2- \triangledown f(x_k)(x_{k+1}-x_k) +\frac{L}{2}\|x_{k+1}-x_k \|^2+\psi(x_{k+1})-\psi (x^*) \end{split}\] <p>第一个不等式根据<strong>L-smooth</strong>，第二个不等式根据\(\sigma-\)<strong>强凸性质</strong>。比非强凸多了一项\(\frac{\sigma}{2}\|x_k-x^*\|^2\),后面相同即只需在3.1节<strong>Key Lemma</strong>中加上这一项即可。</p>]]></content><author><name>Tintin</name></author><category term="Optimization"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Katyusha</title><link href="https://tingtingliao.github.io/blog/2019/Katyusha/" rel="alternate" type="text/html" title="Katyusha"/><published>2019-04-29T00:00:00+00:00</published><updated>2019-04-29T00:00:00+00:00</updated><id>https://tingtingliao.github.io/blog/2019/Katyusha</id><content type="html" xml:base="https://tingtingliao.github.io/blog/2019/Katyusha/"><![CDATA[<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <p><a href="http://jmlr.csail.mit.edu/papers/volume18/16-410/16-410.pdf">\(Katyusha\)</a>算是<a href="https://tintin.space/2019/04/25/Linear_Coupling/">\(Gradient-Mirror Linear Coupling\)</a>的扩展。Linear Coupling是\(GradientDescent\)和\(MirrorDescent\)的线性组合，达到了Nesterov加速的效果。但Linear Coupling将\(GD\)换成\(SGD\)的时候效果并不好，于是Zeyuan为\(SGD\)重新设计一个加速的方法，它依旧是以线性耦合的思想，并利用\(SVRG\)更好帮助其加速。</p> <h2 id="1-momentum">1. Momentum</h2> \[v_{k+1} = \gamma v_{k} + g_k\] \[x_{k+1} = x_k - v_{k+1}\] <p>其中\(\gamma\)为动量常数，\(g\)为步长，普通的momentum中\(g_k=\eta \triangledown f(x_k)\)计算当前梯度，Nesterov’s Momentum中\(g_k= \eta \triangledown f(x_k-\gamma v_{k})\)计算向前一步后的梯度，\(\eta\)为学习率。momentum和Nesterov’s Momentum本质上都是计算历史梯度的加权平均，下文将两者统称为momentum。</p> <table> <tbody> <tr> <td>\(v_0 = 0\)</td> <td>\(x_0\)</td> </tr> <tr> <td>\(v_1 = g_0\)</td> <td>\(x_1 = x_0 - g_0\)</td> </tr> <tr> <td>\(v_2 = \gamma g_0 + g_1\)</td> <td>\(x_2 = x_0 - (1+\gamma)g_0 - g_1\)</td> </tr> <tr> <td>\(v_3 = \gamma^2 g_0 + \gamma g_1 + g_2\)</td> <td>\(x_3 = x_0 - (1+\gamma+\gamma^2)g_0 - (1+\gamma)g_1 - g_2\)</td> </tr> <tr> <td>\(...\)</td> <td>\(...\)</td> </tr> <tr> <td>\(v_{k+1} = \sum_{i=0}^{k} \gamma^i g_{k-i}\)</td> <td>\(x_{k+1} = x_0 -\sum_{i=0}^{k} v_i\)</td> </tr> </tbody> </table> \[v_{k+1} = g_k + \gamma g_{k-1} + \gamma^2 g_{k-2} + ...+\gamma^k g_0\] <p>动量参数\(\gamma \in (0,1)\),当前更新的步长\(x_{k+1} = x_k-v_{k+1}\)为历史梯度序列的加权组合,且时间越近的权重越大越远权重越小。</p> \[x_{k+1} = x_0 - g_{k} -(1+\gamma)g_{k-1} -...- (1+\gamma+...+\gamma^k)g_0\] <p>而随着迭代次数的增加，\(x_{k+1}\)减去关于梯度\(g_0\)的权重在逐渐增加。</p> <h3 id="2-katyusha">2. Katyusha</h3> <p><img src="/img/Katyusha/Algorithm.png" alt=""/></p> \[\begin{split} \quad x_{k+1}&amp; \leftarrow \tau_1 z_k+\tau_2 \tilde{x} + (1-\tau_1-\tau_2) y_k\\ \tilde{\triangledown}_{k+1} &amp; \leftarrow \triangledown f(\tilde{x})+\triangledown f_i(x_{k+1}) -\triangledown_i f(\tilde{x})\\ y_{k+1}&amp;\leftarrow x_{k+1} - \frac{1}{3L}\tilde{\triangledown}_{k+1} \\ z_{k+1}&amp;\leftarrow z_{k} - \alpha\tilde{\triangledown}_{k+1} \\ \end{split}\] <p>当\(\tau_1 = \tau_2=0\)时，算法就变成\(SVRG\).</p> <p>当\(\tau_2=0\),令\(\tau = \tau_1\)，即变成了Linear Coupling（LC）中两者线性组合的形式，不同的是\(LC\)中是\(GD\)与\(MD\)的组合，而这里是\(SGD\),估计梯度\(\tilde{\triangledown}_{k+1}\)利用SVRG计算。而\(LC\)实际上也是momentum加速算法的一种形式。</p> <h3 id="21-linear-coupling与momentum">2.1 Linear Coupling与Momentum</h3> \[\quad x_{k+1} \leftarrow \tau z_k+ (1-\tau) y_k\] <p>跟上面momentum类似,这里的\(g=\eta \tilde{\triangledown}_{k+1}\)是利用SVRG计算的,\(y_{k+1}\)是在\(x_{k+1}\)的基础上进行一步\(SGD\)，\(z_{k+1}\)是在\(z_{k}\)上进行一步\(MirrorDescent\).在Linear Coupling中说过\(\tau=\frac{1}{\alpha L+1}\)，那么\(\alpha = \frac{1}{\tau L} - \frac{1}{L}&lt;\frac{1}{\tau L}\)，在Katyusha中，为了计算简便取\(\alpha =\frac{1}{3\tau L}\).下面看它是如何进行动量计算的。</p> <p>初始值：\(y_0 = z_0=x_0\)</p> <table> <tbody> <tr> <td>\(x_1 = x_0\)</td> <td>\(y_1 = x_0-\frac{1}{3L}\tilde{\triangledown}_{1}\)</td> <td>\(z_1 = x_0 - \alpha \tilde{\triangledown}_{1}\)</td> </tr> <tr> <td>\(x_2 = x_0 - ( \frac{1-\tau}{3L}+\tau\alpha ) \tilde{\triangledown}_{1}\)</td> <td>\(y_2 = x_0 - \frac{1}{3L}\tilde{\triangledown}_{2} -( \frac{1-\tau}{3L} +\tau\alpha) \tilde{\triangledown}_{1}\)</td> <td>\(z_2 = x_0 - \alpha(\tilde{\triangledown}_{1} + \tilde{\triangledown}_{2})\)</td> </tr> </tbody> </table> <table> <tbody> <tr> <td>\(x_3 = x_0 - ((1-\tau)\frac{1}{3L} +\tau\alpha ) \tilde{\triangledown}_{2} - ((1-\tau)^2\frac{1}{3L} + (1-(1-\tau)^2)\alpha) \tilde{\triangledown}_{1}\)</td> </tr> </tbody> </table> \[\begin{split} x_{2} &amp;= x_{1}- ((1-\tau)\frac{1}{3L} +\tau\alpha ) \tilde{\triangledown}_{1} \\ x_{3} &amp;= x_{2}- ((1-\tau)\frac{1}{3L} +\tau\alpha ) \tilde{\triangledown}_{2} - (\frac{(1-\tau)^2-(1-\tau)}{3L} + ((1-\tau)-(1-\tau)^2)\alpha) \tilde{\triangledown}_{1} \end{split}\] <p>类似的，Linear Coupling每次移动的步长也是历史梯度的组合，随着迭代次数的增加，\(x_{k+1}\)关于\(\tilde{\triangledown}_{1}\)的权重也是逐渐增加的。</p> \[\begin{split} x_{k+1} &amp;= x_0-\sum_{i=1}^{k} ((1-\tau)^{k-i}\frac{1}{3L} +(1-(1-\tau)^{k-i})\alpha ) \tilde{\triangledown}_{i} 【LC】 \\ x_{k+1} &amp;= x_0 - \sum_{i=0}^{k} (\gamma^0+...+\gamma^{k-i})g_i 【Momentum】 \end{split}\] <p>两者在某种程度上可以说是等价的。其中\(\alpha =\frac{1}{3\tau L}\)，当我们令\(g_i = \frac{1}{3L} \tilde{\triangledown}_{i}\),那么求和括号内项： </p> \[(1-\tau)^{k-i} +(1-(1-\tau)^{k-i})\frac{1}{\tau} \in (1,\frac{1}{\tau}) \quad (1)\] \[\gamma^0+...+\gamma^{k-i} = \frac{1-\gamma^n}{1-\gamma}\propto \frac{1}{1-\gamma} \in (1,+\infty)\] <p>(1)是根据\(\lambda a+ (1-\lambda)b \in (a,b)\),而\(\frac{1}{\tau}\in (1,+\infty)\)。可以看到实际上Linear Coupling也是一种momentum加速算法的一种形式。而作者发现把\(LC\)中的\(GD\)直接换成\(SGD\)时效果并不好，就像直接将Nesterov’s momentum加在\(SGD\)上时一样加速效果并不好。这是因为\(SGD\)梯度含有一定的噪声，而momentum是会记住历史梯度，它会让\(SGD\)继续往错误的方向加速前进。因此Zeyuan为\(SGD\)重新设计一个加速算法\(Katyusha\).</p> <h3 id="22-katyusha-momentum">2.2 Katyusha Momentum</h3> <p>Katyusha momentum在上述2.1节momentum中添加了新的一项\(\tau_2\tilde{x}\).论文中作者取\(\tau_2=0.5\),</p> \[\quad x_{k+1} \leftarrow \tau z_k+0.5 \tilde{x} + (0.5-\tau)y_k\] \[x_{k+1} = x_0-\sum_{i=1}^{k} ((0.5-\tau)^{k-i}\frac{1}{3L} +(0.5-(0.5-\tau)^{k-i})\alpha ) \tilde{\triangledown}_{i}\] <p>\(\tau_2\tilde{x} = x_0\),它依旧是\(z_k\)与\(y_k\)两者的线性耦合，只不过步长变成了原来的一半,\(\because \lambda_1+\lambda_1=k\),\(\lambda_1 a+\lambda_2 b \in (ka,kb)\),所以\(步长\in (\frac{1}{3L}\tilde{\triangledown}_{i} ,\alpha \tilde{\triangledown}_{i} )\Rightarrow (\frac{0.5}{3L}\tilde{\triangledown}_{i} ,0.5\alpha \tilde{\triangledown}_{i} )\)。即每执行一步momentum都往后向\(x_0\)的方向退一步，因此该步骤也叫做负动量Negative momentum.</p> <p><img src="/img/PrimalDual/Katyusha.jpg" alt=""/></p> <p>如图，黑线（\(SGD\)）为在\(x_{k}\)点走了一步负梯度方向得到\(y_k\)，绿色线（momentum）为\(y_k\)与\(z_k\)组合后的\(x_2'\)即\(\tau_2=0\)的momentum加速，橙色线（Katyusha Momentum）为\(x_2'\)与起点\(x_0\)连线中点。</p> \[\begin{split} 黑SGD：&amp;y_1 \leftarrow x_1 - \frac{1}{3L} \tilde{\triangledown}_{1} \\ 绿Momentum：&amp;x_2' \leftarrow \tau y_1 + (1-\tau)z_1 = x_0-((1-\tau)\frac{1}{3L} +\tau\alpha ) \tilde{\triangledown}_{1} \\ 橙Katyusha Momentum：&amp;x_2 \leftarrow x_0-\frac{1}{2}((1-\tau)\frac{1}{3L} +\tau\alpha ) \tilde{\triangledown}_{1} \end{split}\] <p>在执行完\(m\)次内循环后，起始点\(\tilde{x}\)(磁铁)从该循环的终点开始继续下一轮的momentum更新。</p> <h3 id="23-收敛速率">2.3 收敛速率</h3> <p>\(SGD\)的发展主要分为三个阶段：传统\(SGD\)、方差缩减方法以及加速\(SGD\)。</p> <p>\(SGD\)只需要计算单个样本比\(GD\)计算量小\(n\)倍，但其收敛速率仅为\(\frac{1}{\epsilon}\)尽管目标函数是强凸的。因此第二个阶段中以\(SVRG\)为代表的方差缩减方法将\(SGD\)的收敛速度提升到了\(O((n+\frac{L}{\sigma})\log\frac{1}{\epsilon})\),而它依赖于\(\kappa=\frac{L}{\sigma}\)我们称为“条件数量”，那么是否可以设计一个更快的算法达到\(\sqrt\kappa\)的依赖速度？\(APPA\)和\(Catalyst\)做到了也迎来了\(SGD\)的加速阶段，收敛速度提升到了\(O((n+\sqrt{n\kappa })\log\kappa \log\frac{1}{\epsilon})\)，但是\(Catalyst\)依旧不够完美，\(Katyusha\)消去了\(\log\kappa\)达到了最优收敛速率\(O((n+\sqrt{n\kappa }) \log\frac{1}{\epsilon})\)。</p> <table> <thead> <tr> <th style="text-align: center"> </th> <th style="text-align: center">Variance Reduction</th> <th style="text-align: center">Acceleration(momentum)</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><br/>\(SGD\)</td> <td style="text-align: center">\(SAG\) <br/>\(SVRG\)<br/>\(SAGA\)</td> <td style="text-align: center">\(APPA\)<br/>\(Catalyst\)<br/>\(Katyusha\)</td> </tr> </tbody> </table> <table> <thead> <tr> <th style="text-align: center"> </th> <th style="text-align: center">强凸光滑</th> <th style="text-align: center">强凸不光滑</th> <th style="text-align: center">非强凸光滑</th> <th style="text-align: center">非强凸不光滑</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">\(SGD\)</td> <td style="text-align: center">\(O(\frac{L^2}{\sigma \epsilon})\)</td> <td style="text-align: center">\(O(\frac{G}{\sigma \epsilon})\)</td> <td style="text-align: center">\(O(\frac{L^2}{\epsilon^2})\)</td> <td style="text-align: center">\(O(\frac{G}{ \epsilon^2})\)</td> </tr> <tr> <td style="text-align: center">\(SVRG\)</td> <td style="text-align: center">\(O((n+\kappa )\log\frac{1}{\epsilon})\)</td> <td style="text-align: center">\(O(n\log\frac{1}{\epsilon}+\frac{G}{\sigma\epsilon})\)</td> <td style="text-align: center">\(O(n\log\frac{1}{\epsilon}+\frac{L}{\epsilon})\)</td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: center">\(Katyusha\)</td> <td style="text-align: center">\(O((n+\sqrt{n\kappa })\log\frac{1}{\epsilon})\)</td> <td style="text-align: center"> </td> <td style="text-align: center">\(O(n\log\frac{1}{\epsilon}+ \sqrt{n\frac{L}{\epsilon})}\)</td> <td style="text-align: center"> </td> </tr> </tbody> </table>]]></content><author><name>Tintin</name></author><category term="Optimization"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">梯度下降与镜像下降线性耦合</title><link href="https://tingtingliao.github.io/blog/2019/Linear_Coupling/" rel="alternate" type="text/html" title="梯度下降与镜像下降线性耦合"/><published>2019-04-25T00:00:00+00:00</published><updated>2019-04-25T00:00:00+00:00</updated><id>https://tingtingliao.github.io/blog/2019/Linear_Coupling</id><content type="html" xml:base="https://tingtingliao.github.io/blog/2019/Linear_Coupling/"><![CDATA[<script type="text/javascript" async="" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script> <p>本文来源于<sup id="fnref:footnote" role="doc-noteref"><a href="#fn:footnote" class="footnote" rel="footnote">1</a></sup>Allen-Zhu的Gradient-Mirror Coupling，将\(MirrorDescent\)和\(GradientDescent\)组合起来设计了一个全新的加速方法，并将其扩展到不能用moment等加速方法的场景下。</p> <h3 id="1-online-learning-regret">1. Online Learning Regret</h3> <p>在线学习最主要的一个限制是只能看到当前和过去的数据，未来是未知的，有可能完全颠覆现在的认知。因此，在线学习所追求的是直到所有数据所能设计的最优策略。同这个最优策略的差异成为regret。</p> \[Regret_T(h^*) = \sum_{t=1}^T (l(h(x_t),y_t)-l(h^*(x_t),y_t))\] <p>\(l\)表示损失函数,\(h,h^*\)分别表示当前策略和最优策略。\(T\)表示当前第\(T\)个回合，online learning每个回合都会有一个新数据，随着时间增加数据变多，\(Regret\)也会变小。</p> <p>作者引入此概念用以描述求解过程中，当前更新的点\(x_t\)与最优点\(x^*\)之间的目标函数\(f(x)\)的差值：</p> \[\begin{split} R_k(x^*) \equiv \sum_{t=0}^{k-1} (f(x_t)-f(x^*))&amp; = \sum_{t=0}^{k-1} f(x_t)- T f(x^*) \\ &amp; = k f( \overline{x})- k f(x^*) \\ &amp; = k(f( \overline{x})-f(x^*) ) \end{split}\] <p>而根据Convexity：</p> \[\begin{split} f(x^*)&amp;\geq f(x)+ \left \langle \triangledown f(x),x^*-x \right \rangle \\ &amp;\geq \frac{1}{k}\sum_{t=0}^{k-1}f(x_t)+ \frac{1}{k}\sum_{t=0}^{k-1}\left \langle \triangledown f(x_t),x^*-x_t \right \rangle \\ &amp;\geq f(\overline{x})+\frac{1}{k}\sum_{t=0}^{k-1}\left \langle \triangledown f(x_t),x^*-x_t \right \rangle 【琴生不等式】 \\ f(\overline{x})-f(x^*)&amp; \leq \frac{1}{k}\sum_{t=0}^{k-1}\left \langle \triangledown f(x_t),x_t-x^* \right \rangle \end{split}\] <p>所以：</p> \[R_T(x^*) \equiv \sum_{t=0}^{T-1} (f(x_t)-f(x^*)) = T(f( \overline{x})-f(x^*) ) \leq \sum_{t=0}^{T-1}\left \langle \triangledown f(x_t),x_t-x^* \right \rangle \quad (1.1)\] <p>后面的收敛速率都是由该式推导而出的。只用求出\(f( \overline{x})-f(x^*) \leq \epsilon\)时所需步数\(T\)即可。</p> <h3 id="2-对偶问题镜像下降">2. 对偶问题：镜像下降</h3> <p><strong>【Mirror Descent】</strong>：</p> \[\widetilde{x}=Mirr_x(\alpha *\partial f(x))\] \[Mirr_x(\varepsilon )=\min_y \{D(x,y)+\left \langle \varepsilon,y-x\right \rangle \}\] <p>由上节可知，求收敛速度，很重要一步是求出\(\left \langle \triangledown f(x_t),x_t-x^* \right \rangle\),根据<strong>三点性质</strong>有：</p> \[\begin{split} ||x_{k+1}-x^*||^2 &amp;=||x_{k}-\alpha \triangledown f(x_k)-x^*||^2\\ &amp;= ||x_{k}-x^*||^2-2\alpha\triangledown f(x_k)(x_{k}-x^*)+\alpha^2||\triangledown f(x_k)||^2 \\ \end{split}\] \[\therefore \alpha \triangledown f(x_k)(x_{k}-x^*) = \frac{\alpha^2}{2}||\triangledown f(x_k)||^2 + D(x_k,x^*) -D(x_{k+1},x^*)\] <p>关于<strong>Bregman divergence</strong>的距离函数\(D(x,y)\)，详细解释见<a href="http://127.0.0.1:4000/2019/04/09/Proximal-Descent/">这里</a>.</p> <p>根据<font color="blue">(1.1)式</font>，\(MD\)中的\(Regret\)：</p> \[\begin{split} \alpha T(f( \overline{x})-f(x^*) ) &amp;\leq \alpha \sum_{t=0}^{T-1}\left \langle \triangledown f(x_t),x_t-x^* \right \rangle \\ &amp; \leq \frac{\alpha^2}{2}\sum_{k=0}^{T-1} ||\triangledown f(x_k)||^2 + D(x_0,x^*) -D(x_{T},x^*) \\ &amp; \leq \frac{\alpha^2}{2}\sum_{k=0}^{T-1} ||\triangledown f(x_k)||^2 + D(x_0,x^*) -D(x_{T},x^*) \end{split}\] <p>令\(\rho = \frac{1}{T}\sum_{k=0}^{T-1}\|\triangledown f(x_k)\|^2\)为梯度平方均值，那么：</p> \[\begin{split} \alpha T(f( \overline{x})-f(x^*)) \leq \frac{\alpha^2}{2} T \rho^2 + D(x_0,x^*) \quad (2.1) \end{split}\] <ul> <li>若\(f(x)\)为\(L-smooth\),取\(\alpha = \frac{1}{L}\),有：</li> </ul> \[f( \overline{x})-f(x^*) \leq \frac{\rho^2}{2L} + \frac{LD(x_0,x^*)}{T}\] <p>令\(\frac{LD(x_0,x^*)}{T}\leq \epsilon\)，收敛速率\(T \geq \frac{LD(x_0,x^*}{\epsilon})\)</p> <ul> <li>若\(f(x)\)为\(non-smooth\),令\(\alpha = \frac{\sqrt{2D(x_0,x^*)}}{\rho \sqrt{T}}\),由（2.1）式得：</li> </ul> \[f( \overline{x})-f(x^*) \leq \frac{2D(x_0,x^*)}{\alpha T} = \frac{\sqrt{2D(x_0,x^*)}· \rho}{ \sqrt{T}}\] <p>达到\(\epsilon\)精度，收敛速率\(T \geq \frac{2D(x_0,x^*) \rho^2}{\epsilon^2 }\)。</p> <p>在非光滑的情况下，\(MD\)的收敛速度是\(O(\frac{1}{\epsilon^2})\)，比\(GD\)慢一个量级，而在光滑的情况下两者都是\(O(\frac{1}{\epsilon})\)。</p> <h4 id="mirror-descent与gradient-descent联系">Mirror Descent与Gradient Descent联系</h4> <p>为了更好的\(MD\)与\(GD\)之间的联系，这里假设它们的目标函数都是\(L-smooth\)的：</p> \[f(x_{k+1}) \leq f(x_{k}) + \triangledown f(x_k)|x_{k+1}-x_k|+ \frac{L}{2}||x_{k+1}-x_k||^2\] \[\begin{split} GD(x)&amp;= argmin_y \{ \triangledown f(x)|y-x|+ \frac{L}{2}||y-x||^2\} \\ x_{k+1} &amp;\leftarrow x_k - \frac{1}{L} \triangledown f(x_k) \\ \\ \\ MD(\alpha\triangledown f(x))&amp;=argmin_y \{ \alpha\triangledown f(x)|y-x|+ D(x,y)\} \\ &amp;= argmin_y \{ \alpha\triangledown f(x)|y-x|+ \frac{L}{2}||y-x||^2\} \end{split} \\ x_{k+1} \leftarrow x_k - \alpha \frac{1}{L} \triangledown f(x_k)\] <p>\(GD\)的收敛定理是minimize一个quadratic upper bound<a href="https://tintin.space/2019/03/29/Convergence/">证明见这里</a>，而\(MD\)是minimize dual averaging lower bound.</p> \[f(x_k)-f(x^*)\leq \frac{L\|x_0-x^*\|^2}{2T} 【GD】\] \[\alpha T(f( \overline{x})-f(x^*) ) \leq \alpha \sum_{t=0}^{T-1}\left \langle \triangledown f(x_t),x_t-x^* \right \rangle \leq \frac{\alpha^2}{2}\sum_{k=0}^{T-1} ||\triangledown f(x_k)||^2 + D(x_0,x^*) -D(x_{T},x^*) 【MD】\] <p>当\(f(x)\)光滑，距离函数为欧式距离且\(\alpha=1\)时，\(MD\)和\(GD\)等价。由此我们也可以从一个high level角度解释\(MD\)和\(GD\)，当\(\|\triangledown f(x_k)\|\)特别大的时候，\(GD\)更新的距离也很大，而当\(\|\triangledown f(x_k)\|\)很小即函数很平缓时，相反\(MD\)会表现更好，此时它的\(Regret\)比较小bound也更加严格，而\(\alpha\)也是随着时间的变化在逐步调节获得更好的收敛。</p> <p>因此我们很容易想到，是否可以<font color="red">结合梯度下降和镜像下降得到一个更快速的一阶算法？</font></p> <h3 id="3-linear-coupling">3. Linear Coupling</h3> <p><img src="/img/LinearCoupling/Algorithm.png" alt=""/></p> \[\begin{split} MD\&amp;GD \quad x_{k+1}&amp; \leftarrow \tau_k MD(x_{k})+(1-\tau_k)GD(x_{k}) \\ x_{k+1}&amp;\leftarrow \tau_k z_{k+1}+(1-\tau_k)y_{k+1} \end{split}\] <p>同样地，我们需要先求出\(\alpha \triangledown f(x_{k+1})(x_{k+1}-x^*)\),但Linear Coupling不是\(MD\),而是\(MD\)和\(GD\)的线性组合，因此我们需要将其拆开：</p> \[\alpha \triangledown f(x_{k+1})(x_{k+1}-x^*) = \alpha \triangledown f(x_{k+1})(x_{k+1}-z_{k}) +\alpha \triangledown f(x_{k+1})(z_{k}-x^*)\] <p><strong>第二项</strong>\(z_k\)满足\(MD\)(2.1)式:</p> \[\begin{split} \alpha \triangledown f(x_{k+1})(z_{k}-x^*) &amp;= \frac{\alpha^2}{2}||\triangledown f(x_{k+1})||^2 + D(z_k,x^*) -D(z_{k+1},x^*) \\ &amp; \leq \alpha^2 L (f(x_{k+1})-f(y_{k+1})) + D(z_k,x^*) -D(z_{k+1},x^*) \end{split}\] <p>\(L-smooth\)梯度下降中满足(<a href="https://tintin.space/2019/03/29/Convergence/">证明见这里</a>):</p> \[f(x_k)-f(x_{k+1})\geq \frac{1}{2L}||\triangledown f(x_k)||^2\] <p>Linear Coupling中\(y_{k+1}\)是\(x_{k+1}\)经过\(GD\)的下一步，因此：</p> \[f(x_{k+1})-f(y_{k+1})\geq \frac{1}{2L}||\triangledown f(x_{k+1})||^2\] \[\therefore 第二项 \leq \alpha^2 L (f(x_{k+1})-f(y_{k+1})) + D(z_k,x^*) -D(z_{k+1},x^*)\] <p><strong>第一项</strong>：</p> \[\begin{split} \alpha \triangledown f(x_{k+1})(x_{k+1}-z_{k}) =&amp; \alpha \triangledown f(x_{k+1})(x_{k+1}-\frac{x_{k+1}-(1-\tau_k)y_{k} }{\tau_k}) \\ =&amp; \alpha \triangledown f(x_{k+1}) \frac{1-\tau_k }{\tau_k}(y_{k}-x_{k+1})\\ \leq &amp; \alpha \frac{1-\tau_k }{\tau_k} (f(y_k) -f(x_{k+1})) 【一阶凸性质】 \end{split}\] <p>令\(\frac{1-\tau_k }{\tau_k} = \alpha L\),两式相加得:</p> \[\alpha \triangledown f(x_{k+1})(x_{k+1}-x^*) \leq \alpha^2 L (f(y_k)-f(y_{k+1})) + D(z_k,x^*) -D(z_{k+1},x^*)\] <p>根据<font color="blue">(1.1)式</font>, Linear Coupling的\(Regret\):</p> \[\begin{split} \alpha T(f( \overline{x})-f(x^*)) &amp;\leq \alpha \sum_{t=0}^{T-1}\left \langle \triangledown f(x_t),x_t-x^* \right \rangle \\ &amp;\leq \alpha^2 L (f(y_0)-f(y_{T})) + D(z_0,x^*) -D(z_{T},x^*) \\ f( \overline{x})-f(x^*) &amp;\leq \frac{1}{T} (\alpha L d + \frac{D(z_0,x^*)}{\alpha} ) \end{split}\] <p>其中\(d=f(y_0)-f(y_{T})\),令\(\alpha = \sqrt{\frac{ D(z_0,x^*)}{Ld}}\),</p> \[f( \overline{x})-f(x^*) \leq \frac{2\sqrt{LdD(z_0,x^*)}}{T}\] <p>当\(T = 4\sqrt{\frac{LD(z_0,x^*)}{d}}\)时，\(f( \overline{x})-f(x^*) \leq \frac{d}{2}\),即当前点的距离到最优点距离变成一半.即每个epoch的距离依次为\(d,\frac{d}{2},\frac{d}{4},...\),那么收敛速率：</p> \[T = O(\sqrt{\frac{LD(z_0,x^*)}{\epsilon}}+\sqrt{\frac{LD(z_0,x^*)}{2\epsilon}}+\sqrt{\frac{LD(z_0,x^*)}{4\epsilon}}+...) =O(\sqrt{\frac{LD(z_0,x^*)}{\epsilon}})\] <p>Linear Coupling的收敛速度\(\frac{1}{\sqrt{\epsilon}}\)和Nesterov加速方法一样，比\(GD\)快了一个量级。其中步长是固定的\(\alpha = \sqrt{\frac{ D(z_0,x^*)}{Ld}}\)随着时间的增加\(\alpha\)变大，我们取\(\tau=\frac{1}{\alpha L+1}\)逐渐减小，也就是说随着当前点离最优点越来越近的时候，\(\alpha\)变小，\(\tau\)变大，\(GD\)更新能力逐渐变弱而\(MD\)逐渐变强。</p> <p>但是它有三个缺点：1）\(\alpha\)的值取决于\(D(z_0,x^*)\);2)\(d\)初始化好坏会影响收敛；3）算法需要重新开始，即在每个epoch开始时都需要重新初始化参数。</p> <p>为了解决这几个问题，Zheyuan将\(\alpha，\tau\)设为随着时间变化的参数不需要额外初始化其它参数,\(\alpha_{t+1} = \frac{t+2}{2L},\tau_t=\frac{1}{\alpha L+1}=\frac{2}{t+2}\),收敛速率为\(O(\sqrt{\frac{4LD(z_0,x^*)}{\epsilon}})\)</p> <p>优点：1）Linear Coupling不同于常见的momentum加速方法，但是它和一般的加速方法有着相同的收敛速度； 2）利用Mirror Descent应用于非Euclidean Distance场景中。</p> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:footnote" role="doc-endnote"> <p><a href="https://arxiv.org/pdf/1407.1537.pdf">Allen-Zhu Z, Orecchia L. Linear coupling: An ultimate unification of gradient and mirror descent[J]. arXiv preprint arXiv:1407.1537, 2014.</a>. <a href="#fnref:footnote" class="reversefootnote" role="doc-backlink">&#8617;</a></p> </li> </ol> </div>]]></content><author><name>Tintin</name></author><category term="optimization"/><summary type="html"><![CDATA[]]></summary></entry></feed>